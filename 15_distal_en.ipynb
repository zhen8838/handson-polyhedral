{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cb2fae",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "As the demand for computing power in AI workloads continues to surge, while the performance and frequency improvements of individual chips slow down, and the memory walls and bandwidth walls encountered by large models, large graphs, and large tables requiring massive capacity and bandwidth, the hardware is gradually shifting towards a scale-out direction, such as multi-GPU, multi-chip, multi-die, etc. After hardware scales up, the challenges faced by AI software extend from computing distribution within a single node to data distribution across multiple nodes, as well as communication overhead brought by data dependencies.\n",
    "\n",
    "I believe that the combination of hardware horizontal expansion will become more diverse, and manually building highly optimized kernels for different topological combinations will become more difficult. Therefore, the technology of automatically generating distributed computing kernels through AI compilation will become important.\n",
    "\n",
    "In this context, I originally intended to try using AI compilation technology to automatically search for kernel implementations that conform to computing and data distribution, but due to current technical limitations, I cannot achieve this yet. Therefore, I take a step back and attempt to model distributed computing using polyhedral compilation, analyze and filter out legal implementations to lay the foundation for future automation. In short, this article adopts the Compute Schedule separation approach, combined with polyhedral technology, to build a fusion DSL that can help everyone better understand the relationship between computing distribution and data distribution, and also serves as a more comprehensive usage example of polyhedral compilation technology.\n",
    "\n",
    "Notes:\n",
    "\n",
    "1. This article draws heavily on inspiration from the [Distal paper](https://arxiv.org/abs/2203.08069); please refer to [here](https://zhen8838.github.io/2025/02/04/distal/) for supplementary background knowledge. Distal is actually based on the long-developed Legion project, where Legion implements a domain/point-based polyhedral mapping scheme in the runtime, allowing relatively simple implementation of various forms of communication. This article, for minimal dependencies, uses polyhedral analysis to identify communication patterns and offloads them to the MPI backend, which is the main difference.\n",
    "2. If there is a backend like SymmetricMemory, it can simplify complex communication pattern detection.\n",
    "3. This article currently only implements code generation for a single-level topology; adaptation for multi-level topologies still needs further exploration.\n",
    "4. This article implements compute-communication fusion; for the need to overlap communication and computation, it is necessary to switch to a backend that supports asynchronous communication, and to implement it with optimizations like NBuffer/SoftPipeline compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543539c9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6af8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Tuple, Union, TextIO, List, Dict, Optional, Any, Callable, Sequence, cast, NamedTuple\n",
    "\n",
    "from io import FileIO\n",
    "from dataclasses import dataclass, replace, field\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import more_itertools as itertools\n",
    "from enum import IntEnum\n",
    "from xdsl.dialects import arith, builtin, tensor, linalg, func\n",
    "from xdsl.frontend.pyast.context import PyASTContext, TypeRegistry\n",
    "from xdsl.frontend.pyast.code_generation import CodeGeneration, CodeGenerationVisitor\n",
    "from xdsl import ir\n",
    "from xdsl.irdl import irdl_op_definition, IRDLOperation, prop_def, result_def, operand_def, var_operand_def, attr_def\n",
    "from xdsl import passes\n",
    "import dowhen\n",
    "import isl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84921521",
   "metadata": {},
   "source": [
    "To implement a more complete DSL, a frontend is essential. Fortunately, [xDSL](https://github.com/xdslproject/xdsl) recently provided a simplified frontend [xDSL front-end: Embedding MLIR into Python](https://github.com/xdslproject/xdsl/tree/v0.48.3/xdsl/frontend/pyast). Although it has many imperfections, in Python, we can use the [dowhen](https://github.com/gaogaotiantian/dowhen) library to monkey-patch xDSL to supplement the imperfections.\n",
    "\n",
    "The logic of xDSL is to bridge Python types and MLIR types through `TypeRegistry`, and then traverse and generate using the pre-provided `CodeGenerationVisitor`. However, it currently does not support type annotations with parameters, such as `Buffer[float, [2048, 1024]]`. I solved this with a custom `ParameterizedTypeRegistry`. Additionally, the default `CodeGenerationVisitor` does not support some AST visits, which I supplemented with `MyCodeGenVisitor`. After extending these implementations, by using the `dowhen` library to replace some internal calls in xDSL, I successfully built a frontend based on index notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577522f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builtin.module {\n",
      "  func.func @matmul(%A : memref<512x2048xf32>, %B : memref<2048x1024xf32>, %C : memref<512x1024xf32>, %m : index, %n : index, %k : index) -> memref<512x1024xf32> {\n",
      "    %0 = \"buffer.access\"(%C, %m, %n) : (memref<512x1024xf32>, index, index) -> f32\n",
      "    %1 = \"buffer.access\"(%B, %k, %n) : (memref<2048x1024xf32>, index, index) -> f32\n",
      "    %2 = \"buffer.access\"(%A, %m, %k) : (memref<512x2048xf32>, index, index) -> f32\n",
      "    %3 = arith.mulf %2, %1 : f32\n",
      "    \"tensor.assign\"(%0, %3) : (f32, f32) -> ()\n",
      "    func.return %C : memref<512x1024xf32>\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ParameterizedTypeRegistry(TypeRegistry):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self._generic_mapping: dict[type, type] = {}\n",
    "\n",
    "  def resolve_attribute(\n",
    "      self, annotation_name: str, globals: dict[str, Any]\n",
    "  ) -> ir.TypeAttribute | None:\n",
    "    \"\"\"Get an IR type attribute from a string annotation.\"\"\"\n",
    "    annotation = cast(\n",
    "        type,\n",
    "        eval(annotation_name, globals, None),\n",
    "    )\n",
    "    if isinstance(annotation, ir.TypeAttribute):\n",
    "      return annotation\n",
    "    return self._mapping.get(annotation, None)\n",
    "\n",
    "  def get_annotation(self, attribute: ir.TypeAttribute) -> type | None:\n",
    "    anno = super().get_annotation(attribute)\n",
    "    if anno is None:\n",
    "      for key, value in self._generic_mapping.items():\n",
    "        if value == type(attribute):\n",
    "          return key\n",
    "    return anno\n",
    "\n",
    "  def register_param_type(self, annotation: type,\n",
    "                          attributeType: type):\n",
    "    self._generic_mapping[annotation] = attributeType\n",
    "\n",
    "\n",
    "class MyCodeGenVisitor(CodeGenerationVisitor):\n",
    "  def parse_op(self, ir_type, func_name, args: tuple):\n",
    "    ir_type = cast(ir.TypeAttribute, ir_type)\n",
    "    source_type = self.type_converter.type_registry.get_annotation(ir_type)\n",
    "    assert source_type\n",
    "    function_name = f\"{source_type.__qualname__}.{func_name}\"\n",
    "    op = self.type_converter.function_registry.resolve_operation(\n",
    "        module_name=source_type.__module__,\n",
    "        method_name=function_name,\n",
    "        args=args,\n",
    "    )\n",
    "    assert op\n",
    "    self.inserter.insert_op(op)\n",
    "\n",
    "  def visit_Subscript(self, node):\n",
    "    self.visit(node.slice)\n",
    "    elts = [self.inserter.get_operand() for i in range(len(node.slice.elts))]\n",
    "    self.visit(node.value)\n",
    "    value = self.inserter.get_operand()\n",
    "    self.parse_op(value.type, '__getitem__', (value, elts[::-1]))\n",
    "\n",
    "  def visit_Tuple(self, node):\n",
    "    for elt in node.elts:\n",
    "      self.visit(elt)\n",
    "\n",
    "  def visit_Assign(self, node) -> None:\n",
    "    self.visit(node.targets[0])\n",
    "    target = self.inserter.get_operand()\n",
    "    self.visit(node.value)\n",
    "    value = self.inserter.get_operand()\n",
    "    self.inserter.insert_op(AssignOp(target, value))\n",
    "\n",
    "\n",
    "dowhen.when(CodeGeneration.run_with_type_converter, \"+9\").do(\n",
    "    lambda type_converter, module, file:\n",
    "    {\"visitor\": MyCodeGenVisitor(type_converter, module, file)})\n",
    "\n",
    "\n",
    "class IterKind(IntEnum):\n",
    "  Serial = 0\n",
    "  Distributed = 1\n",
    "  Tensorize = 2\n",
    "\n",
    "\n",
    "class UsageKind(IntEnum):\n",
    "  Input = 0\n",
    "  Output = 1\n",
    "  Const = 2\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Expr:\n",
    "\n",
    "  def __add__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('+', self, other)\n",
    "\n",
    "  def __sub__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('-', self, other)\n",
    "\n",
    "  def __mul__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('*', self, other)\n",
    "\n",
    "  def __floordiv__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('//', self, other)\n",
    "\n",
    "  def __truediv__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('/', self, other)\n",
    "\n",
    "  def __mod__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('%', self, other)\n",
    "\n",
    "  @abstractmethod\n",
    "  def walk(fn: Callable[['Expr'], None]):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Const(Expr):\n",
    "  value: int\n",
    "\n",
    "  def __str__(self):\n",
    "    return str(self.value)\n",
    "\n",
    "  def walk(self, fn: Callable[['Expr'], None]):\n",
    "    fn(self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class IterVar(Expr):\n",
    "  name: str\n",
    "  lower_bound: int | None\n",
    "  upper_bound: int | None\n",
    "  step: int = 1\n",
    "\n",
    "  @property\n",
    "  def extent(self) -> int:\n",
    "    return self.upper_bound - self.lower_bound\n",
    "\n",
    "  @staticmethod\n",
    "  def range(name: str, extent: int):\n",
    "    return IterVar(name, 0, extent, 1)\n",
    "\n",
    "  @staticmethod\n",
    "  def symbol(name: str):\n",
    "    vars = tuple(map(lambda s: IterVar(s, None, None, 1), name.split(' ')))\n",
    "    return vars[0] if len(vars) == 1 else vars\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.name, self.lower_bound, self.upper_bound, self.step))\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.name\n",
    "\n",
    "  def walk(self, fn: Callable[['Expr'], None]):\n",
    "    fn(self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Binary(Expr):\n",
    "  op: str\n",
    "  lhs: Expr\n",
    "  rhs: Expr\n",
    "\n",
    "  @staticmethod\n",
    "  def create(op: str, lhs: Expr, rhs: Expr):\n",
    "    match lhs:\n",
    "      case int():\n",
    "        lhs = Const(lhs)\n",
    "      case Expr():\n",
    "        pass\n",
    "      case _:\n",
    "        raise TypeError(f\"Unsupported left-hand side operand type: {type(lhs)}\")\n",
    "    match rhs:\n",
    "      case int():\n",
    "        rhs = Const(rhs)\n",
    "      case Expr():\n",
    "        pass\n",
    "      case _:\n",
    "        raise TypeError(f\"Unsupported right-hand side operand type: {type(rhs)}\")\n",
    "\n",
    "    return Binary(op=op, lhs=lhs, rhs=rhs)\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"({self.lhs} {self.op} {self.rhs})\"\n",
    "\n",
    "  def walk(self, fn: Callable[['Expr'], None]):\n",
    "    self.lhs.walk(fn)\n",
    "    self.rhs.walk(fn)\n",
    "    fn(self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Buffer:\n",
    "  name: str\n",
    "  dims: tuple[int | IterVar, ...]\n",
    "  dtype: type = float\n",
    "  sharding: None | isl.map = None\n",
    "  usage: UsageKind = UsageKind.Input\n",
    "\n",
    "  @property\n",
    "  def shape(self) -> tuple[int | IterVar, ...]:\n",
    "    return tuple(d for d in self.dims)\n",
    "\n",
    "  @property\n",
    "  def domain(self) -> isl.set:\n",
    "    def render(i): return f'0 <= d{i} < {self.dims[i]}' if isinstance(\n",
    "        self.dims[i], int) else f'{self.dims[i].lower_bound} <= d{i} < {self.dims[i].upper_bound}'\n",
    "    return isl.set(f\"{{ {self.name}[{','.join([f'd{i}' for i in range(len(self.dims))])}] : {' and '.join([render(i) for i in range(len(self.dims))])} }}\")\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.name, self.dims, self.dtype, str(self.sharding)))\n",
    "\n",
    "  @classmethod\n",
    "  def __class_getitem__(cls, args):\n",
    "    elem_type = None\n",
    "    if issubclass(args[0], float):\n",
    "      elem_type = builtin.f32\n",
    "    elif issubclass(args[0], int):\n",
    "      elem_type = builtin.i32\n",
    "    else:\n",
    "      raise TypeError(f\"Unsupported element type: {args[0]}\")\n",
    "    return builtin.MemRefType(elem_type, [builtin.IntAttr(arg) for arg in args[1]])\n",
    "\n",
    "  def __setitem__(cls, args):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __getitem__(cls, args):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __iadd__(self, value):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __matmul__(self, value):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "@irdl_op_definition\n",
    "class AccessOp(IRDLOperation):\n",
    "  name = \"buffer.access\"\n",
    "\n",
    "  buffer = operand_def(builtin.MemRefType)\n",
    "  indices = var_operand_def(builtin.IndexType)\n",
    "  result = result_def(builtin.Attribute)\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      buffer: ir.SSAValue,\n",
    "      indices: Sequence[ir.SSAValue] | ir.SSAValue,\n",
    "      result_type: ir.Attribute,\n",
    "  ):\n",
    "    return super().__init__(operands=[buffer, indices], result_types=[result_type])\n",
    "\n",
    "\n",
    "@irdl_op_definition\n",
    "class AssignOp(IRDLOperation):\n",
    "  name = \"tensor.assign\"\n",
    "\n",
    "  target = operand_def(ir.TypeAttribute)\n",
    "  value = operand_def(ir.TypeAttribute)\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      target: ir.SSAValue,\n",
    "      value: ir.SSAValue,\n",
    "  ):\n",
    "    return super().__init__(operands=[target, value],\n",
    "                            result_types=[])\n",
    "\n",
    "\n",
    "type_registry = ParameterizedTypeRegistry()\n",
    "type_registry.register_param_type(Buffer, builtin.MemRefType)\n",
    "ctx = PyASTContext(type_registry)\n",
    "ctx.register_type(float, builtin.f32)\n",
    "ctx.register_type(IterVar, builtin.IndexType())\n",
    "ctx.register_function(Buffer.__getitem__, lambda *args:\n",
    "                      AccessOp(args[0], args[1], args[0].type.element_type))\n",
    "ctx.register_function(Buffer.__setitem__, lambda *args:\n",
    "                      AssignOp(args[0], args[1]))\n",
    "ctx.register_function(float.__mul__, arith.MulfOp)\n",
    "\n",
    "\n",
    "@ctx.parse_program\n",
    "def matmul(A: Buffer[float, [512, 2048]], B: Buffer[float, [2048, 1024]], C: Buffer[float, [512, 1024]], m: IterVar, n: IterVar, k: IterVar) -> Buffer[float, [512, 1024]]:\n",
    "  C[m, n] = A[m, k] * B[k, n]\n",
    "  return C\n",
    "\n",
    "\n",
    "print(matmul.module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab43eb",
   "metadata": {},
   "source": [
    "Since I tend to use a polyhedral approach for compiler optimization, I still need my own IR. In the previous step, I defined expressions such as `Expr`, `Const`, `IterVar`, and `Binary`. Here, I also need to define other core components, such as `Computation` which represents a specific computation, `Mesh` which represents topology, `Access` which represents the access information of computations to `Buffer`, and `Transfer` which represents data movement information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64739ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class Mesh:\n",
    "  dims: tuple[IterVar, ...]\n",
    "\n",
    "  @property\n",
    "  def shape(self) -> tuple[int, ...]:\n",
    "    return tuple(var.extent for var in self.dims)\n",
    "\n",
    "  @property\n",
    "  def domain(self) -> isl.set:\n",
    "    return isl.set(f\"{{ Mesh[{','.join(map(str, self.dims))}] : {' and '.join([f'{dim.lower_bound} <= {dim} < {dim.upper_bound}' for dim in self.dims])} }}\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Access:\n",
    "  buffer: Buffer\n",
    "  relation: isl.map\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.buffer, str(self.relation)))\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Transfer:\n",
    "  access: Access\n",
    "  schedule: isl.map\n",
    "\n",
    "class AccessDimIndex(NamedTuple):\n",
    "  access_idx: int\n",
    "  buffer_dim: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Computation:\n",
    "  op: str\n",
    "  domain: isl.set\n",
    "  schedule: isl.map\n",
    "  accesses: List[Access]\n",
    "  iter_vars: tuple[IterVar]\n",
    "  mesh: Mesh | None = None\n",
    "  iter_kinds: dict[IterVar, IterKind] = field(default_factory=dict)\n",
    "  dim_bindings: dict[int, List[AccessDimIndex]] = field(default_factory=dict)\n",
    "  transfers: dict[IterVar, Tuple[Transfer, ...]] = field(default_factory=dict)\n",
    "\n",
    "  def name(self):\n",
    "    return self.domain.get_tuple_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237697c",
   "metadata": {},
   "source": [
    "Next, I will parse the AST into my own IR. Here, the parsing of index notation is only implemented in a simple way, that is, the case where iterVar directly participates in buffer access. More complex situations are left for interested readers to implement on their own. The parsing process is also relatively simple: by analyzing the usage of `SSAValue` by `AccessOp`, we can obtain the computed `Domain/AccessRelation/Schedule`, which are then uniformly stored in `Computation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20db3c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[k' = k, m' = m, n' = n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IndexCollector:\n",
    "  def __init__(self, iter_set: set[IterVar]):\n",
    "    self.iter_set: set[IterVar] = iter_set\n",
    "\n",
    "  def collect(self, node: ir.IRWithUses):\n",
    "    # todo support complex index pattern\n",
    "    match node:\n",
    "      case ir.BlockArgument():\n",
    "        match node.type:\n",
    "          case builtin.IndexType():\n",
    "            iter_var = IterVar.symbol(node.name_hint)\n",
    "            self.iter_set.add(iter_var)\n",
    "            return iter_var\n",
    "      case _:\n",
    "        raise NotImplementedError(\"Unsupported index node\")\n",
    "\n",
    "\n",
    "class StmtCollector:\n",
    "  def __init__(self, stmt_name: str):\n",
    "    self.stmt_name = stmt_name\n",
    "    self.iter_set: set[IterVar] = set()\n",
    "    self.access_dict: dict[AccessOp, (Buffer, list[ir.Operation])] = {}\n",
    "    self.op: str = None\n",
    "    self.on_value = False\n",
    "\n",
    "  def visit(self, node: ir.IRWithUses):\n",
    "    match node:\n",
    "      case ir.BlockArgument():\n",
    "        match node.type:\n",
    "          case builtin.MemRefType():\n",
    "            return Buffer(node.name_hint, tuple(dim.data for dim in node.type.shape), node.type.element_type, usage=UsageKind.Input if self.on_value else UsageKind.Output)\n",
    "          case _:\n",
    "            return\n",
    "      case ir.SSAValue() | ir.Operation():\n",
    "        op = node if isinstance(node, ir.Operation) else node.owner\n",
    "        match op:\n",
    "          case AssignOp():\n",
    "            self.on_value = False\n",
    "            self.visit(op.target)\n",
    "            self.on_value = True\n",
    "            self.visit(op.value)\n",
    "            self.on_value = False\n",
    "          case AccessOp():\n",
    "            b: Buffer = self.visit(op.buffer)\n",
    "            indices = [IndexCollector(self.iter_set).collect(i) for i in op.indices]\n",
    "            self.access_dict[op] = (b, indices)\n",
    "          case arith.MulfOp():\n",
    "            assert self.op is None\n",
    "            self.op = op.name\n",
    "            self.visit(op.lhs)\n",
    "            self.visit(op.rhs)\n",
    "\n",
    "\n",
    "class PolyhedronExtractPass(passes.ModulePass):\n",
    "  name = \"polyhedron_analysis\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.computations: list[Computation] = []\n",
    "    return super().__init__()\n",
    "\n",
    "  def analysis_stmt(self, op: AssignOp):\n",
    "    assert len(self.computations) == 0, \"not support stmts more than 1\"\n",
    "    stmt_name = f's{len(self.computations)}'\n",
    "    c = StmtCollector(stmt_name)\n",
    "    c.visit(op)\n",
    "    accesses = []\n",
    "    iters = sorted(c.iter_set, key=lambda i: i.name)\n",
    "    domain_dims = list(map(lambda x: x.name, iters))\n",
    "    domain = isl.set(f\"{{ {stmt_name}[{','.join(domain_dims)}] }}\")\n",
    "    bounded_iters: dict[str, IterVar] = {}\n",
    "    dim_bindings: dict[int, List[Tuple[int, int]]] = {}\n",
    "    for (bf, indices) in c.access_dict.values():\n",
    "      relation = isl.map(\n",
    "          f\"{{ {stmt_name}[{','.join(domain_dims)}] -> {bf.name}[{','.join(map(lambda x: x.name, indices))}]}}\")\n",
    "      domain = domain.intersect(relation.intersect_range(bf.domain).domain())\n",
    "      for i, idx in enumerate(indices):\n",
    "        if idx.name not in bounded_iters:\n",
    "          bounded_iters[idx.name] = replace(idx, lower_bound=bf.domain.dim_min_val(\n",
    "              i).num_si(), upper_bound=bf.domain.dim_max_val(i).num_si() + 1)\n",
    "      access = Access(replace(bf, dims=tuple(\n",
    "          [bounded_iters[idx.name] for idx in indices])), relation)\n",
    "      accesses.append(access)\n",
    "      for i, idx in enumerate(indices):\n",
    "        j = iters.index(idx)\n",
    "        binding = dim_bindings.get(j, [])\n",
    "        binding.append(AccessDimIndex(len(accesses) - 1, i))\n",
    "        dim_bindings[j] = binding\n",
    "        \n",
    "    comp = Computation(c.op, domain, domain.identity(), accesses,\n",
    "                       tuple([bounded_iters[v.name] for v in iters]), dim_bindings=dim_bindings)\n",
    "    self.computations.append(comp)\n",
    "\n",
    "  def analysis_op(self, op: ir.Operation):\n",
    "    if isinstance(op, AssignOp):\n",
    "      self.analysis_stmt(op)\n",
    "\n",
    "  def apply(self, ctx, op: builtin.ModuleOp) -> dict[str, Computation]:\n",
    "    for sub in op.walk():\n",
    "      self.analysis_op(sub)\n",
    "    return self.computations\n",
    "\n",
    "\n",
    "def polyhedron_extract(func) -> Computation:\n",
    "  return PolyhedronExtractPass().apply(passes.Context(allow_unregistered=True), func.module)[0]\n",
    "  \n",
    "s0 = polyhedron_extract(matmul)\n",
    "s0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e09b40",
   "metadata": {},
   "source": [
    "The IR I designed is an immutable structure. My idea is to implement a schedule trace similar to [Meta Scheduler](https://arxiv.org/abs/2205.13603), so that it can be connected to external optimizers for search. Then, based on the polyhedral representation, it is convenient to implement some loop optimization operations, such as split (fixing the inner loop of the loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a2f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[k' = k, mo, mi = m - 8mo, n' = n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -7 + m <= 8mo <= m }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(self: Computation, parent_var: str, outer_var: str, inner_var: str, factor: int) -> 'Computation':\n",
    "  \"\"\" factor = extend(inner_var) \"\"\"\n",
    "  dim_index = self.iter_vars.index(parent_var)\n",
    "  assert dim_index != -1\n",
    "  new_iter_vars = tuple([*self.iter_vars[:dim_index],\n",
    "                         outer_var, inner_var, *self.iter_vars[dim_index + 1:]])\n",
    "\n",
    "  constraints_str = f' {outer_var} = {parent_var} // {factor} and {inner_var} = {parent_var} - {outer_var} * {factor}'\n",
    "  mapping_str = f\"{{ {self.name()}[{str.join(',', map(str, self.iter_vars))}] -> {self.name()}[{str.join(',', map(str, new_iter_vars))}]: {constraints_str} }}\"\n",
    "  split_map = isl.map(mapping_str)\n",
    "\n",
    "  new_schedule = self.schedule.apply_range(split_map)\n",
    "  new_schedule = reduce(lambda sche, p: sche.set_dim_name(\n",
    "      isl.dim_type.OUT, p[0], str(p[1])), enumerate(new_iter_vars), new_schedule)\n",
    "  return replace(self, iter_vars=tuple(new_iter_vars), schedule=new_schedule)\n",
    "\n",
    "\n",
    "Computation.split = split\n",
    "\n",
    "k, m, n = s0.iter_vars\n",
    "mo = IterVar.symbol('mo')\n",
    "mi = IterVar.symbol('mi')\n",
    "\n",
    "s0_splited = s0.split(m, mo, mi, 8)\n",
    "s0_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a80fad",
   "metadata": {},
   "source": [
    "and divide, fix the outer loop of the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ee18b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[k' = k, mo, mi = m - 8mo, no, ni = n - 128no] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -7 + m <= 8mo <= m and -127 + n <= 128no <= n }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dim_bounds(self: Computation, dim_var: str) -> tuple[isl.val, isl.val]:\n",
    "  domain = self.schedule.intersect_domain(self.domain).range()\n",
    "  return (domain.dim_min_val(self.iter_vars.index(dim_var)), domain.dim_max_val(self.iter_vars.index(dim_var)))\n",
    "\n",
    "\n",
    "Computation.dim_bounds = dim_bounds\n",
    "\n",
    "\n",
    "def divide(self: Computation, parent_var: str, outer_var: str, inner_var: str, factor: int) -> 'Computation':\n",
    "  (min_val, max_val) = self.dim_bounds(parent_var)\n",
    "  return split(self, parent_var, outer_var, inner_var, (max_val.num_si() - min_val.num_si() + 1) // factor)\n",
    "\n",
    "\n",
    "Computation.divide = divide\n",
    "\n",
    "no = IterVar.symbol('no')\n",
    "ni = IterVar.symbol('ni')\n",
    "s0_divided = s0_splited.divide(n, no, ni, 8)\n",
    "s0_divided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39461776",
   "metadata": {},
   "source": [
    "Reorder is also very simple; you just need to re-modify the order of the dimensions in the schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9fb642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, mi = m - 8mo, ni = n - 128no, k' = k] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -7 + m <= 8mo <= m and -127 + n <= 128no <= n }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reorder(self: Computation, *vars: List[int]):\n",
    "  assert len(set(vars)) == len(vars)\n",
    "  g = iter(vars)\n",
    "  new_iter_vars = [var if var not in vars else next(g) for var in self.iter_vars]\n",
    "  name = self.domain.get_tuple_name()\n",
    "  transform = isl.map(\n",
    "      f\"{{ {name}[{','.join(map(str,self.iter_vars))}] -> {name}[{','.join(map(str,new_iter_vars))}] }}\")\n",
    "  new_schedule = self.schedule.apply_range(transform)\n",
    "  new_schedule = reduce(lambda sche, p: sche.set_dim_name(\n",
    "      isl.dim_type.OUT, p[0], str(p[1])), enumerate(new_iter_vars), new_schedule)\n",
    "  return replace(self, iter_vars=tuple(new_iter_vars), schedule=new_schedule)\n",
    "\n",
    "\n",
    "Computation.reorder = reorder\n",
    "\n",
    "s0_ordered = s0_divided.reorder(mo, no, mi, ni, k)\n",
    "s0_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29459888",
   "metadata": {},
   "source": [
    "`Distribute` is a important scheduling method, and it is actually different from `parallel`. Similar to Triton's scheme of mapping loops to threads for parallelism, it usually fixes the `BLOCK SIZE` for computation, that is, the outer loop is dynamic while the inner loop is fixed, corresponding to the loop split scheduling. However, `distribute` corresponds to the situation where the number of nodes is fixed, and the size of internal tasks will change, corresponding to the loop divide scheduling. Therefore, the `distribute` scheduling fixes the outer loop through divide scheduling, and then moves the outer loop to the outermost side through reordering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27b70c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distribute(self: Computation, parent_vars: List[IterVar], outer_vars: List[IterVar], inner_vars: List[IterVar], mesh: Mesh):\n",
    "  assert self.mesh is None\n",
    "  assert len(parent_vars) == len(outer_vars) == len(inner_vars)\n",
    "  assert all(map(lambda k: k != IterKind.Distributed, self.iter_kinds.values()))\n",
    "  for i, mesh_dim in enumerate(mesh.dims):\n",
    "    self = self.divide(parent_vars[i], outer_vars[i], inner_vars[i], mesh_dim.extent)\n",
    "  self = self.reorder(chain(outer_vars, inner_vars))\n",
    "  new_iter_kinds = self.iter_kinds.copy()\n",
    "  new_iter_kinds.update({v: IterKind.Distributed for v in outer_vars})\n",
    "  return replace(self, iter_kinds=new_iter_kinds, mesh=mesh)\n",
    "\n",
    "\n",
    "Computation.distribute = distribute\n",
    "\n",
    "x, y = IterVar.range('x', 8), IterVar.range('y', 8)\n",
    "mo, no, mi, ni = IterVar.symbol('mo no mi ni')\n",
    "ko, ki = IterVar.symbol('ko ki')\n",
    "s0_distributed = s0.distribute([m, n], [mo, no], [mi, ni], Mesh((x, y))). \\\n",
    "    divide(k, ko, ki, x.extent). \\\n",
    "    reorder(mo, no, ko, mi, ni, ki)\n",
    "s0_distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ef77f",
   "metadata": {},
   "source": [
    "After defining the computation distribution, we start to consider the storage distribution. Currently, most training frameworks still use abstractions similar to [OneFlow's SBP abstraction](https://arxiv.org/pdf/2110.15032). Google has conducted in-depth research on distributed systems and proposed the [Shardy](https://openxla.org/shardy) abstraction. Compared with SBP, Shardy can support specifying the order of axis distribution. In my opinion, all the above representation methods are intended to describe the mapping relationship between data points and nodes/data points within nodes (I feel that CUTE can also describe this, but it is not as intuitive). Therefore, a map directly based on a polyhedron can support the mappings represented by the above abstractions and can also support other more complex mapping relationships.\n",
    "\n",
    "Here, I added a syntactic sugar `@` to `IterVar`. Through `shard('A', m @ x, k @ y)`, it can represent that the `m` axis of `A` is distributed incrementally on the `x` axis of the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5ba57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=(Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ C[m, n] -> C[x, y, m - 64x, local_n = n - 128y] : 0 <= m <= 511 and 0 <= n <= 1023 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))), iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class ShardAxis:\n",
    "  lhs: IterVar\n",
    "  rhs: Tuple[Expr]\n",
    "\n",
    "\n",
    "def var_shard_op(self: Expr, other: Expr | List[Expr]):\n",
    "  return ShardAxis(self, (other,) if isinstance(other, Expr) else tuple(other))\n",
    "\n",
    "\n",
    "IterVar.__matmul__ = var_shard_op\n",
    "\n",
    "\n",
    "def shard(self: Computation, buffer_name: str, *shard_axes: ShardAxis):\n",
    "  shard_axis_vars = set()\n",
    "\n",
    "  def collect_fn(e: Expr):\n",
    "    if isinstance(e, IterVar):\n",
    "      shard_axis_vars.add(e)\n",
    "\n",
    "  for shard_axis in shard_axes:\n",
    "    for rhs in shard_axis.rhs:\n",
    "      rhs.walk(collect_fn)\n",
    "    assert all(map(lambda v: v in self.mesh.dims, shard_axis_vars)\n",
    "               ), \"rhs must be in mesh dimensions\"\n",
    "    shard_axis_vars.clear()\n",
    "\n",
    "  access = next(filter(lambda acc: acc.buffer.name == buffer_name, self.accesses))\n",
    "  assert access\n",
    "  assert all([shard_axis.lhs in access.buffer.dims for shard_axis in shard_axes]\n",
    "             ), \"lhs must be in buffer dimensions\"\n",
    "  buffer = access.buffer\n",
    "  assert buffer.sharding == None, \"Buffer must not be sharded\"\n",
    "\n",
    "  def bound_fn(v): return f'{v.lower_bound} <= {v} < {v.upper_bound}'\n",
    "  sharding_map = isl.map(\n",
    "      f\"{{ {buffer.name}[{','.join(map(str, buffer.dims))}] -> {buffer.name}[{','.join(map(str, self.mesh.dims))},{','.join(map(str, buffer.dims))}] : {' and '.join(map(bound_fn, chain(self.mesh.dims, buffer.dims)))} }}\")\n",
    "\n",
    "  local = 'local_'\n",
    "  space_dims = list(map(str, chain(self.mesh.dims, buffer.dims)))\n",
    "  for shard_axis in shard_axes:\n",
    "    lhs = shard_axis.lhs\n",
    "    dim_extent = lhs.extent\n",
    "    for rhs in shard_axis.rhs:\n",
    "      match rhs:\n",
    "        # todo support expr.\n",
    "        case Expr():\n",
    "          # assert (dim_extent % rhs.extent) == 0, \"Dimension can't divide evenly\"\n",
    "          # isl.map( rhs)\n",
    "          sched_space = str(self.mesh.domain.space())[1:-1]\n",
    "          factor_map = isl.map(f'{{ {sched_space} -> [{rhs}] }}').intersect_domain(self.mesh.domain)\n",
    "          factor = factor_map.max_multi_pw_aff().at(0).max_val().num_si() - factor_map.min_multi_pw_aff().at(0).min_val().num_si() + 1\n",
    "          # .size().at(0).num_si()\n",
    "          assert dim_extent % factor == 0, \"Dimension must be divisible by sharding factor\"\n",
    "          local_dim_extent = dim_extent // factor\n",
    "          # rhs.extent\n",
    "          constraints = f'{rhs} = {lhs} // {local_dim_extent} and {local + str(lhs)} = {lhs} - {rhs} * {local_dim_extent}'\n",
    "          lhs_space = f\"{buffer.name}[{','.join(space_dims)}]\"\n",
    "          rhs_space = f\"{buffer.name}[{','.join([local + str(lhs) if dim == str(lhs) else dim for dim in space_dims])}]\"\n",
    "          sharding_map = sharding_map.apply_range(\n",
    "              isl.map(f'{{ {lhs_space} -> {rhs_space} : {constraints} }}'))\n",
    "          dim_extent = dim_extent // local_dim_extent  # update extent\n",
    "        case _:\n",
    "          raise NotImplementedError()\n",
    "  sharding_map = reduce(lambda sche, p: sche.set_dim_name(\n",
    "      isl.dim_type.OUT, p[0], str(p[1])), enumerate(self.mesh.dims), sharding_map)\n",
    "  n_access = replace(access, buffer=replace(buffer, sharding=sharding_map))\n",
    "  return replace(self, accesses=tuple([n_access if o_access.buffer.name == buffer.name else o_access for o_access in self.accesses]))\n",
    "\n",
    "\n",
    "Computation.shard = shard\n",
    "\n",
    "\n",
    "s0_sharded = s0_distributed.shard('A', m @ x, k @ y). \\\n",
    "    shard('B', k @ x, n @ y). \\\n",
    "    shard('C', m @ x, n @ y)\n",
    "s0_sharded"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "188df835",
   "metadata": {},
   "source": [
    "With computational distribution and storage distribution in place, we begin to add the most important part of communication-computation fusion: communication. By specifying loops for communication and using polyhedral analysis to obtain node/offset information of dependent data, we avoid the complexity caused by manual calculations by users. In the future, we can support promotion, allowing one communication to match multiple computations.\n",
    "\n",
    "In `communicate`, I introduced the `rotate` scheduling proposed by `Distal`. By specifying `rotate_factors`, the node IDs that the current moment depends on are dynamically changed along the time dimension. Later, combined with the ring shift communication operation, the data referenced at each moment is made local, improving computational efficiency.\n",
    "\n",
    "In this step, matrix A undergoes rotate communication, while matrix B undergoes direct communication. This corresponds to the [PUMMA](https://onlinelibrary.wiley.com/doi/10.1002/cpe.4330060702) algorithm, as shown in the figure:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38aa134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=(Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ C[m, n] -> C[x, y, m - 64x, local_n = n - 128y] : 0 <= m <= 511 and 0 <= n <= 1023 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))), iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={IterVar(name='ko', lower_bound=None, upper_bound=None, step=1): (Transfer(access=Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\")), Transfer(access=Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\")))})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def communicate(self: Computation, buffer_name: str, var: IterVar, rotate_factors: List[IterVar] = []):\n",
    "  access = next(filter(lambda acc: acc.buffer.name == buffer_name, self.accesses))\n",
    "  assert access.buffer.sharding\n",
    "  assert IterKind.Serial == self.iter_kinds.get(var, IterKind.Serial)\n",
    "  new_transfers = self.transfers.copy()\n",
    "  transed = new_transfers.get(var, ())\n",
    "  assert access not in transed\n",
    "\n",
    "  i = self.iter_vars.index(var)\n",
    "\n",
    "  access_schedule = None\n",
    "  if len(rotate_factors) > 0:\n",
    "    name = self.name()\n",
    "    extent = self.schedule.range().dim_max_val(i).num_si() + 1\n",
    "    nvar = str(var) + '_r'\n",
    "    niter_vars = tuple([*self.iter_vars[:i], nvar, *self.iter_vars[i + 1:]])\n",
    "    constraints = [f\"{nvar} = ({' + '.join(map(str, rotate_factors))} + {var}) mod {extent}\"]\n",
    "    for factor in rotate_factors + [var]:\n",
    "      i = self.iter_vars.index(factor)\n",
    "      min = self.schedule.range().dim_min_val(i).num_si()\n",
    "      max = self.schedule.range().dim_max_val(i).num_si()\n",
    "      constraints.append(f\"{min} <= {str(factor)} <= {max}\")\n",
    "    access_schedule = isl.map(\n",
    "        f\"{{ {name}[{','.join(map(str, self.iter_vars))}] -> {name}[{','.join(map(str, niter_vars))}] : {' and '.join(constraints)} }}\")\n",
    "  else:\n",
    "    access_schedule = self.schedule.range().identity()\n",
    "\n",
    "  # check validity\n",
    "  schedule_to_sharding = self.schedule.apply_range(access_schedule).apply_domain(\n",
    "      access.relation).apply_domain(access.buffer.sharding).reverse()  # schedule -> buffer\n",
    "  dist_to_shard = schedule_to_sharding.project_out(isl.dim_type.IN, i + 1, len(self.iter_vars) - i - 1). \\\n",
    "      project_out(isl.dim_type.OUT, len(self.mesh.dims),\n",
    "                  access.buffer.sharding.dim(isl.dim_type.OUT) - len(self.mesh.dims))\n",
    "  assert dist_to_shard.is_single_valued(), \"transfer can't read/write data cross multi nodes.\"\n",
    "\n",
    "  new_transfers[var] = (Transfer(access, access_schedule), *transed)\n",
    "  return replace(self, transfers=new_transfers)\n",
    "\n",
    "\n",
    "Computation.communicate = communicate\n",
    "\n",
    "s0_communicated = s0_sharded.communicate('A', ko, [no]). \\\n",
    "    communicate('B', ko)\n",
    "\n",
    "s0_communicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152963cc",
   "metadata": {},
   "source": [
    "Up to now, all the necessary components for computation have been defined, and we can start generating code. However, because transfer scheduling introduces new temporary buffers and data communication operations, supporting them in polyhedral representation is somewhat complex. This involves content related to polyhedral code generation. Early polyhedral compilation used the `2d+1` representation to mark the execution order of statements, but as programs became more complex, many maps became difficult to handle and analyze. Later, isl introduced the `schedule tree` approach, which uses a tree structure to represent the execution order of statements, making traversal and modification easier. Currently, isl supports generating ASTs from both `2d+1` representations and `schedule tree` representations. [tiramisu](http://tiramisu-compiler.org) uses the `2d+1` approach, while [akg-tvm](https://gitee.com/mindspore/akg/blob/master/src/poly/schedule_pass.cc) uses the `schedule tree` approach. Although different approaches are used, both generate isl ASTs, which are then traversed to generate platform-specific code.\n",
    "\n",
    "The IR here is not complicated, so I use `2d+1` to represent and generate the AST. The following will define some extended AST node types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24465d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpKind(IntEnum):\n",
    "  # call(Assign, dest, src)\n",
    "  Assign = 0\n",
    "  # call(Access, buffer, *(int | slice))\n",
    "  Access = 1\n",
    "  # call(Trans, commPattern, sendbuf, dest, recvbuf, source)\n",
    "  Trans = 2\n",
    "  # call(Alloc, name, *dims)\n",
    "  Alloc = 3\n",
    "  # call(Rank, *ids)\n",
    "  Rank = 4\n",
    "  # call(CommSendrecv)\n",
    "  CommSendrecv = 5\n",
    "  # call(CommBroadcast, *commGroups)\n",
    "  CommBroadcast = 6\n",
    "  # call(CommShift, *commGroups, direction)\n",
    "  CommShift = 7\n",
    "  # call(AssertEqual, a, b)\n",
    "  AssertEqual = 8\n",
    "  # call(AugAssign, dest, src)\n",
    "  AugAssign = 9\n",
    "\n",
    "  # call(Slice, begin, end)\n",
    "  Slice = 128\n",
    "  Add = 129\n",
    "  Mul = 130\n",
    "  MatMul = 131\n",
    "  MatMulTransA = 132\n",
    "\n",
    "\n",
    "def call_from(build: isl.ast_build, op: OpKind, *args: List[isl.ast_expr | str]):\n",
    "  assert isinstance(op, OpKind)\n",
    "  l = isl.ast_expr_list(len(args))\n",
    "  for i in range(len(args)):\n",
    "    match args[i]:\n",
    "      case isl.ast_expr():\n",
    "        l = l.add(args[i])\n",
    "      case int() | isl.val():\n",
    "        l = l.add(isl.ast_expr.from_val(args[i]))\n",
    "      case str():\n",
    "        l = l.add(isl.ast_expr.from_id(args[i]))\n",
    "      case isl.pw_aff():\n",
    "        l = l.add(build.expr_from(isl.pw_aff(str(args[i]))))\n",
    "      case _:\n",
    "        raise ValueError(f\"Unsupported argument type: {type(args[i])}\")\n",
    "  return isl.ast_expr.call(isl.ast_expr.from_id(op.name), l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cefa1",
   "metadata": {},
   "source": [
    "Add the analysis set of `TransferScheduleInfo, ComputationScheduleInfo` to collect information related to the conversion of the original schedule to the `2d+1` representation. Here, I have additionally added `access_schedule` to `TransferScheduleInfo` to support different access patterns, such as rotate. `access_adapt_schedule` is used to align dependencies of the same dimension. For example, when the k-dimension of matrix A is indexed by means of rotate, and the k-dimension of matrix B needs to match it for correct computation, the corresponding `access_adapt_schedule` needs to be added to matrix B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c021b8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[256ko + ki, 128no + ni] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[x, y, 256ko + ki - 256x, local_n = 128no + ni - 128y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -255 + 256ko + ki <= 256x <= 256ko + ki and 0 <= y <= 7 and -127 + 128no + ni <= 128y <= 128no + ni }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_adapt_schedule=None, box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> B[(256ko), (128no)] }\", size: \"{ B[256, 128] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransB[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 0, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransB[mo, no, ko, mi = 0, ni, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 1, mi' = 0, 0, ni' = ni, 0, ki' = ki] : 0 <= mo <= 7 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(3,))\n",
      "TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[64mo + mi, 256ko + ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[x, y, 64mo + mi - 64x, local_k = 256ko + ki - 256y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -63 + 64mo + mi <= 64x <= 64mo + mi and 0 <= y <= 7 and -255 + 256ko + ki <= 256y <= 256ko + ki }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\"), access_adapt_schedule=None, box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> A[(64mo), (256ko)] }\", size: \"{ A[64, 256] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransA[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 0, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransA[mo, no, ko, mi, ni = 0, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 1, mi' = mi, 0, ni' = 0, 0, ki' = ki] : 0 <= no <= 7 and mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(4,))\n"
     ]
    }
   ],
   "source": [
    "def get_kelly_map(self: Computation, *tps: Tuple[int, int]):\n",
    "  ndim = self.schedule.dim(isl.dim_type.OUT)\n",
    "  sche = self.schedule.range().identity()\n",
    "  d = {p[0] + 1: p[1] for p in tps}\n",
    "  for i in range(ndim):\n",
    "    sche = sche.insert_dims(isl.dim_type.OUT, i * 2,\n",
    "                            1).fix_val(isl.dim_type.OUT, i * 2, d.get(i, 0))\n",
    "  return sche.set_tuple_name(isl.dim_type.OUT, sche.get_tuple_name(isl.dim_type.IN))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class TransferScheduleInfo:\n",
    "  dim: int\n",
    "  access_map: isl.map\n",
    "  access_shard_map: isl.map  # schedule -> buffer\n",
    "  access_schedule: isl.map  # schedule -> new schedule\n",
    "  access_adapt_schedule: isl.map | None\n",
    "  box_hull: isl.fixed_box\n",
    "  alloc_schedule: isl.map\n",
    "  trans_schedule: isl.map\n",
    "  redundancies: Tuple[int, ...]\n",
    "\n",
    "  @property\n",
    "  def alloc_name(self):\n",
    "    return self.alloc_schedule.tuple_name(isl.dim_type.IN)\n",
    "\n",
    "  @property\n",
    "  def trans_name(self):\n",
    "    return self.trans_schedule.tuple_name(isl.dim_type.IN)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class ComputationScheduleInfo:\n",
    "  comp_schedule: isl.map\n",
    "  assign_kind: OpKind\n",
    "  op_kind: OpKind\n",
    "\n",
    "  @property\n",
    "  def comp_name(self):\n",
    "    return self.comp_schedule.tuple_name(isl.dim_type.IN)\n",
    "\n",
    "\n",
    "def get_transfer_schedule_info(self: Computation, transfer: Transfer, dim: int, order: int):\n",
    "  sched_domain = self.schedule.range()\n",
    "  ndim = sched_domain.n_dim()\n",
    "  access_map = self.schedule.apply_domain(transfer.access.relation).reverse()\n",
    "  access_shard_map = access_map.apply_range(transfer.access.buffer.sharding)\n",
    "  box_hull = access_map. \\\n",
    "      eliminate(isl.dim_type.IN, dim + 1, ndim - dim - 1). \\\n",
    "      range_simple_fixed_box_hull()\n",
    "\n",
    "  trans_name = OpKind.Trans.name + transfer.access.buffer.name\n",
    "  alloc_name = OpKind.Alloc.name + trans_name\n",
    "  alloc_schedule = get_kelly_map(self, (dim, order)). \\\n",
    "      intersect_domain(sched_domain). \\\n",
    "      project_out(isl.dim_type.IN, dim + 1, ndim - (dim + 1)). \\\n",
    "      set_domain_tuple(alloc_name)\n",
    "  for drop_dim in range(dim + 1, ndim):\n",
    "    alloc_schedule = alloc_schedule.fix_si(isl.dim_type.OUT, drop_dim * 2 + 1, 0)\n",
    "  order += 1\n",
    "\n",
    "  trans_schedule = get_kelly_map(self, (dim, order)). \\\n",
    "      intersect_domain(sched_domain). \\\n",
    "      set_domain_tuple(trans_name)\n",
    "\n",
    "  # find dropped dimensions\n",
    "  redundancies = []\n",
    "  cons_free_map = access_map.drop_constraints_not_involving_dims(\n",
    "      isl.dim_type.OUT, 0, len(transfer.access.buffer.dims))\n",
    "  for i in range(dim, ndim):\n",
    "    if not cons_free_map.involves_dims(isl.dim_type.IN, i, 1):\n",
    "      trans_schedule = trans_schedule.fix_si(isl.dim_type.IN, i, 0)\n",
    "      redundancies.append(i)\n",
    "\n",
    "  order += 1\n",
    "\n",
    "  return TransferScheduleInfo(dim, access_map, access_shard_map, transfer.schedule, \n",
    "                              None, box_hull, alloc_schedule, trans_schedule,\n",
    "                              tuple(redundancies))\n",
    "\n",
    "\n",
    "s0_trans_info_0 = get_transfer_schedule_info(\n",
    "    s0_communicated, s0_communicated.transfers[ko][0], 2, 0)\n",
    "s0_trans_info_1 = get_transfer_schedule_info(\n",
    "    s0_communicated, s0_communicated.transfers[ko][1], 2, 0)\n",
    "print(s0_trans_info_0)\n",
    "print(s0_trans_info_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757b75c",
   "metadata": {},
   "source": [
    "With the scheduling information, we already know the communication node/offset information. However, since the distributed backend I chose here is MPI, it is impossible to directly read and write data based on the above information, and we can only rely on the communication primitives it provides. For example, when multiple ranks need to fetch data from the same rank, the broadcast primitive must be used for normal communication; if the sendrecv primitive is used, it needs to be called multiple times with specified ranks. Therefore, it is also necessary to detect the communication mode based on the communication schedule. My approach here is to change the time dimension in which communication occurs to obtain the expression of the change in the source rank over time. If the source rank remains unchanged, it may be p2p or broadcast, and then further check whether the source rank and destination rank are bijective to determine if it is broadcast. When the source rank changes over time, we can determine whether it is a ring and the direction of the ring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5951bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast(axes=(0,))\n",
      "Shift(axes=(1,), direction=1)\n"
     ]
    }
   ],
   "source": [
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class CommPattern:\n",
    "  def build_call(self, build):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class SendRecv(CommPattern):\n",
    "  def build_call(self, build):\n",
    "    return call_from(build, OpKind.CommSendrecv)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class Broadcast(CommPattern):\n",
    "  axes: tuple[int, ...]\n",
    "\n",
    "  def build_call(self, build):\n",
    "    return call_from(build, OpKind.CommBroadcast, *self.axes)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class Shift(CommPattern):\n",
    "  axes: tuple[int, ...]\n",
    "  direction: int\n",
    "\n",
    "  def build_call(self, build):\n",
    "    return call_from(build, OpKind.CommShift, *self.axes, self.direction)\n",
    "\n",
    "\n",
    "def drop_dims(sche: isl.map | isl.aff, redundancies: Tuple[int] = ()):\n",
    "  dims = list(redundancies)\n",
    "  dims.sort()\n",
    "  j = 0\n",
    "  for i in range(len(dims)):\n",
    "    if isinstance(sche, isl.map):\n",
    "      sche = sche.project_out(isl.dim_type.IN, dims[i] - j, 1)\n",
    "    elif isinstance(sche, isl.pw_aff):\n",
    "      sche = sche.drop_dims(isl.dim_type.IN, dims[i] - j, 1)\n",
    "    else:\n",
    "      raise NotImplementedError\n",
    "    j += 1\n",
    "  return sche\n",
    "\n",
    "\n",
    "def detect_communication_pattern(self: Computation, info: TransferScheduleInfo):\n",
    "  domain_ndim = info.access_map.dim(isl.dim_type.IN)\n",
    "  shard_ndim = info.access_shard_map.dim(isl.dim_type.OUT)\n",
    "  mesh_ndim = len(self.mesh.dims)\n",
    "  comm_dim = info.dim\n",
    "  access_shard_map = info.access_shard_map.apply_domain(info.access_schedule)\n",
    "  access_src_rank = access_shard_map. \\\n",
    "      project_out(isl.dim_type.OUT, mesh_ndim, shard_ndim - mesh_ndim).\\\n",
    "      project_out(isl.dim_type.IN, info.dim + 1, domain_ndim - info.dim - 1)\n",
    "  # mesh_ndim = len(self.mesh.dims)\n",
    "  # access_shard_map = info.access_shard_map.apply_domain(info.access_schedule)\n",
    "  # cons_free_map = access_shard_map.drop_constraints_not_involving_dims(\n",
    "  #     isl.dim_type.OUT, 0, access_shard_map.dim(isl.dim_type.OUT))\n",
    "  # redundancies = []\n",
    "  # for i in range(comm_dim, cons_free_map.dim(isl.dim_type.IN)):\n",
    "  #   if not cons_free_map.involves_dims(isl.dim_type.IN, i, 1):\n",
    "  #     redundancies.append(i)\n",
    "\n",
    "  # access_src_rank = drop_dims(access_shard_map, redundancies)\n",
    "  access_src_pma = access_src_rank.as_pw_multi_aff()\n",
    "  delta_vals = ','.join(\n",
    "    ['1' if i == comm_dim else '0' for i in range(access_src_pma.dim(isl.dim_type.IN))])\n",
    "  access_next_src_pma = isl.pw_multi_aff.identity_on_domain(\n",
    "      access_src_pma.domain_space()).add_constant(isl.multi_val(f'{{[{delta_vals}]}}'))\n",
    "  src_rank_deltas = access_src_pma.pullback(access_next_src_pma).sub(access_src_pma).coalesce()\n",
    "  comm_patterns = []\n",
    "  for i in range(mesh_ndim):\n",
    "    pa = src_rank_deltas.at(i)\n",
    "    if pa.is_cst():\n",
    "      match pa.max_val().num_si():\n",
    "        case 0:  # not involved\n",
    "          comm_patterns.append(SendRecv())\n",
    "        case 1:  # changed with time.\n",
    "          if not access_src_rank.is_bijective():  # detect broadcast\n",
    "            unbounded = access_src_rank.drop_constraints_not_involving_dims(\n",
    "                isl.dim_type.OUT, 0, mesh_ndim)\n",
    "            if not unbounded.involves_dims(isl.dim_type.IN, i, 1):\n",
    "              comm_patterns.append(Broadcast((i,)))\n",
    "            else:\n",
    "              comm_patterns.append(SendRecv())\n",
    "          else:\n",
    "            comm_patterns.append(SendRecv())\n",
    "    else:\n",
    "      points = []\n",
    "      pa.as_map().range().foreach_point(lambda x: points.append(isl.set(x)))\n",
    "      points = reduce(lambda acc, x: acc.union(x), points, isl.set.empty(\n",
    "          isl.space.unit().add_dims(isl.dim_type.SET, 1)))\n",
    "      extent = self.schedule.range().dim_max_val(info.dim).num_si()\n",
    "      cw_set = isl.set(f'{{[1]; [-{extent}]}}')\n",
    "      ccw_set = isl.set(f'{{[-1]; [{extent}]}}')\n",
    "      if points.is_equal(cw_set):\n",
    "        comm_patterns.append(Shift((i,), 1))\n",
    "      elif points.is_equal(ccw_set):\n",
    "        comm_patterns.append(Shift((i,), -1))\n",
    "\n",
    "  special = sum([isinstance(p, (Broadcast, Shift)) for p in comm_patterns])\n",
    "  assert special <= 1\n",
    "  return SendRecv() if special == 0 else next(filter(lambda p: not isinstance(p, SendRecv), comm_patterns))\n",
    "\n",
    "\n",
    "print(detect_communication_pattern(s0_communicated, s0_trans_info_0))\n",
    "print(detect_communication_pattern(s0_communicated, s0_trans_info_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146c9dc",
   "metadata": {},
   "source": [
    "The previous step detected the data transmission pattern through `TransferScheduleInfo`. We still need to obtain `ComputationScheduleInfo`. This step is relatively simple; we just need to convert the original schedule into a `2d+1` representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a6589f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScheduleInfo(trans_infos=(TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[256ko + ki, 128no + ni] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[x, y, 256ko + ki - 256x, local_n = 128no + ni - 128y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -255 + 256ko + ki <= 256x <= 256ko + ki and 0 <= y <= 7 and -127 + 128no + ni <= 128y <= 128no + ni }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_adapt_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\"), box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> B[(256ko), (128no)] }\", size: \"{ B[256, 128] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransB[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 0, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransB[mo, no, ko, mi = 0, ni, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 1, mi' = 0, 0, ni' = ni, 0, ki' = ki] : 0 <= mo <= 7 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(3,)), TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[64mo + mi, 256ko + ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[x, y, 64mo + mi - 64x, local_k = 256ko + ki - 256y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -63 + 64mo + mi <= 64x <= 64mo + mi and 0 <= y <= 7 and -255 + 256ko + ki <= 256y <= 256ko + ki }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\"), access_adapt_schedule=None, box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> A[(64mo), (256ko)] }\", size: \"{ A[64, 256] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransA[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 2, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransA[mo, no, ko, mi, ni = 0, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 3, mi' = mi, 0, ni' = 0, 0, ki' = ki] : 0 <= no <= 7 and mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(4,))), comp_infos=(ComputationScheduleInfo(comp_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 4, mi' = mi, 0, ni' = ni, 0, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), assign_kind=<OpKind.AugAssign: 9>, op_kind=<OpKind.Mul: 130>),))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class ScheduleInfo:\n",
    "  trans_infos: Tuple[TransferScheduleInfo]\n",
    "  comp_infos: Tuple[ComputationScheduleInfo]\n",
    "\n",
    "\n",
    "def get_schedule_info(self: Computation):\n",
    "  transfer_sche_infos: List[TransferScheduleInfo] = []\n",
    "  used_orders = []\n",
    "  for (var, accesses) in self.transfers.items():\n",
    "    dim = self.iter_vars.index(var)\n",
    "    order = 0\n",
    "    for access in accesses:\n",
    "      transfer_sche_infos.append(get_transfer_schedule_info(self, access, dim, order))\n",
    "      order += 2\n",
    "      used_orders.append((dim, order))\n",
    "  # check dim bindings\n",
    "  for dim, dim_indices in self.dim_bindings.items():\n",
    "    worklist: List[Tuple[int, TransferScheduleInfo, AccessDimIndex]] = []\n",
    "    for dim_index in dim_indices:\n",
    "      for var, trans_infos in self.transfers.items():\n",
    "        for i, trans in enumerate(trans_infos):\n",
    "          if self.accesses[dim_index.access_idx] == trans.access:\n",
    "            worklist.append((i, transfer_sche_infos[i], dim_index))\n",
    "    # process worklist\n",
    "    if len(worklist) > 1:\n",
    "      access_dim_maps: List[isl.map] = []\n",
    "      for workitem in worklist:\n",
    "        _, trans_info, dim_index = workitem\n",
    "        access_dim_map: isl.map = trans_info.access_map.apply_domain(trans_info.access_schedule)\n",
    "        access_dim_map = access_dim_map.project_out(isl.dim_type.OUT, 0, dim_index.buffer_dim)\n",
    "        access_dim_map = access_dim_map.project_out(\n",
    "            isl.dim_type.OUT, 1, access_dim_map.dim(isl.dim_type.OUT) - 1)\n",
    "        access_dim_maps.append(access_dim_map)\n",
    "      for i in range(len(access_dim_maps) - 1):\n",
    "        # when dim not equal, add index schedule\n",
    "        if not access_dim_maps[i].is_equal(access_dim_maps[i + 1]):\n",
    "          a = worklist[i][1]\n",
    "          b = worklist[i + 1][1]\n",
    "          if a.access_schedule.is_identity():\n",
    "            assert a.access_adapt_schedule is None\n",
    "            transfer_sche_infos[worklist[i][0]] = replace(a, access_adapt_schedule=b.access_schedule)\n",
    "          elif b.access_schedule.is_identity():\n",
    "            assert b.access_adapt_schedule is None\n",
    "            transfer_sche_infos[worklist[i + 1][0]] = replace(b, access_adapt_schedule=a.access_schedule)\n",
    "          else:\n",
    "            raise ValueError(\"Incompatible access schedules\")\n",
    "\n",
    "  in_iters = set(itertools.flatten(\n",
    "      [acc.buffer.dims for acc in self.accesses if acc.buffer.usage is UsageKind.Input]))\n",
    "  out_iters = set(itertools.flatten(\n",
    "      [acc.buffer.dims for acc in self.accesses if acc.buffer.usage is UsageKind.Output]))\n",
    "\n",
    "  op_kind = None\n",
    "  match self.op:\n",
    "    case OpKind():\n",
    "      op_kind = self.op\n",
    "    case 'arith.mulf':\n",
    "      op_kind = OpKind.Mul\n",
    "    case _:\n",
    "      raise NotImplementedError()\n",
    "\n",
    "  comp_schedule = ComputationScheduleInfo(get_kelly_map(\n",
    "      self, *used_orders).intersect_domain(self.schedule.range()),\n",
    "      OpKind.AugAssign if len(in_iters) > len(out_iters) else OpKind.Assign,\n",
    "      op_kind)\n",
    "  return ScheduleInfo(tuple(transfer_sche_infos), (comp_schedule,))\n",
    "\n",
    "\n",
    "s0_schedule_info = get_schedule_info(s0_communicated)\n",
    "s0_schedule_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2705c",
   "metadata": {},
   "source": [
    "Generate the AST based on `ScheduleInfo`, and at the same time, use the above analysis to insert the required operations into the AST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea79a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int ko = 0; ko <= 7; ko += 1) {\n",
      "      Alloc(TransB, 256, 128);\n",
      "      for (int ni = 0; ni <= 127; ni += 1)\n",
      "        for (int ki = 0; ki <= 255; ki += 1)\n",
      "          Trans(CommBroadcast(0), Access(B, Slice(ki, ki + 1), Slice(ni, ni + 1)), Rank((y + ko) % 8), Access(TransB, Slice(ki, ki + 1), Slice(ni, ni + 1)), Rank(x));\n",
      "      Alloc(TransA, 64, 256);\n",
      "      for (int mi = 0; mi <= 63; mi += 1)\n",
      "        for (int ki = 0; ki <= 255; ki += 1)\n",
      "          Trans(CommShift(1, 1), Access(A, Slice(mi, mi + 1), Slice(ki, ki + 1)), Rank(x, (y + ko) % 8), Access(TransA, Slice(mi, mi + 1), Slice(ki, ki + 1)), Rank(x, y));\n",
      "      for (int mi = 0; mi <= 63; mi += 1)\n",
      "        for (int ni = 0; ni <= 127; ni += 1)\n",
      "          for (int ki = 0; ki <= 255; ki += 1)\n",
      "            AugAssign(Access(C, Slice(mi, mi + 1), Slice(ni, ni + 1)), Mul(Access(TransA, Slice(mi, mi + 1), Slice(ki, ki + 1)), Access(TransB, Slice(ki, ki + 1), Slice(ni, ni + 1))));\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lower_computation(self: Computation):\n",
    "  schedule_info = get_schedule_info(self)\n",
    "  # process tensorized\n",
    "  sched_domain = self.schedule.range()\n",
    "  sched_domain_min = self.schedule.range()\n",
    "  sched_domain_max = self.schedule.range()\n",
    "  tensorized_dims = []\n",
    "  for i, v in enumerate(self.iter_vars):\n",
    "    if self.iter_kinds.get(v) is IterKind.Tensorize:\n",
    "      sched_domain_min = sched_domain_min.fix_val(isl.dim_type.SET, i, sched_domain.dim_min_val(i))\n",
    "      sched_domain_max = sched_domain_max.fix_val(isl.dim_type.SET, i, sched_domain.dim_max_val(i))\n",
    "      tensorized_dims.append(i)\n",
    "\n",
    "  def fix_dims(sche: isl.map):\n",
    "    for d in tensorized_dims:\n",
    "      sche = sche.fix_si(isl.dim_type.OUT, (2 * d) + 1, 0)\n",
    "    return sche\n",
    "\n",
    "  def drop_dims1(sche: isl.map | isl.aff, redundancies: Tuple[int] = ()):\n",
    "    dims = list(set([*redundancies, *tensorized_dims]))\n",
    "    dims.sort()\n",
    "    j = 0\n",
    "    for i in range(len(dims)):\n",
    "      if isinstance(sche, isl.map):\n",
    "        sche = sche.project_out(isl.dim_type.IN, dims[i] - j, 1)\n",
    "      elif isinstance(sche, isl.pw_aff):\n",
    "        sche = sche.drop_dims(isl.dim_type.IN, dims[i] - j, 1)\n",
    "      else:\n",
    "        raise NotImplementedError\n",
    "      j += 1\n",
    "    return sche\n",
    "\n",
    "  def get_box(map: isl.map) -> isl.multi_val:\n",
    "    min = drop_dims1(map.intersect_domain(sched_domain_min))\n",
    "    max = drop_dims1(map.intersect_domain(sched_domain_max))\n",
    "    diff = max.as_pw_multi_aff().sub(min.as_pw_multi_aff())\n",
    "    assert diff.is_cst()\n",
    "    return diff.max_multi_val()\n",
    "\n",
    "  full_sche_map = isl.union_map.empty()\n",
    "  for info in schedule_info.comp_infos:\n",
    "    full_sche_map = full_sche_map.union(fix_dims(info.comp_schedule))\n",
    "  for info in schedule_info.trans_infos:\n",
    "    full_sche_map = full_sche_map.union(fix_dims(info.alloc_schedule))\n",
    "    full_sche_map = full_sche_map.union(fix_dims(info.trans_schedule))\n",
    "  alloc_info_map = {info.alloc_name: info for info in schedule_info.trans_infos}\n",
    "  trans_info_map = {info.trans_name: info for info in schedule_info.trans_infos}\n",
    "  comp_info_map = {info.comp_name: info for info in schedule_info.comp_infos}\n",
    "\n",
    "  def at_each_domain(node: isl.ast_node_user, build: isl.ast_build) -> isl.ast_node:\n",
    "    origin_expr = node.expr()\n",
    "    if not isinstance(origin_expr, isl.ast_expr_op_call):\n",
    "      return node\n",
    "\n",
    "    call_id: isl.ast_expr_id = origin_expr.op_arg(0)\n",
    "    call_id_name = call_id.id().name()\n",
    "    # alloc\n",
    "    if call_id_name in alloc_info_map:\n",
    "      info = alloc_info_map[call_id_name]\n",
    "      box_shape = info.box_hull.get_size()\n",
    "      rank = box_shape.size()\n",
    "      alloc = call_from(build, OpKind.Alloc, info.trans_name,\n",
    "                        *[box_shape.at(i) for i in range(rank)])\n",
    "      return isl.ast_node_user(alloc)\n",
    "\n",
    "    # trans\n",
    "    if call_id_name in trans_info_map:\n",
    "      info = trans_info_map[call_id_name]\n",
    "      pattern = detect_communication_pattern(self, info)\n",
    "      select_ranks = list(range(len(self.mesh.dims)))\n",
    "      match pattern:\n",
    "        case Broadcast():\n",
    "          select_ranks = list(filter(lambda i: i in pattern.axes, select_ranks))\n",
    "\n",
    "      def drop_dims2(x): return drop_dims1(x, info.redundancies)\n",
    "\n",
    "      src_shard_pma = info.access_shard_map.as_pw_multi_aff()\n",
    "      access_sche_pma = info.access_schedule.as_pw_multi_aff()\n",
    "      src_shard_pma = src_shard_pma.pullback(access_sche_pma)\n",
    "      if info.access_adapt_schedule:\n",
    "        src_shard_pma = src_shard_pma.pullback(info.access_adapt_schedule.as_pw_multi_aff())\n",
    "      src_rank = call_from(build, OpKind.Rank, *[drop_dims2(src_shard_pma.at(i))\n",
    "                           for i in select_ranks])\n",
    "\n",
    "      dest_rank_pma = info.access_map.domain().identity().as_pw_multi_aff()\n",
    "      dest_rank_pma = dest_rank_pma.pullback(access_sche_pma)\n",
    "      dest_rank = call_from(build, OpKind.Rank, *\n",
    "                            [drop_dims2(dest_rank_pma.at(i)) for i in select_ranks])\n",
    "\n",
    "      src_tensor_box = get_box(info.access_shard_map)\n",
    "      src_slice = call_from(build, OpKind.Access, info.access_shard_map.tuple_name(isl.dim_type.OUT),\n",
    "                            *[call_from(build, OpKind.Slice, drop_dims2(src_shard_pma.at(i)),\n",
    "                                        drop_dims2(src_shard_pma.at(i)).add_constant(src_tensor_box.at(i)).add_constant(1))\n",
    "                              for i in range(len(self.mesh.dims), src_shard_pma.dim(isl.dim_type.OUT))])\n",
    "\n",
    "      dest_start_pma = info.box_hull.get_offset().as_pw_multi_aff()\n",
    "      dest_origin_pma = info.access_map.as_pw_multi_aff()\n",
    "      dest_tensor_box = get_box(info.access_map)\n",
    "      dest_pma = dest_origin_pma.sub(dest_start_pma)\n",
    "      dest_pma = dest_pma.pullback(access_sche_pma)\n",
    "      dest_slice = call_from(build, OpKind.Access, info.trans_name,\n",
    "                             *[call_from(build, OpKind.Slice, drop_dims2(dest_pma.at(i)),\n",
    "                                         drop_dims2(dest_pma.at(i)).add_constant(dest_tensor_box.at(i)).add_constant(1))\n",
    "                               for i in range(dest_pma.size())])\n",
    "\n",
    "      trans = call_from(build, OpKind.Trans, pattern.build_call(build),\n",
    "                        src_slice, src_rank, dest_slice, dest_rank)\n",
    "      return isl.ast_node_user(trans)\n",
    "    if call_id_name in comp_info_map:\n",
    "      info = comp_info_map[call_id_name]\n",
    "      access_exprs = []\n",
    "      for access in self.accesses:\n",
    "        trans_name = OpKind.Trans.name + access.buffer.name\n",
    "        if trans_name in trans_info_map:\n",
    "          trans_info = trans_info_map[trans_name]\n",
    "          access_sche_pma = trans_info.access_schedule.as_pw_multi_aff()\n",
    "          dest_start_pma = trans_info.box_hull.get_offset().as_pw_multi_aff()\n",
    "          dest_origin_pma = trans_info.access_map.as_pw_multi_aff()\n",
    "          dest_tensor_box = get_box(trans_info.access_map)\n",
    "          dest_pma = dest_origin_pma.sub(dest_start_pma)\n",
    "          dest_pma = dest_pma.pullback(access_sche_pma)\n",
    "          access_exprs.append(call_from(build, OpKind.Access, trans_name, *\n",
    "                              [call_from(build, OpKind.Slice, drop_dims1(dest_pma.at(i)), drop_dims1(dest_pma.at(i)).add_constant(dest_tensor_box.at(i)).add_constant(1))\n",
    "                               for i in range(dest_pma.size())]))\n",
    "        else:\n",
    "          access_shard_map = self.schedule.reverse().apply_range(\n",
    "              access.relation).apply_range(access.buffer.sharding)\n",
    "          dest_shard_pma = access_shard_map.as_pw_multi_aff()\n",
    "          dest_tensor_box = get_box(access_shard_map)\n",
    "          dest_slice = call_from(build, OpKind.Access, access.buffer.name, *[\n",
    "              call_from(build, OpKind.Slice, drop_dims1(dest_shard_pma.at(i)),\n",
    "                        drop_dims1(dest_shard_pma.at(i)).add_constant(dest_tensor_box.at(i)).add_constant(1))\n",
    "              for i in range(len(self.mesh.dims), dest_shard_pma.dim(isl.dim_type.OUT))])\n",
    "          access_exprs.append(dest_slice)\n",
    "      call_expr = call_from(build, info.assign_kind,\n",
    "                            access_exprs[0],\n",
    "                            call_from(build, info.op_kind, access_exprs[1], access_exprs[2]))\n",
    "      return isl.ast_node_user(call_expr)\n",
    "    return node\n",
    "\n",
    "  builtin_iters = list(map(str, self.mesh.dims))\n",
    "\n",
    "  def at_each_for(node: isl.ast_node_for, build: isl.ast_build) -> isl.ast_node:\n",
    "    it = node.get_iterator()\n",
    "    if isinstance(it, isl.ast_expr_id) and it.id().name() in builtin_iters:\n",
    "      node = node.set_annotation(IterKind.Distributed.name)\n",
    "    return node\n",
    "\n",
    "  ast_build = isl.ast_build()\n",
    "  ast_build = ast_build.set_at_each_domain(at_each_domain)\n",
    "  ast_build = ast_build.set_after_each_for(at_each_for)\n",
    "  iter_ids = []\n",
    "  ndim = len(self.iter_vars)\n",
    "  comp_schedule = schedule_info.comp_infos[0].comp_schedule\n",
    "  iter_kinds = {k.name: v for (k, v) in self.iter_kinds.items()}\n",
    "  for i in range(ndim):\n",
    "    iter_ids.append(f'c{i}')\n",
    "    name = comp_schedule.dim_name(isl.dim_type.OUT, 2 * i + 1)\n",
    "    if iter_kinds.get(name) is IterKind.Distributed:\n",
    "      name = str(self.mesh.dims[i])\n",
    "    iter_ids.append(name)\n",
    "  ast_build = ast_build.set_iterators('(' + ','.join(iter_ids) + ')')\n",
    "  ast_node = ast_build.node_from_schedule_map(full_sche_map)\n",
    "  return ast_node\n",
    "\n",
    "\n",
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_computation = lower_computation(s0_communicated)\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.flush()\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f850cfc",
   "metadata": {},
   "source": [
    "Up to this step, we have obtained a relatively complete pseudocode. However, we can see that it is entirely loop-based, with relatively low performance. Here, we will add a `tensorize` schedule to fold the dimensions, change program to tile-based:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9793ba96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op=<OpKind.MatMul: 131>, domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=(Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ C[m, n] -> C[x, y, m - 64x, local_n = n - 128y] : 0 <= m <= 511 and 0 <= n <= 1023 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))), iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='mi', lower_bound=None, upper_bound=None, step=1): <IterKind.Tensorize: 2>, IterVar(name='ni', lower_bound=None, upper_bound=None, step=1): <IterKind.Tensorize: 2>, IterVar(name='ki', lower_bound=None, upper_bound=None, step=1): <IterKind.Tensorize: 2>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={IterVar(name='ko', lower_bound=None, upper_bound=None, step=1): (Transfer(access=Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\")), Transfer(access=Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\")))})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tensorize(self: Computation, vars: List[IterVar], new_op: OpKind = None):\n",
    "  new_kinds = self.iter_kinds.copy()\n",
    "  for var in vars:\n",
    "    assert new_kinds.get(var, None) in (None, IterKind.Serial)\n",
    "    new_kinds[var] = IterKind.Tensorize\n",
    "  if new_op:\n",
    "    self = replace(self, op=new_op)\n",
    "  return replace(self, iter_kinds=new_kinds)\n",
    "\n",
    "\n",
    "Computation.tensorize = tensorize\n",
    "\n",
    "s0_tensorized = s0_communicated.tensorize([mi, ni, ki], OpKind.MatMul)\n",
    "s0_tensorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e622a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int ko = 0; ko <= 7; ko += 1) {\n",
      "      Alloc(TransB, 256, 128);\n",
      "      Trans(CommBroadcast(0), Access(B, Slice(0, 256), Slice(0, 128)), Rank((y + ko) % 8), Access(TransB, Slice(0, 256), Slice(0, 128)), Rank(x));\n",
      "      Alloc(TransA, 64, 256);\n",
      "      Trans(CommShift(1, 1), Access(A, Slice(0, 64), Slice(0, 256)), Rank(x, (y + ko) % 8), Access(TransA, Slice(0, 64), Slice(0, 256)), Rank(x, y));\n",
      "      AugAssign(Access(C, Slice(0, 64), Slice(0, 128)), MatMul(Access(TransA, Slice(0, 64), Slice(0, 256)), Access(TransB, Slice(0, 256), Slice(0, 128))));\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_computation = lower_computation(s0_tensorized)\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.flush()\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaaa38c",
   "metadata": {},
   "source": [
    "Now we have obtained the AST for the calculation part. To enable it to execute properly, we still need to prepare the input and output. Here, I will directly generate code for `Access`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a31144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alloc(C, 64, 128);\n",
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int m = 0; m <= 63; m += 1)\n",
      "      for (int n = 0; n <= 127; n += 1)\n",
      "        AssertEqual(Access(C, m, n), Access(GlobalC, 64 * x + m, 128 * y + n));\n",
      "Alloc(A, 64, 256);\n",
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int m = 0; m <= 63; m += 1)\n",
      "      for (int k = 0; k <= 255; k += 1)\n",
      "        Assign(Access(A, m, k), Access(GlobalA, 64 * x + m, 256 * y + k));\n",
      "Alloc(B, 256, 128);\n",
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int k = 0; k <= 255; k += 1)\n",
      "      for (int n = 0; n <= 127; n += 1)\n",
      "        Assign(Access(B, k, n), Access(GlobalB, 256 * x + k, 128 * y + n));\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lower_shard(self: Computation, access: Access) -> Tuple[isl.ast_build, isl.ast_build]:\n",
    "  sharding = access.buffer.sharding\n",
    "  assert sharding\n",
    "  builtin_iters = list(map(str, self.mesh.dims))\n",
    "\n",
    "  access_global_map = sharding.reverse().set_tuple_id(\n",
    "      isl.dim_type.OUT, 'Global' + access.buffer.name)\n",
    "\n",
    "  redundancies = []\n",
    "  cons_free_map = access_global_map.drop_constraints_not_involving_dims(\n",
    "      isl.dim_type.OUT, 0, access_global_map.dim(isl.dim_type.OUT))\n",
    "  for i in range(0, access_global_map.dim(isl.dim_type.IN)):\n",
    "    if not cons_free_map.involves_dims(isl.dim_type.IN, i, 1):\n",
    "      redundancies.append(i)\n",
    "\n",
    "  access_global_pma = access_global_map.as_pw_multi_aff()\n",
    "  access_global_domain = sharding.reverse().domain()\n",
    "  buffer_local_shape = access_global_domain.project_out(\n",
    "      isl.dim_type.SET, 0, len(self.mesh.dims)).simple_fixed_box_hull().size()\n",
    "  access_local_map = sharding.reverse().domain().identity().project_out(\n",
    "      isl.dim_type.OUT, 0, len(self.mesh.dims)).set_range_tuple(access.buffer.name)\n",
    "  access_local_pma = access_local_map.as_pw_multi_aff()\n",
    "\n",
    "  ast_build = isl.ast_build()\n",
    "\n",
    "  def at_each_domain(node: isl.ast_node_user, build: isl.ast_build) -> isl.ast_node:\n",
    "    \n",
    "    access_global = call_from(build, OpKind.Access, access_global_pma.tuple_name(\n",
    "        isl.dim_type.OUT), *[drop_dims(access_global_pma.at(i), redundancies) for i in range(access_global_pma.size())])\n",
    "    access_local = call_from(build, OpKind.Access, access_local_pma.tuple_name(\n",
    "        isl.dim_type.OUT), *[drop_dims(access_local_pma.at(i), redundancies) for i in range(access_local_pma.size())])\n",
    "\n",
    "    call = call_from(build, OpKind.Assign if access.buffer.usage ==\n",
    "                     UsageKind.Input else OpKind.AssertEqual, access_local, access_global)\n",
    "    return isl.ast_node_user(call)\n",
    "\n",
    "  def at_each_for(node: isl.ast_node_for, build: isl.ast_build) -> isl.ast_node:\n",
    "    it = node.get_iterator()\n",
    "    if isinstance(it, isl.ast_expr_id) and it.id().name() in builtin_iters:\n",
    "      node = node.set_annotation(IterKind.Distributed.name)\n",
    "    return node\n",
    "\n",
    "  ast_build = ast_build.set_at_each_domain(at_each_domain)\n",
    "  ast_build = ast_build.set_after_each_for(at_each_for)\n",
    "  ast_build = ast_build.set_iterators(\n",
    "      '(' + ', '.join(map(str, chain(self.mesh.dims, access.buffer.dims))) + ')')\n",
    "  ast_node = ast_build.node_from_schedule_map(sharding.range().identity())\n",
    "  alloc = isl.ast_node_user(call_from(ast_build, OpKind.Alloc, access.buffer.name, *\n",
    "                                      [buffer_local_shape.at(i) for i in range(buffer_local_shape.size())]))\n",
    "  return (alloc, ast_node)\n",
    "\n",
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_shard_buffer_0 = lower_shard(s0_communicated, s0_communicated.accesses[0])\n",
    "  ast_shard_buffer_1 = lower_shard(s0_communicated, s0_communicated.accesses[1])\n",
    "  ast_shard_buffer_2 = lower_shard(s0_communicated, s0_communicated.accesses[2])\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_shard_buffer_0[0].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_0[1].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_1[0].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_1[1].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_2[0].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_2[1].print(printer, print_options)\n",
    "  printer.flush()\n",
    "  \n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c0727",
   "metadata": {},
   "source": [
    "After having all the ASTs, it is necessary to generate the corresponding backend code. ISL provides a printer for users, and I have added a Python-style printer implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d25adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_python_style_item(printer: isl.printer, item: isl.ast_expr | str):\n",
    "  match item:\n",
    "    case str():\n",
    "      printer.print_str(item)\n",
    "    case isl.ast_expr():\n",
    "      expr = item\n",
    "      match expr:\n",
    "        case isl.ast_expr_op_call():\n",
    "          op_name = expr.get_op_arg(0).id().name()\n",
    "          match op_name:\n",
    "            case OpKind.Access.name:\n",
    "              print_python_style_item(printer, expr.get_op_arg(1))  # buffer name\n",
    "              printer.print_str(\"[\")\n",
    "              for i in range(2, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(\"]\")\n",
    "            case OpKind.Rank.name:\n",
    "              printer.print_str(\"[\")\n",
    "              for i in range(1, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(\"]\")\n",
    "            case OpKind.Assign.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" = \", expr.get_op_arg(2))\n",
    "            case OpKind.AugAssign.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" += \", expr.get_op_arg(2))\n",
    "            case OpKind.Slice.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \":\", expr.get_op_arg(2))\n",
    "              if expr.op_n_arg() > 3:\n",
    "                printer.print_str(\":\")\n",
    "                print_python_style_item(printer, expr.get_op_arg(3))\n",
    "            case OpKind.Alloc.name:\n",
    "              print_python_style_item(printer, expr.get_op_arg(1))\n",
    "              printer.print_str(\" = np.zeros([\")\n",
    "              for i in range(2, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(\"])\")\n",
    "            case OpKind.AssertEqual.name:\n",
    "              print_python_style_items(printer, \"assert np.allclose(\", expr.get_op_arg(1), \", \", expr.get_op_arg(2), \")\")\n",
    "            case OpKind.Trans.name:\n",
    "              printer.print_str(op_name)\n",
    "              printer.print_str('(')\n",
    "              for i in range(1, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(')')\n",
    "            case OpKind.Mul.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" * \", expr.get_op_arg(2))\n",
    "            case OpKind.MatMul.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" @ \", expr.get_op_arg(2))\n",
    "            case OpKind.MatMulTransA.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \".T\", \" @ \", expr.get_op_arg(2))\n",
    "            case OpKind.CommShift.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(0), \"(\")\n",
    "              print_python_style_item(printer, '(')\n",
    "              for i in range(1, expr.op_n_arg() - 1):\n",
    "                print_python_style_items(printer, expr.get_op_arg(i), ',')\n",
    "              print_python_style_item(printer, '),')\n",
    "              print_python_style_item(printer, expr.get_op_arg(expr.op_n_arg() - 1))\n",
    "              print_python_style_item(printer, ')')\n",
    "            case _:\n",
    "              printer.print_ast_expr(expr)\n",
    "        case _:\n",
    "          printer.print_ast_expr(expr)\n",
    "    case _:\n",
    "      raise NotImplementedError()\n",
    "\n",
    "\n",
    "def print_python_style_items(printer: isl.printer, *items: List[isl.ast_expr | str]):\n",
    "  for item in items:\n",
    "    print_python_style_item(printer, item)\n",
    "\n",
    "\n",
    "def print_python_style_user(printer: isl.printer, options: isl.ast_print_options, node: isl.ast_node):\n",
    "  expr: isl.ast_expr = node.get_expr()\n",
    "  printer.start_line()\n",
    "  print_python_style_item(printer, expr)\n",
    "  printer.end_line()\n",
    "  return printer\n",
    "\n",
    "\n",
    "def print_python_style_for(printer: isl.printer, options: isl.ast_print_options, node: isl.ast_node_for):\n",
    "  (it, init, cond, inc) = node.get_iterator(), node.get_init(), node.get_cond(), node.get_inc()\n",
    "  omit = False\n",
    "  try:\n",
    "    anno = node.annotation()\n",
    "    if anno.name() == IterKind.Distributed.name:\n",
    "      omit = True\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  if not omit:\n",
    "    printer.start_line()\n",
    "    print_python_style_items(printer, \"for \", it, \" in range(\", init,\n",
    "                             \", \", cond.get_arg(1), \" + 1\", \", \", inc, \"):\\n\")\n",
    "    printer = printer.indent(4)\n",
    "  printer = node.get_body().print(printer, options)\n",
    "  if not omit:\n",
    "    printer = printer.indent(-4)\n",
    "  return printer\n",
    "\n",
    "\n",
    "def print_python_style_block(printer: isl.printer, options: isl.ast_print_options, node: isl.ast_node_block):\n",
    "  children = node.get_children()\n",
    "  for i in range(children.size()):\n",
    "    printer = children.get_at(i).print(printer, options)\n",
    "  return printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4325608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ko in range(0, 7 + 1, 1):\n",
      "    TransB = np.zeros([256,128])\n",
      "    Trans(CommBroadcast(0),B[0:256,0:128],[(y + ko) % 8],TransB[0:256,0:128],[x])\n",
      "    TransA = np.zeros([64,256])\n",
      "    Trans(CommShift((1,),1),A[0:64,0:256],[x,(y + ko) % 8],TransA[0:64,0:256],[x,y])\n",
      "    C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_computation = lower_computation(s0_tensorized)\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  print_options = print_options.set_print_for(print_python_style_for)\n",
    "  print_options = print_options.set_print_user(print_python_style_user)\n",
    "  print_options = print_options.set_print_block(print_python_style_block)\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.flush()\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679c62d",
   "metadata": {},
   "source": [
    "During the process of generating the AST, I used a unified communication operation API. These APIs, along with some setup code, need to be implemented in the runtime. However, they are not included in the compilation process. For simplicity, I handled this by directly constructing strings and writing them into files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52544aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codegen_setup(self: Computation, printer: isl.printer) -> isl.printer:\n",
    "  printer.print_str('import numpy as np\\n')\n",
    "  printer.print_str('from mpi4py import MPI\\n')\n",
    "  printer.print_str('from enum import IntEnum\\n')\n",
    "  printer.print_str('import sys\\n')\n",
    "  printer.print_str('RANK = MPI.COMM_WORLD.Get_rank()\\n')\n",
    "  printer.print_str(f'MESH = [{\",\".join(map(str, self.mesh.shape))}]\\n')\n",
    "  printer.print_str(f'COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\\n')\n",
    "  printer.print_str(f\"({','.join(map(str, self.mesh.dims))},) = PIDS = COMM_ALL.Get_coords(RANK)\\n\")\n",
    "\n",
    "  printer.print_str(f\"\"\"\n",
    "\n",
    "class CommBroadcast:\n",
    "  def __init__(self, *axes: int):\n",
    "    self.axes: tuple[int] = axes\n",
    "\n",
    "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
    "    src_rank = comm.Get_cart_rank(source)\n",
    "    if comm.Get_rank() == src_rank:\n",
    "      np.copyto(recvbuf, srcbuf)\n",
    "    comm.Bcast(recvbuf, root=src_rank)\n",
    "\n",
    "class CommShift:\n",
    "  def __init__(self, axes: tuple[int], delta: int):\n",
    "    self.axes: tuple[int] = axes\n",
    "    self.delta: int = delta\n",
    "\n",
    "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
    "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
    "      src_rank = COMM_ALL.Get_cart_rank(\n",
    "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
    "      dest_rank = COMM_ALL.Get_cart_rank(\n",
    "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
    "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
    "    np.copyto(recvbuf, srcbuf)\n",
    "\n",
    "\n",
    "class CommSendrecv:\n",
    "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
    "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
    "\n",
    "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "  comm(srcbuf, source, recvbuf, dest)\n",
    "\n",
    "\"\"\")\n",
    "  return printer\n",
    "\n",
    "\n",
    "def codegen_computation(self: Computation, printer: isl.printer, ast_computation: isl.ast_node):\n",
    "  printer.print_str(f\"def computation({', '.join([a.buffer.name for a in self.accesses])}):\\n\")\n",
    "  printer.set_indent(4)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.set_indent(-4)\n",
    "  printer.end_line()\n",
    "  return printer\n",
    "\n",
    "\n",
    "def codegen_main(self: Computation, printer: isl.printer, ast_inputs: List[isl.ast_node], ast_outputs: List[isl.ast_node]):\n",
    "  printer.print_str('if __name__ == \"__main__\":\\n')\n",
    "  for i, access in enumerate(self.accesses):\n",
    "    printer.print_str(\n",
    "        f'    Global{access.buffer.name} = np.load(sys.argv[{i + 1}], mmap_mode=\"r\")\\n')\n",
    "\n",
    "  printer.set_indent(4)\n",
    "  for in_ast in ast_inputs:\n",
    "    printer = in_ast[0].print(printer, print_options)\n",
    "    printer = in_ast[1].print(printer, print_options)\n",
    "  for out_ast in ast_outputs:\n",
    "    printer = out_ast[0].print(printer, print_options)\n",
    "  printer.print_str(f\"    computation({', '.join([a.buffer.name for a in self.accesses])})\\n\")\n",
    "  for out_ast in ast_outputs:\n",
    "    printer = out_ast[1].print(printer, print_options)\n",
    "  printer.print_str(\"    print(f\\\"rank [{','.join(map(str,PIDS))}] passed!\\\")\")\n",
    "  printer.set_indent(-4)\n",
    "  printer.end_line()\n",
    "  return printer\n",
    "\n",
    "\n",
    "def codegen_full(self: Computation, f: FileIO, ast_inputs: List[isl.ast_node], ast_outputs: List[Tuple[isl.ast_node, isl.ast_node]], ast_computation: isl.ast_node):\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  print_options = print_options.set_print_for(print_python_style_for)\n",
    "  print_options = print_options.set_print_user(print_python_style_user)\n",
    "  print_options = print_options.set_print_block(print_python_style_block)\n",
    "  printer.set_output_format(isl.format.C)\n",
    "\n",
    "  printer = codegen_setup(self, printer)\n",
    "  printer = codegen_computation(self, printer, ast_computation)\n",
    "  printer = codegen_main(self, printer, ast_inputs, ast_outputs)\n",
    "\n",
    "  printer.flush()\n",
    "\n",
    "\n",
    "def lower_and_codegen(self: Computation, f: FileIO):\n",
    "  ast_shard_inputs = [lower_shard(self, access)\n",
    "                      for access in self.accesses if access.buffer.usage == UsageKind.Input]\n",
    "  ast_shard_outputs = [lower_shard(self, access)\n",
    "                       for access in self.accesses if access.buffer.usage == UsageKind.Output]\n",
    "  ast_computation = lower_computation(self)\n",
    "  codegen_full(self, f, ast_shard_inputs, ast_shard_outputs, ast_computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd7e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [8,8]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,y,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for ko in range(0, 7 + 1, 1):\n",
      "        TransB = np.zeros([256,128])\n",
      "        Trans(CommBroadcast(0),B[0:256,0:128],[(y + ko) % 8],TransB[0:256,0:128],[x])\n",
      "        TransA = np.zeros([64,256])\n",
      "        Trans(CommShift((1,),1),A[0:64,0:256],[x,(y + ko) % 8],TransA[0:64,0:256],[x,y])\n",
      "        C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([64,256])\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for k in range(0, 255 + 1, 1):\n",
      "            A[m,k] = GlobalA[64 * x + m,256 * y + k]\n",
      "    B = np.zeros([256,128])\n",
      "    for k in range(0, 255 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            B[k,n] = GlobalB[256 * x + k,128 * y + n]\n",
      "    C = np.zeros([64,128])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[64 * x + m,128 * y + n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"tmp/pumma.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f636fa1",
   "metadata": {},
   "source": [
    "Start creating inputs and executing the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8101555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arrA = np.random.rand(512, 2048).astype(np.float32)\n",
    "arrB = np.random.rand(2048, 1024).astype(np.float32)\n",
    "np.save(\"tmp/arrA.npy\", arrA)\n",
    "np.save(\"tmp/arrB.npy\", arrB)\n",
    "np.save(\"tmp/arrC.npy\", arrA @ arrB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27053ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 64 python tmp/pumma.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f95a20",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "I would like to share some thoughts while implementing the above functions:\n",
    "1. Computational scheduling and distributed storage scheduling influence each other. For example, in the Cannon algorithm, the correct data distribution and the ring communication method are interdependent; the absence of either will lead to incorrect results. This actually greatly limits the schedule language because many special distributed computing methods are difficult to schedule step by step from the original index notation.\n",
    "2. Currently, most hardware is tile-based. The process from index notation to polyhedral representation and then to the tensor level introduces a very complex index processing procedure. In the future, scheduling optimization should be carried out directly on the basis of tiles in conjunction with polyhedrons.\n",
    "3. Although introducing a backend that supports arbitrary communication will expand the scheduling search domain, in fact, high-performance communication modes are still several commonly used ones, and ultimately, they should be offloaded similarly to coalesced memory access.\n",
    "4. AI compilers can consider building a search domain based on ring/broadcast/p2p communication methods. The main difficulty here should be how to adjust the mapping between the time dimension and the distributed dimension.\n",
    "5. The new paper by the author of distal, [Task-Based Tensor Computations on Modern GPUs](https://rohany.github.io/publications/pldi2025-cypress.pdf), is also an excellent solution and worth learning from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708732b9",
   "metadata": {},
   "source": [
    "# Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94340e31",
   "metadata": {},
   "source": [
    "## AllGather + Gemm\n",
    "\n",
    "Referring to NVIDIA's [cublasmp documentation](https://docs.nvidia.com/cuda/cublasmp/usage/tp.html), the computational process is expressed using index notation as `C[m @ x,n] = A[k,m @ x].T @ B[k,n @ x]`. That is, the `m/n` dimensions of matrices `A/B` are distributed over a one-dimensional topology, but only the `m` dimension of the output `C` is distributed. Therefore, the computation depends on all data in the `n` dimension. A naive computation method is to collect the complete `B` matrix on each process via `AllGather`, and then perform the operation `C[m @ x, n] = A[k, m @ x].T @ B[k, n]` to obtain the result.\n",
    "\n",
    "However, in this paper, through polyhedral analysis, it is only necessary for the user to specify communication during iteration over the `n` dimension, and the correct `B` matrix can be automatically loaded during computation for the operation, achieving communication-computation fusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd2e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ctx.parse_program\n",
    "def ag_matmul(A: Buffer[float, [1024, 2048]], B: Buffer[float, [1024, 4096]], C: Buffer[float, [2048, 4096]], m: IterVar, n: IterVar, k: IterVar) -> Buffer[float, [2048, 4096]]:\n",
    "  C[m, n] = A[k, m] * B[k, n]\n",
    "  return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f2f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [4]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for no in range(0, 3 + 1, 1):\n",
      "        TransB = np.zeros([1024,1024])\n",
      "        Trans(CommBroadcast(0),B[0:1024,0:1024],[no],TransB[0:1024,0:1024],[x])\n",
      "        C[0:512,1024 * no:1024 * no + 1024] += A[0:1024,0:512].T @ TransB[0:1024,0:1024]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([1024,512])\n",
      "    for k in range(0, 1023 + 1, 1):\n",
      "        for m in range(0, 511 + 1, 1):\n",
      "            A[k,m] = GlobalA[k,512 * x + m]\n",
      "    B = np.zeros([1024,1024])\n",
      "    for k in range(0, 1023 + 1, 1):\n",
      "        for n in range(0, 1023 + 1, 1):\n",
      "            B[k,n] = GlobalB[k,1024 * x + n]\n",
      "    C = np.zeros([512,4096])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 511 + 1, 1):\n",
      "        for n in range(0, 4095 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[512 * x + m,n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s0 = polyhedron_extract(ag_matmul) # extract to polyhedron.\n",
    "\n",
    "k, m, n = s0.iter_vars\n",
    "x = IterVar.range('x', 4) # mesh axis\n",
    "\n",
    "no, ni, mo, mi = IterVar.symbol('no ni mo mi')\n",
    "s0_tensorized = s0.distribute([m], [mo], [mi], Mesh((x,))). \\\n",
    "    divide(n, no, ni, x.extent). \\\n",
    "    reorder(mo, no, mi, ni, k). \\\n",
    "    shard('A', m @ x).shard('B', n @ x).shard('C', m @ x). \\\n",
    "    communicate('B', no). \\\n",
    "    tensorize([mi, ni, k], OpKind.MatMulTransA)\n",
    "\n",
    "with open(\"tmp/ag_matmul.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/ag_matmul.py', 'r') as f:\n",
    "  print(f.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93a0b9",
   "metadata": {},
   "source": [
    "Construct input and output using numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec080f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m, k, n = 2048, 1024, 4096\n",
    "arrA = np.random.randn(k, m)\n",
    "arrB = np.random.randn(k, n)\n",
    "np.save(\"tmp/arrA.npy\", arrA)\n",
    "np.save(\"tmp/arrB.npy\", arrB)\n",
    "np.save(\"tmp/arrC.npy\", arrA.T @ arrB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de1c8a",
   "metadata": {},
   "source": [
    "and verified using mpi4py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae37b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 4 python tmp/ag_matmul.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641466b9",
   "metadata": {},
   "source": [
    "## SUMMA\n",
    "\n",
    "For detailed information about SUMMA, you can refer to my previous article: [Matrix Multiplication and Compilers in Distributed Storage Architecture](https://zhen8838.github.io/2024/11/07/mesh-matmul/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3025f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [8,8]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,y,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for ko in range(0, 7 + 1, 1):\n",
      "        TransB = np.zeros([256,128])\n",
      "        Trans(CommBroadcast(0),B[0:256,0:128],[ko],TransB[0:256,0:128],[x])\n",
      "        TransA = np.zeros([64,256])\n",
      "        Trans(CommBroadcast(1),A[0:64,0:256],[ko],TransA[0:64,0:256],[y])\n",
      "        C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([64,256])\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for k in range(0, 255 + 1, 1):\n",
      "            A[m,k] = GlobalA[64 * x + m,256 * y + k]\n",
      "    B = np.zeros([256,128])\n",
      "    for k in range(0, 255 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            B[k,n] = GlobalB[256 * x + k,128 * y + n]\n",
      "    C = np.zeros([64,128])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[64 * x + m,128 * y + n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@ctx.parse_program\n",
    "def matmul(A: Buffer[float, [512, 2048]], B: Buffer[float, [2048, 1024]], C: Buffer[float, [512, 1024]], m: IterVar, n: IterVar, k: IterVar) -> Buffer[float, [512, 1024]]:\n",
    "  C[m, n] = A[m, k] * B[k, n]\n",
    "  return C\n",
    "  \n",
    "s0 = polyhedron_extract(matmul)\n",
    "\n",
    "k, m, n = s0.iter_vars\n",
    "x, y = IterVar.range('x', 8), IterVar.range('y', 8)\n",
    "mo, no, mi, ni = IterVar.symbol('mo no mi ni')\n",
    "ko, ki = IterVar.symbol('ko ki')\n",
    "s0_tensorized = s0.distribute([m, n], [mo, no], [mi, ni], Mesh((x, y))). \\\n",
    "    divide(k, ko, ki, x.extent). \\\n",
    "    reorder(mo, no, ko, mi, ni, ki). \\\n",
    "    shard('A', m @ x, k @ y). \\\n",
    "    shard('B', k @ x, n @ y). \\\n",
    "    shard('C', m @ x, n @ y). \\\n",
    "    communicate('A', ko). \\\n",
    "    communicate('B', ko). \\\n",
    "    tensorize([mi, ni, ki], OpKind.MatMul)\n",
    "\n",
    "with open(\"tmp/summa.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/summa.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820be2c",
   "metadata": {},
   "source": [
    "Use numpy to construct input and output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36bdabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m, k, n = 512, 2048, 1024\n",
    "arrA = np.random.randn(m, k)\n",
    "arrB = np.random.randn(k, n)\n",
    "np.save(\"tmp/arrA.npy\", arrA)\n",
    "np.save(\"tmp/arrB.npy\", arrB)\n",
    "np.save(\"tmp/arrC.npy\", arrA @ arrB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e9efa",
   "metadata": {},
   "source": [
    "and verified using mpi4py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12281d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 64 python tmp/summa.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ab9cf",
   "metadata": {},
   "source": [
    "## Cannon\n",
    "\n",
    "For detailed information about Cannon, you can refer to my previous article: [Matrix Multiplication and Compilers in Distributed Storage Architecture](https://zhen8838.github.io/2024/11/07/mesh-matmul/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "121e53d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [8,8]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,y,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for ko in range(0, 7 + 1, 1):\n",
      "        TransB = np.zeros([256,128])\n",
      "        Trans(CommShift((0,),1),B[0:256,0:128],[(x + ko) % 8,y],TransB[0:256,0:128],[x,y])\n",
      "        TransA = np.zeros([64,256])\n",
      "        Trans(CommShift((1,),1),A[0:64,0:256],[x,(y + ko) % 8],TransA[0:64,0:256],[x,y])\n",
      "        C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([64,256])\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for k in range(0, 255 + 1, 1):\n",
      "            A[m,k] = GlobalA[64 * x + m,(256 * x + 256 * y + k) % 2048]\n",
      "    B = np.zeros([256,128])\n",
      "    for k in range(0, 255 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            B[k,n] = GlobalB[(256 * x + 256 * y + k) % 2048,128 * y + n]\n",
      "    C = np.zeros([64,128])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[64 * x + m,128 * y + n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k, m, n = s0.iter_vars\n",
    "x, y = IterVar.range('x', 8), IterVar.range('y', 8)\n",
    "mo, no, mi, ni = IterVar.symbol('mo no mi ni')\n",
    "ko, ki = IterVar.symbol('ko ki')\n",
    "s0_tensorized = s0.distribute([m, n], [mo, no], [mi, ni], Mesh((x, y))). \\\n",
    "    divide(k, ko, ki, x.extent). \\\n",
    "    reorder(mo, no, ko, mi, ni, ki). \\\n",
    "    shard('A', m @ x, k @ ((x + y) % 8)). \\\n",
    "    shard('B', k @ ((x + y) % 8), n @ y). \\\n",
    "    shard('C', m @ x, n @ y). \\\n",
    "    communicate('A', ko, [mo, no]). \\\n",
    "    communicate('B', ko, [mo, no]). \\\n",
    "    tensorize([mi, ni, ki], OpKind.MatMul)\n",
    "\n",
    "with open(\"tmp/cannon.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/cannon.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26981d50",
   "metadata": {},
   "source": [
    "Reuse the data from summa and verify it using mpi4py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 64 python tmp/cannon.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
