{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0cb2fae",
   "metadata": {},
   "source": [
    "# 前言\n",
    "\n",
    "随着AI workload对于算力的需求激增，且单位芯片的性能/频率提升趋缓，以及大模型/大图/大表需要巨量容量与带宽遇到的内存墙与带宽墙问题，未来硬件逐渐向scale out的方向发展，比如多GPU/多chip/多die等方向。在硬件scale up之后AI软件遇到的挑战则是从单节点内的计算分布扩展到多个节点的存储分布，以及数据依赖带来的通信开销问题。\n",
    "\n",
    "我认为硬件横向扩展的组合会更加千变万化，在不同的拓扑组合下通过人力构建高度优化的Kernel会变得更加困难，因此通过AI编译自动生成分布式计算Kernel的技术会变得重要。\n",
    "\n",
    "在以上背景下，我原本想尝试通过AI编译技术自动搜索符合计算/存储分布的Kernel实现，但目前受限于技术水平还做不到。因此退而求其次尝试使用多面体编译对分布式计算进行建模，分析并筛选出合法的实现为后续自动化打下基础。总之，本文采用Compute Schedule分离的方式，配合多面体技术，构建一个通算融合的DSL，可以帮助大家更好的理解计算分布/存储分布的关系，同时也是对于多面体编译技术一个更加整体的使用样例。\n",
    "\n",
    "注意:\n",
    "1. 本文大量参考[Distal](https://arxiv.org/abs/2203.08069)论文启发，可以先查看[这里](https://zhen8838.github.io/2025/02/04/distal/)补充预备知识。 distal实际上是依托于开发许久的[legion项目](https://legion.stanford.edu/publications/), `legion`在runtime中实现了一套domain/point的类多面体映射方案，因此可以相对简单的进行各种形式的通信。而本文为了做到最小依赖，通过多面体分析的方式把通信模式识别出来并offload到MPI后端，这是主要区别。\n",
    "2. 如果有类似[SymmetricMemory](https://www.youtube.com/watch?v=DdQm-tUf0d8)的后端，可以简化复杂的通信模式识别。\n",
    "3. 本文目前只实现了单一层级拓扑的代码生成，对于多级拓扑的适配还需要继续探索。\n",
    "4. 本文目前实现了通算融合，对于通信计算overlap的需求，需要切换到可异步通信的后端，并且配合NBuffer/SoftPipeLine的编译优化来实现，读者们可以尝试修改实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543539c9",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6af8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Tuple, Union, TextIO, List, Dict, Optional, Any, Callable, Sequence, cast, NamedTuple\n",
    "\n",
    "from io import FileIO\n",
    "from dataclasses import dataclass, replace, field\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "import more_itertools as itertools\n",
    "from enum import IntEnum\n",
    "from xdsl.dialects import arith, builtin, tensor, linalg, func\n",
    "from xdsl.frontend.pyast.context import PyASTContext, TypeRegistry\n",
    "from xdsl.frontend.pyast.code_generation import CodeGeneration, CodeGenerationVisitor\n",
    "from xdsl import ir\n",
    "from xdsl.irdl import irdl_op_definition, IRDLOperation, prop_def, result_def, operand_def, var_operand_def, attr_def\n",
    "from xdsl import passes\n",
    "import dowhen\n",
    "import isl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84921521",
   "metadata": {},
   "source": [
    "为了实现一个比较完整的DSL，前端必不可少，正好最近[xDSL](https://github.com/xdslproject/xdsl)提供了一套简化的前端方案[xDSL front-end: Embedding MLIR into Python](https://github.com/xdslproject/xdsl/tree/v0.48.3/xdsl/frontend/pyast)。虽然有许多不完善的地方，但是在python中我们可以通过[dowhen](https://github.com/gaogaotiantian/dowhen)库对xDSL进行 monkey patch，从而补充上不完善的功能。\n",
    "\n",
    "xDSL的逻辑是通过`TypeRegistry`把python的类型和MLIR的类型进行桥接，然后通过预先提供的`CodeGenerationVisitor`遍历生成。但是他目前并不支持 type annotation 带有参数的情况，比如`Buffer[float, [2048, 1024]]`, 我通过自定义的`ParameterizedTypeRegistry`解决了这个问题。 同时他默认的`CodeGenerationVisitor`不支持一些ast的visit，我通过`MyCodeGenVisitor`进行了支持。扩展这些实现后，通过`dowhen`库替换了xDSL内部一些调用的地方，成功构建了一个基于index notation的前端。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "577522f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builtin.module {\n",
      "  func.func @matmul(%A : memref<512x2048xf32>, %B : memref<2048x1024xf32>, %C : memref<512x1024xf32>, %m : index, %n : index, %k : index) -> memref<512x1024xf32> {\n",
      "    %0 = \"buffer.access\"(%C, %m, %n) : (memref<512x1024xf32>, index, index) -> f32\n",
      "    %1 = \"buffer.access\"(%B, %k, %n) : (memref<2048x1024xf32>, index, index) -> f32\n",
      "    %2 = \"buffer.access\"(%A, %m, %k) : (memref<512x2048xf32>, index, index) -> f32\n",
      "    %3 = arith.mulf %2, %1 : f32\n",
      "    \"tensor.assign\"(%0, %3) : (f32, f32) -> ()\n",
      "    func.return %C : memref<512x1024xf32>\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ParameterizedTypeRegistry(TypeRegistry):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self._generic_mapping: dict[type, type] = {}\n",
    "\n",
    "  def resolve_attribute(\n",
    "      self, annotation_name: str, globals: dict[str, Any]\n",
    "  ) -> ir.TypeAttribute | None:\n",
    "    \"\"\"Get an IR type attribute from a string annotation.\"\"\"\n",
    "    annotation = cast(\n",
    "        type,\n",
    "        eval(annotation_name, globals, None),\n",
    "    )\n",
    "    if isinstance(annotation, ir.TypeAttribute):\n",
    "      return annotation\n",
    "    return self._mapping.get(annotation, None)\n",
    "\n",
    "  def get_annotation(self, attribute: ir.TypeAttribute) -> type | None:\n",
    "    anno = super().get_annotation(attribute)\n",
    "    if anno is None:\n",
    "      for key, value in self._generic_mapping.items():\n",
    "        if value == type(attribute):\n",
    "          return key\n",
    "    return anno\n",
    "\n",
    "  def register_param_type(self, annotation: type,\n",
    "                          attributeType: type):\n",
    "    self._generic_mapping[annotation] = attributeType\n",
    "\n",
    "\n",
    "class MyCodeGenVisitor(CodeGenerationVisitor):\n",
    "  def parse_op(self, ir_type, func_name, args: tuple):\n",
    "    ir_type = cast(ir.TypeAttribute, ir_type)\n",
    "    source_type = self.type_converter.type_registry.get_annotation(ir_type)\n",
    "    assert source_type\n",
    "    function_name = f\"{source_type.__qualname__}.{func_name}\"\n",
    "    op = self.type_converter.function_registry.resolve_operation(\n",
    "        module_name=source_type.__module__,\n",
    "        method_name=function_name,\n",
    "        args=args,\n",
    "    )\n",
    "    assert op\n",
    "    self.inserter.insert_op(op)\n",
    "\n",
    "  def visit_Subscript(self, node):\n",
    "    self.visit(node.slice)\n",
    "    elts = [self.inserter.get_operand() for i in range(len(node.slice.elts))]\n",
    "    self.visit(node.value)\n",
    "    value = self.inserter.get_operand()\n",
    "    self.parse_op(value.type, '__getitem__', (value, elts[::-1]))\n",
    "\n",
    "  def visit_Tuple(self, node):\n",
    "    for elt in node.elts:\n",
    "      self.visit(elt)\n",
    "\n",
    "  def visit_Assign(self, node) -> None:\n",
    "    self.visit(node.targets[0])\n",
    "    target = self.inserter.get_operand()\n",
    "    self.visit(node.value)\n",
    "    value = self.inserter.get_operand()\n",
    "    self.inserter.insert_op(AssignOp(target, value))\n",
    "\n",
    "\n",
    "dowhen.when(CodeGeneration.run_with_type_converter, \"+9\").do(\n",
    "    lambda type_converter, module, file:\n",
    "    {\"visitor\": MyCodeGenVisitor(type_converter, module, file)})\n",
    "\n",
    "\n",
    "class IterKind(IntEnum):\n",
    "  Serial = 0\n",
    "  Distributed = 1\n",
    "  Tensorize = 2\n",
    "\n",
    "\n",
    "class UsageKind(IntEnum):\n",
    "  Input = 0\n",
    "  Output = 1\n",
    "  Const = 2\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Expr:\n",
    "\n",
    "  def __add__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('+', self, other)\n",
    "\n",
    "  def __sub__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('-', self, other)\n",
    "\n",
    "  def __mul__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('*', self, other)\n",
    "\n",
    "  def __floordiv__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('//', self, other)\n",
    "\n",
    "  def __truediv__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('/', self, other)\n",
    "\n",
    "  def __mod__(self, other: 'Expr') -> 'Expr':\n",
    "    return Binary.create('%', self, other)\n",
    "\n",
    "  @abstractmethod\n",
    "  def walk(fn: Callable[['Expr'], None]):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Const(Expr):\n",
    "  value: int\n",
    "\n",
    "  def __str__(self):\n",
    "    return str(self.value)\n",
    "\n",
    "  def walk(self, fn: Callable[['Expr'], None]):\n",
    "    fn(self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class IterVar(Expr):\n",
    "  name: str\n",
    "  lower_bound: int | None\n",
    "  upper_bound: int | None\n",
    "  step: int = 1\n",
    "\n",
    "  @property\n",
    "  def extent(self) -> int:\n",
    "    return self.upper_bound - self.lower_bound\n",
    "\n",
    "  @staticmethod\n",
    "  def range(name: str, extent: int):\n",
    "    return IterVar(name, 0, extent, 1)\n",
    "\n",
    "  @staticmethod\n",
    "  def symbol(name: str):\n",
    "    vars = tuple(map(lambda s: IterVar(s, None, None, 1), name.split(' ')))\n",
    "    return vars[0] if len(vars) == 1 else vars\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.name, self.lower_bound, self.upper_bound, self.step))\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.name\n",
    "\n",
    "  def walk(self, fn: Callable[['Expr'], None]):\n",
    "    fn(self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Binary(Expr):\n",
    "  op: str\n",
    "  lhs: Expr\n",
    "  rhs: Expr\n",
    "\n",
    "  @staticmethod\n",
    "  def create(op: str, lhs: Expr, rhs: Expr):\n",
    "    match lhs:\n",
    "      case int():\n",
    "        lhs = Const(lhs)\n",
    "      case Expr():\n",
    "        pass\n",
    "      case _:\n",
    "        raise TypeError(f\"Unsupported left-hand side operand type: {type(lhs)}\")\n",
    "    match rhs:\n",
    "      case int():\n",
    "        rhs = Const(rhs)\n",
    "      case Expr():\n",
    "        pass\n",
    "      case _:\n",
    "        raise TypeError(f\"Unsupported right-hand side operand type: {type(rhs)}\")\n",
    "\n",
    "    return Binary(op=op, lhs=lhs, rhs=rhs)\n",
    "\n",
    "  def __str__(self):\n",
    "    return f\"({self.lhs} {self.op} {self.rhs})\"\n",
    "\n",
    "  def walk(self, fn: Callable[['Expr'], None]):\n",
    "    self.lhs.walk(fn)\n",
    "    self.rhs.walk(fn)\n",
    "    fn(self)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Buffer:\n",
    "  name: str\n",
    "  dims: tuple[int | IterVar, ...]\n",
    "  dtype: type = float\n",
    "  sharding: None | isl.map = None\n",
    "  usage: UsageKind = UsageKind.Input\n",
    "\n",
    "  @property\n",
    "  def shape(self) -> tuple[int | IterVar, ...]:\n",
    "    return tuple(d for d in self.dims)\n",
    "\n",
    "  @property\n",
    "  def domain(self) -> isl.set:\n",
    "    def render(i): return f'0 <= d{i} < {self.dims[i]}' if isinstance(\n",
    "        self.dims[i], int) else f'{self.dims[i].lower_bound} <= d{i} < {self.dims[i].upper_bound}'\n",
    "    return isl.set(f\"{{ {self.name}[{','.join([f'd{i}' for i in range(len(self.dims))])}] : {' and '.join([render(i) for i in range(len(self.dims))])} }}\")\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.name, self.dims, self.dtype, str(self.sharding)))\n",
    "\n",
    "  @classmethod\n",
    "  def __class_getitem__(cls, args):\n",
    "    elem_type = None\n",
    "    if issubclass(args[0], float):\n",
    "      elem_type = builtin.f32\n",
    "    elif issubclass(args[0], int):\n",
    "      elem_type = builtin.i32\n",
    "    else:\n",
    "      raise TypeError(f\"Unsupported element type: {args[0]}\")\n",
    "    return builtin.MemRefType(elem_type, [builtin.IntAttr(arg) for arg in args[1]])\n",
    "\n",
    "  def __setitem__(cls, args):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __getitem__(cls, args):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __iadd__(self, value):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __matmul__(self, value):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "@irdl_op_definition\n",
    "class AccessOp(IRDLOperation):\n",
    "  name = \"buffer.access\"\n",
    "\n",
    "  buffer = operand_def(builtin.MemRefType)\n",
    "  indices = var_operand_def(builtin.IndexType)\n",
    "  result = result_def(builtin.Attribute)\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      buffer: ir.SSAValue,\n",
    "      indices: Sequence[ir.SSAValue] | ir.SSAValue,\n",
    "      result_type: ir.Attribute,\n",
    "  ):\n",
    "    return super().__init__(operands=[buffer, indices], result_types=[result_type])\n",
    "\n",
    "\n",
    "@irdl_op_definition\n",
    "class AssignOp(IRDLOperation):\n",
    "  name = \"tensor.assign\"\n",
    "\n",
    "  target = operand_def(ir.TypeAttribute)\n",
    "  value = operand_def(ir.TypeAttribute)\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      target: ir.SSAValue,\n",
    "      value: ir.SSAValue,\n",
    "  ):\n",
    "    return super().__init__(operands=[target, value],\n",
    "                            result_types=[])\n",
    "\n",
    "\n",
    "type_registry = ParameterizedTypeRegistry()\n",
    "type_registry.register_param_type(Buffer, builtin.MemRefType)\n",
    "ctx = PyASTContext(type_registry)\n",
    "ctx.register_type(float, builtin.f32)\n",
    "ctx.register_type(IterVar, builtin.IndexType())\n",
    "ctx.register_function(Buffer.__getitem__, lambda *args:\n",
    "                      AccessOp(args[0], args[1], args[0].type.element_type))\n",
    "ctx.register_function(Buffer.__setitem__, lambda *args:\n",
    "                      AssignOp(args[0], args[1]))\n",
    "ctx.register_function(float.__mul__, arith.MulfOp)\n",
    "\n",
    "\n",
    "@ctx.parse_program\n",
    "def matmul(A: Buffer[float, [512, 2048]], B: Buffer[float, [2048, 1024]], C: Buffer[float, [512, 1024]], m: IterVar, n: IterVar, k: IterVar) -> Buffer[float, [512, 1024]]:\n",
    "  C[m, n] = A[m, k] * B[k, n]\n",
    "  return C\n",
    "\n",
    "\n",
    "print(matmul.module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab43eb",
   "metadata": {},
   "source": [
    "因为我倾向于使用多面体的方式进行编译优化，因此还需要有自己的IR，在上一步中我定义了`Expr,Const,IterVar,Binary`等表达式，这里还需要定义其他核心组件，比如`Computation`表示一个具体的计算,`Mesh`表示拓扑, `Access`表示计算对于`Buffer`的访问信息，`Transfer`表示数据移动信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64739ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class Mesh:\n",
    "  dims: tuple[IterVar, ...]\n",
    "\n",
    "  @property\n",
    "  def shape(self) -> tuple[int, ...]:\n",
    "    return tuple(var.extent for var in self.dims)\n",
    "\n",
    "  @property\n",
    "  def domain(self) -> isl.set:\n",
    "    return isl.set(f\"{{ Mesh[{','.join(map(str, self.dims))}] : {' and '.join([f'{dim.lower_bound} <= {dim} < {dim.upper_bound}' for dim in self.dims])} }}\")\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Access:\n",
    "  buffer: Buffer\n",
    "  relation: isl.map\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.buffer, str(self.relation)))\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Transfer:\n",
    "  access: Access\n",
    "  schedule: isl.map\n",
    "\n",
    "class AccessDimIndex(NamedTuple):\n",
    "  access_idx: int\n",
    "  buffer_dim: int\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Computation:\n",
    "  op: str\n",
    "  domain: isl.set\n",
    "  schedule: isl.map\n",
    "  accesses: List[Access]\n",
    "  iter_vars: tuple[IterVar]\n",
    "  mesh: Mesh | None = None\n",
    "  iter_kinds: dict[IterVar, IterKind] = field(default_factory=dict)\n",
    "  dim_bindings: dict[int, List[AccessDimIndex]] = field(default_factory=dict)\n",
    "  transfers: dict[IterVar, Tuple[Transfer, ...]] = field(default_factory=dict)\n",
    "\n",
    "  def name(self):\n",
    "    return self.domain.get_tuple_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237697c",
   "metadata": {},
   "source": [
    "接下来我要将AST解析到自己的IR上，这里对于index notation的解析仅做简单实现，即iterVar直接参与buffer访问的情况，更加复杂的情况留给有兴趣的读者们自行实现吧。解析的过程也相对比较简单，通过分析`AccessOp`对于`SSAValue`的使用情况，从而得到计算的`Domain/AccessRelation/Schedule`，然后统一存放到`Computation`中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20db3c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[k' = k, m' = m, n' = n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IndexCollector:\n",
    "  def __init__(self, iter_set: set[IterVar]):\n",
    "    self.iter_set: set[IterVar] = iter_set\n",
    "\n",
    "  def collect(self, node: ir.IRWithUses):\n",
    "    # todo support complex index pattern\n",
    "    match node:\n",
    "      case ir.BlockArgument():\n",
    "        match node.type:\n",
    "          case builtin.IndexType():\n",
    "            iter_var = IterVar.symbol(node.name_hint)\n",
    "            self.iter_set.add(iter_var)\n",
    "            return iter_var\n",
    "      case _:\n",
    "        raise NotImplementedError(\"Unsupported index node\")\n",
    "\n",
    "\n",
    "class StmtCollector:\n",
    "  def __init__(self, stmt_name: str):\n",
    "    self.stmt_name = stmt_name\n",
    "    self.iter_set: set[IterVar] = set()\n",
    "    self.access_dict: dict[AccessOp, (Buffer, list[ir.Operation])] = {}\n",
    "    self.op: str = None\n",
    "    self.on_value = False\n",
    "\n",
    "  def visit(self, node: ir.IRWithUses):\n",
    "    match node:\n",
    "      case ir.BlockArgument():\n",
    "        match node.type:\n",
    "          case builtin.MemRefType():\n",
    "            return Buffer(node.name_hint, tuple(dim.data for dim in node.type.shape), node.type.element_type, usage=UsageKind.Input if self.on_value else UsageKind.Output)\n",
    "          case _:\n",
    "            return\n",
    "      case ir.SSAValue() | ir.Operation():\n",
    "        op = node if isinstance(node, ir.Operation) else node.owner\n",
    "        match op:\n",
    "          case AssignOp():\n",
    "            self.on_value = False\n",
    "            self.visit(op.target)\n",
    "            self.on_value = True\n",
    "            self.visit(op.value)\n",
    "            self.on_value = False\n",
    "          case AccessOp():\n",
    "            b: Buffer = self.visit(op.buffer)\n",
    "            indices = [IndexCollector(self.iter_set).collect(i) for i in op.indices]\n",
    "            self.access_dict[op] = (b, indices)\n",
    "          case arith.MulfOp():\n",
    "            assert self.op is None\n",
    "            self.op = op.name\n",
    "            self.visit(op.lhs)\n",
    "            self.visit(op.rhs)\n",
    "\n",
    "\n",
    "class PolyhedronExtractPass(passes.ModulePass):\n",
    "  name = \"polyhedron_analysis\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.computations: list[Computation] = []\n",
    "    return super().__init__()\n",
    "\n",
    "  def analysis_stmt(self, op: AssignOp):\n",
    "    assert len(self.computations) == 0, \"not support stmts more than 1\"\n",
    "    stmt_name = f's{len(self.computations)}'\n",
    "    c = StmtCollector(stmt_name)\n",
    "    c.visit(op)\n",
    "    accesses = []\n",
    "    iters = sorted(c.iter_set, key=lambda i: i.name)\n",
    "    domain_dims = list(map(lambda x: x.name, iters))\n",
    "    domain = isl.set(f\"{{ {stmt_name}[{','.join(domain_dims)}] }}\")\n",
    "    bounded_iters: dict[str, IterVar] = {}\n",
    "    dim_bindings: dict[int, List[Tuple[int, int]]] = {}\n",
    "    for (bf, indices) in c.access_dict.values():\n",
    "      relation = isl.map(\n",
    "          f\"{{ {stmt_name}[{','.join(domain_dims)}] -> {bf.name}[{','.join(map(lambda x: x.name, indices))}]}}\")\n",
    "      domain = domain.intersect(relation.intersect_range(bf.domain).domain())\n",
    "      for i, idx in enumerate(indices):\n",
    "        if idx.name not in bounded_iters:\n",
    "          bounded_iters[idx.name] = replace(idx, lower_bound=bf.domain.dim_min_val(\n",
    "              i).num_si(), upper_bound=bf.domain.dim_max_val(i).num_si() + 1)\n",
    "      access = Access(replace(bf, dims=tuple(\n",
    "          [bounded_iters[idx.name] for idx in indices])), relation)\n",
    "      accesses.append(access)\n",
    "      for i, idx in enumerate(indices):\n",
    "        j = iters.index(idx)\n",
    "        binding = dim_bindings.get(j, [])\n",
    "        binding.append(AccessDimIndex(len(accesses) - 1, i))\n",
    "        dim_bindings[j] = binding\n",
    "        \n",
    "    comp = Computation(c.op, domain, domain.identity(), accesses,\n",
    "                       tuple([bounded_iters[v.name] for v in iters]), dim_bindings=dim_bindings)\n",
    "    self.computations.append(comp)\n",
    "\n",
    "  def analysis_op(self, op: ir.Operation):\n",
    "    if isinstance(op, AssignOp):\n",
    "      self.analysis_stmt(op)\n",
    "\n",
    "  def apply(self, ctx, op: builtin.ModuleOp) -> dict[str, Computation]:\n",
    "    for sub in op.walk():\n",
    "      self.analysis_op(sub)\n",
    "    return self.computations\n",
    "\n",
    "\n",
    "def polyhedron_extract(func) -> Computation:\n",
    "  return PolyhedronExtractPass().apply(passes.Context(allow_unregistered=True), func.module)[0]\n",
    "  \n",
    "s0 = polyhedron_extract(matmul)\n",
    "s0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e09b40",
   "metadata": {},
   "source": [
    "我设计的IR是一个immutable的结构，我的设想是可以实现类似于[Meta Scheduler](https://arxiv.org/abs/2205.13603)的schedule trace，这样可以接入外部的优化器进行搜索。然后基于多面体的表示，可以很方便的实现一些循环优化操作，比如split(对循环的inner loop进行固定)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41a2f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[k' = k, mo, mi = m - 8mo, n' = n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -7 + m <= 8mo <= m }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(self: Computation, parent_var: str, outer_var: str, inner_var: str, factor: int) -> 'Computation':\n",
    "  \"\"\" factor = extend(inner_var) \"\"\"\n",
    "  dim_index = self.iter_vars.index(parent_var)\n",
    "  assert dim_index != -1\n",
    "  new_iter_vars = tuple([*self.iter_vars[:dim_index],\n",
    "                         outer_var, inner_var, *self.iter_vars[dim_index + 1:]])\n",
    "\n",
    "  constraints_str = f' {outer_var} = {parent_var} // {factor} and {inner_var} = {parent_var} - {outer_var} * {factor}'\n",
    "  mapping_str = f\"{{ {self.name()}[{str.join(',', map(str, self.iter_vars))}] -> {self.name()}[{str.join(',', map(str, new_iter_vars))}]: {constraints_str} }}\"\n",
    "  split_map = isl.map(mapping_str)\n",
    "\n",
    "  new_schedule = self.schedule.apply_range(split_map)\n",
    "  new_schedule = reduce(lambda sche, p: sche.set_dim_name(\n",
    "      isl.dim_type.OUT, p[0], str(p[1])), enumerate(new_iter_vars), new_schedule)\n",
    "  return replace(self, iter_vars=tuple(new_iter_vars), schedule=new_schedule)\n",
    "\n",
    "\n",
    "Computation.split = split\n",
    "\n",
    "k, m, n = s0.iter_vars\n",
    "mo = IterVar.symbol('mo')\n",
    "mi = IterVar.symbol('mi')\n",
    "\n",
    "s0_splited = s0.split(m, mo, mi, 8)\n",
    "s0_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a80fad",
   "metadata": {},
   "source": [
    "以及divide，对循环的outer loop进行固定："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ee18b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[k' = k, mo, mi = m - 8mo, no, ni = n - 128no] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -7 + m <= 8mo <= m and -127 + n <= 128no <= n }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dim_bounds(self: Computation, dim_var: str) -> tuple[isl.val, isl.val]:\n",
    "  domain = self.schedule.intersect_domain(self.domain).range()\n",
    "  return (domain.dim_min_val(self.iter_vars.index(dim_var)), domain.dim_max_val(self.iter_vars.index(dim_var)))\n",
    "\n",
    "\n",
    "Computation.dim_bounds = dim_bounds\n",
    "\n",
    "\n",
    "def divide(self: Computation, parent_var: str, outer_var: str, inner_var: str, factor: int) -> 'Computation':\n",
    "  (min_val, max_val) = self.dim_bounds(parent_var)\n",
    "  return split(self, parent_var, outer_var, inner_var, (max_val.num_si() - min_val.num_si() + 1) // factor)\n",
    "\n",
    "\n",
    "Computation.divide = divide\n",
    "\n",
    "no = IterVar.symbol('no')\n",
    "ni = IterVar.symbol('ni')\n",
    "s0_divided = s0_splited.divide(n, no, ni, 8)\n",
    "s0_divided"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39461776",
   "metadata": {},
   "source": [
    "reorder同样也非常简单，只需要对重新修改schedule的dim顺序即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9fb642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, mi = m - 8mo, ni = n - 128no, k' = k] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -7 + m <= 8mo <= m and -127 + n <= 128no <= n }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), mesh=None, iter_kinds={}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reorder(self: Computation, *vars: List[int]):\n",
    "  assert len(set(vars)) == len(vars)\n",
    "  g = iter(vars)\n",
    "  new_iter_vars = [var if var not in vars else next(g) for var in self.iter_vars]\n",
    "  name = self.domain.get_tuple_name()\n",
    "  transform = isl.map(\n",
    "      f\"{{ {name}[{','.join(map(str,self.iter_vars))}] -> {name}[{','.join(map(str,new_iter_vars))}] }}\")\n",
    "  new_schedule = self.schedule.apply_range(transform)\n",
    "  new_schedule = reduce(lambda sche, p: sche.set_dim_name(\n",
    "      isl.dim_type.OUT, p[0], str(p[1])), enumerate(new_iter_vars), new_schedule)\n",
    "  return replace(self, iter_vars=tuple(new_iter_vars), schedule=new_schedule)\n",
    "\n",
    "\n",
    "Computation.reorder = reorder\n",
    "\n",
    "s0_ordered = s0_divided.reorder(mo, no, mi, ni, k)\n",
    "s0_ordered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29459888",
   "metadata": {},
   "source": [
    "distribute是一个比较重要的调度，他其实和parallel有所不同。类似triton把循环映射到线程上并行的方案，通常是固定计算的BLOCK SIZE，也就是外循环动态内循环固定，对应loop split调度，但distribute是对应节点个数固定的情况，内部任务大小会发生变化，对应loop divie调度。因此distribute的调度就是通过divide调度将外循环固定，然后通过reorder将外循环移动到最外侧："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27b70c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=[Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=None, usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))], iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distribute(self: Computation, parent_vars: List[IterVar], outer_vars: List[IterVar], inner_vars: List[IterVar], mesh: Mesh):\n",
    "  assert self.mesh is None\n",
    "  assert len(parent_vars) == len(outer_vars) == len(inner_vars)\n",
    "  assert all(map(lambda k: k != IterKind.Distributed, self.iter_kinds.values()))\n",
    "  for i, mesh_dim in enumerate(mesh.dims):\n",
    "    self = self.divide(parent_vars[i], outer_vars[i], inner_vars[i], mesh_dim.extent)\n",
    "  self = self.reorder(chain(outer_vars, inner_vars))\n",
    "  new_iter_kinds = self.iter_kinds.copy()\n",
    "  new_iter_kinds.update({v: IterKind.Distributed for v in outer_vars})\n",
    "  return replace(self, iter_kinds=new_iter_kinds, mesh=mesh)\n",
    "\n",
    "\n",
    "Computation.distribute = distribute\n",
    "\n",
    "x, y = IterVar.range('x', 8), IterVar.range('y', 8)\n",
    "mo, no, mi, ni = IterVar.symbol('mo no mi ni')\n",
    "ko, ki = IterVar.symbol('ko ki')\n",
    "s0_distributed = s0.distribute([m, n], [mo, no], [mi, ni], Mesh((x, y))). \\\n",
    "    divide(k, ko, ki, x.extent). \\\n",
    "    reorder(mo, no, ko, mi, ni, ki)\n",
    "s0_distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ef77f",
   "metadata": {},
   "source": [
    "定义完了计算分布，开始考虑存储分布。目前大部分的训练框架还是沿用着类似[OneFlow的SBP抽象](https://arxiv.org/pdf/2110.15032)，Google在分布式上的研究比较深入，他们提出了[Shardy](https://openxla.org/shardy)的抽象，相比于SBP他们可以支持指定轴分布的先后顺序。在我看来，以上表示方法都是为了描述数据点与节点/节点内数据点的映射关系(感觉用CUTE都可以描述，就是没有那么直观），那么直接基于多面体的map就可以支持上述抽象所表示的映射，并且可以支持其他更加复杂的映射关系。\n",
    "\n",
    "这里我为`IterVar`添加了一个`@`的语法糖，通过`shard('A', m @ x, k @ y)`就可以表示`A`的`m`轴在mesh的`x`轴上进行递增分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5ba57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=(Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ C[m, n] -> C[x, y, m - 64x, local_n = n - 128y] : 0 <= m <= 511 and 0 <= n <= 1023 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))), iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class ShardAxis:\n",
    "  lhs: IterVar\n",
    "  rhs: Tuple[Expr]\n",
    "\n",
    "\n",
    "def var_shard_op(self: Expr, other: Expr | List[Expr]):\n",
    "  return ShardAxis(self, (other,) if isinstance(other, Expr) else tuple(other))\n",
    "\n",
    "\n",
    "IterVar.__matmul__ = var_shard_op\n",
    "\n",
    "\n",
    "def shard(self: Computation, buffer_name: str, *shard_axes: ShardAxis):\n",
    "  shard_axis_vars = set()\n",
    "\n",
    "  def collect_fn(e: Expr):\n",
    "    if isinstance(e, IterVar):\n",
    "      shard_axis_vars.add(e)\n",
    "\n",
    "  for shard_axis in shard_axes:\n",
    "    for rhs in shard_axis.rhs:\n",
    "      rhs.walk(collect_fn)\n",
    "    assert all(map(lambda v: v in self.mesh.dims, shard_axis_vars)\n",
    "               ), \"rhs must be in mesh dimensions\"\n",
    "    shard_axis_vars.clear()\n",
    "\n",
    "  access = next(filter(lambda acc: acc.buffer.name == buffer_name, self.accesses))\n",
    "  assert access\n",
    "  assert all([shard_axis.lhs in access.buffer.dims for shard_axis in shard_axes]\n",
    "             ), \"lhs must be in buffer dimensions\"\n",
    "  buffer = access.buffer\n",
    "  assert buffer.sharding == None, \"Buffer must not be sharded\"\n",
    "\n",
    "  def bound_fn(v): return f'{v.lower_bound} <= {v} < {v.upper_bound}'\n",
    "  sharding_map = isl.map(\n",
    "      f\"{{ {buffer.name}[{','.join(map(str, buffer.dims))}] -> {buffer.name}[{','.join(map(str, self.mesh.dims))},{','.join(map(str, buffer.dims))}] : {' and '.join(map(bound_fn, chain(self.mesh.dims, buffer.dims)))} }}\")\n",
    "\n",
    "  local = 'local_'\n",
    "  space_dims = list(map(str, chain(self.mesh.dims, buffer.dims)))\n",
    "  for shard_axis in shard_axes:\n",
    "    lhs = shard_axis.lhs\n",
    "    dim_extent = lhs.extent\n",
    "    for rhs in shard_axis.rhs:\n",
    "      match rhs:\n",
    "        # todo support expr.\n",
    "        case Expr():\n",
    "          # assert (dim_extent % rhs.extent) == 0, \"Dimension can't divide evenly\"\n",
    "          # isl.map( rhs)\n",
    "          sched_space = str(self.mesh.domain.space())[1:-1]\n",
    "          factor_map = isl.map(f'{{ {sched_space} -> [{rhs}] }}').intersect_domain(self.mesh.domain)\n",
    "          factor = factor_map.max_multi_pw_aff().at(0).max_val().num_si() - factor_map.min_multi_pw_aff().at(0).min_val().num_si() + 1\n",
    "          # .size().at(0).num_si()\n",
    "          assert dim_extent % factor == 0, \"Dimension must be divisible by sharding factor\"\n",
    "          local_dim_extent = dim_extent // factor\n",
    "          # rhs.extent\n",
    "          constraints = f'{rhs} = {lhs} // {local_dim_extent} and {local + str(lhs)} = {lhs} - {rhs} * {local_dim_extent}'\n",
    "          lhs_space = f\"{buffer.name}[{','.join(space_dims)}]\"\n",
    "          rhs_space = f\"{buffer.name}[{','.join([local + str(lhs) if dim == str(lhs) else dim for dim in space_dims])}]\"\n",
    "          sharding_map = sharding_map.apply_range(\n",
    "              isl.map(f'{{ {lhs_space} -> {rhs_space} : {constraints} }}'))\n",
    "          dim_extent = dim_extent // local_dim_extent  # update extent\n",
    "        case _:\n",
    "          raise NotImplementedError()\n",
    "  sharding_map = reduce(lambda sche, p: sche.set_dim_name(\n",
    "      isl.dim_type.OUT, p[0], str(p[1])), enumerate(self.mesh.dims), sharding_map)\n",
    "  n_access = replace(access, buffer=replace(buffer, sharding=sharding_map))\n",
    "  return replace(self, accesses=tuple([n_access if o_access.buffer.name == buffer.name else o_access for o_access in self.accesses]))\n",
    "\n",
    "\n",
    "Computation.shard = shard\n",
    "\n",
    "\n",
    "s0_sharded = s0_distributed.shard('A', m @ x, k @ y). \\\n",
    "    shard('B', k @ x, n @ y). \\\n",
    "    shard('C', m @ x, n @ y)\n",
    "s0_sharded"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "188df835",
   "metadata": {},
   "source": [
    "有了计算分布和存储分布，开始添加通算融合中最重要的一部分：通信。 通过指定循环进行通信，通过多面体分析得到依赖数据的节点/偏移信息，避免用户手动计算的带来的复杂性。未来可以支持promote，让一次通信匹配多次计算。\n",
    "\n",
    "在communicate中我引入了Distal提出的rotate调度，通过指定`rotate_factors`让当前时刻所依赖的节点ID随着时间维度发生动态的改变，后续配合ring shift的通信操作，使得每个时刻引用的数据都在本地，提升计算效率。\n",
    "\n",
    "这一步中对A矩阵进行rotate的通信，B矩阵直接通信，这对应的是[PUMMA](https://onlinelibrary.wiley.com/doi/10.1002/cpe.4330060702)的算法，如图所示：\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38aa134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op='arith.mulf', domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=(Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ C[m, n] -> C[x, y, m - 64x, local_n = n - 128y] : 0 <= m <= 511 and 0 <= n <= 1023 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))), iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={IterVar(name='ko', lower_bound=None, upper_bound=None, step=1): (Transfer(access=Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\")), Transfer(access=Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\")))})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def communicate(self: Computation, buffer_name: str, var: IterVar, rotate_factors: List[IterVar] = []):\n",
    "  access = next(filter(lambda acc: acc.buffer.name == buffer_name, self.accesses))\n",
    "  assert access.buffer.sharding\n",
    "  assert IterKind.Serial == self.iter_kinds.get(var, IterKind.Serial)\n",
    "  new_transfers = self.transfers.copy()\n",
    "  transed = new_transfers.get(var, ())\n",
    "  assert access not in transed\n",
    "\n",
    "  i = self.iter_vars.index(var)\n",
    "\n",
    "  access_schedule = None\n",
    "  if len(rotate_factors) > 0:\n",
    "    name = self.name()\n",
    "    extent = self.schedule.range().dim_max_val(i).num_si() + 1\n",
    "    nvar = str(var) + '_r'\n",
    "    niter_vars = tuple([*self.iter_vars[:i], nvar, *self.iter_vars[i + 1:]])\n",
    "    constraints = [f\"{nvar} = ({' + '.join(map(str, rotate_factors))} + {var}) mod {extent}\"]\n",
    "    for factor in rotate_factors + [var]:\n",
    "      i = self.iter_vars.index(factor)\n",
    "      min = self.schedule.range().dim_min_val(i).num_si()\n",
    "      max = self.schedule.range().dim_max_val(i).num_si()\n",
    "      constraints.append(f\"{min} <= {str(factor)} <= {max}\")\n",
    "    access_schedule = isl.map(\n",
    "        f\"{{ {name}[{','.join(map(str, self.iter_vars))}] -> {name}[{','.join(map(str, niter_vars))}] : {' and '.join(constraints)} }}\")\n",
    "  else:\n",
    "    access_schedule = self.schedule.range().identity()\n",
    "\n",
    "  # check validity\n",
    "  schedule_to_sharding = self.schedule.apply_range(access_schedule).apply_domain(\n",
    "      access.relation).apply_domain(access.buffer.sharding).reverse()  # schedule -> buffer\n",
    "  dist_to_shard = schedule_to_sharding.project_out(isl.dim_type.IN, i + 1, len(self.iter_vars) - i - 1). \\\n",
    "      project_out(isl.dim_type.OUT, len(self.mesh.dims),\n",
    "                  access.buffer.sharding.dim(isl.dim_type.OUT) - len(self.mesh.dims))\n",
    "  assert dist_to_shard.is_single_valued(), \"transfer can't read/write data cross multi nodes.\"\n",
    "\n",
    "  new_transfers[var] = (Transfer(access, access_schedule), *transed)\n",
    "  return replace(self, transfers=new_transfers)\n",
    "\n",
    "\n",
    "Computation.communicate = communicate\n",
    "\n",
    "s0_communicated = s0_sharded.communicate('A', ko, [no]). \\\n",
    "    communicate('B', ko)\n",
    "\n",
    "s0_communicated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152963cc",
   "metadata": {},
   "source": [
    "到目前为止，已经定义好了计算所有需要的内容，可以开始进行代码生成。然而由于transfer调度引入了新的临时buffer/数据通信操作，在多面体表示中去支持会稍显复杂。这里会涉及多面体代码生成相关的内容，早期多面体编译会采用`2d+1`的表示方式标记语句执行的顺序，但是当程序复杂后，许多的map会很难处理和分析。 后来isl引入了`schedule tree`的方式，用树形的结构来表示语句的执行顺序，便于遍历和修改。 目前isl是支持从`2d+1`表示以及`schedule tree`表示生成ast的，在[tiramisu](http://tiramisu-compiler.org)中是使用`2d+1`的方式，在[akg-tvm](https://gitee.com/mindspore/akg/blob/master/src/poly/schedule_pass.cc)则是使用`schedule tree`的方式，尽管使用不同的方式，但都是会生成isl的ast，最终再遍历它生成平台相关代码。\n",
    "\n",
    "这里我的IR不算复杂，因此采用`2d+1`表示生成ast。下面会定义一些扩展的ast节点类型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24465d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpKind(IntEnum):\n",
    "  # call(Assign, dest, src)\n",
    "  Assign = 0\n",
    "  # call(Access, buffer, *(int | slice))\n",
    "  Access = 1\n",
    "  # call(Trans, commPattern, sendbuf, dest, recvbuf, source)\n",
    "  Trans = 2\n",
    "  # call(Alloc, name, *dims)\n",
    "  Alloc = 3\n",
    "  # call(Rank, *ids)\n",
    "  Rank = 4\n",
    "  # call(CommSendrecv)\n",
    "  CommSendrecv = 5\n",
    "  # call(CommBroadcast, *commGroups)\n",
    "  CommBroadcast = 6\n",
    "  # call(CommShift, *commGroups, direction)\n",
    "  CommShift = 7\n",
    "  # call(AssertEqual, a, b)\n",
    "  AssertEqual = 8\n",
    "  # call(AugAssign, dest, src)\n",
    "  AugAssign = 9\n",
    "\n",
    "  # call(Slice, begin, end)\n",
    "  Slice = 128\n",
    "  Add = 129\n",
    "  Mul = 130\n",
    "  MatMul = 131\n",
    "  MatMulTransA = 132\n",
    "\n",
    "\n",
    "def call_from(build: isl.ast_build, op: OpKind, *args: List[isl.ast_expr | str]):\n",
    "  assert isinstance(op, OpKind)\n",
    "  l = isl.ast_expr_list(len(args))\n",
    "  for i in range(len(args)):\n",
    "    match args[i]:\n",
    "      case isl.ast_expr():\n",
    "        l = l.add(args[i])\n",
    "      case int() | isl.val():\n",
    "        l = l.add(isl.ast_expr.from_val(args[i]))\n",
    "      case str():\n",
    "        l = l.add(isl.ast_expr.from_id(args[i]))\n",
    "      case isl.pw_aff():\n",
    "        l = l.add(build.expr_from(isl.pw_aff(str(args[i]))))\n",
    "      case _:\n",
    "        raise ValueError(f\"Unsupported argument type: {type(args[i])}\")\n",
    "  return isl.ast_expr.call(isl.ast_expr.from_id(op.name), l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cefa1",
   "metadata": {},
   "source": [
    "添加`TransferScheduleInfo,ComputationScheduleInfo`的分析集合，用于收集原始调度转化到`2d+1`的表示等相关信息。这里`TransferScheduleInfo`我额外添加了`access_schedule`用于支持不同的访问模式，比如rotate等。`access_adapt_schedule`则是用于对齐相同维度依赖的，比如当A矩阵的k维度通过rotate的方式进行索引，而B矩阵的k维度要与它进行匹配才能计算正确，此时需要为B矩阵添加对应的`access_adapt_schedule`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c021b8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[256ko + ki, 128no + ni] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[x, y, 256ko + ki - 256x, local_n = 128no + ni - 128y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -255 + 256ko + ki <= 256x <= 256ko + ki and 0 <= y <= 7 and -127 + 128no + ni <= 128y <= 128no + ni }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_adapt_schedule=None, box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> B[(256ko), (128no)] }\", size: \"{ B[256, 128] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransB[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 0, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransB[mo, no, ko, mi = 0, ni, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 1, mi' = 0, 0, ni' = ni, 0, ki' = ki] : 0 <= mo <= 7 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(3,))\n",
      "TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[64mo + mi, 256ko + ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[x, y, 64mo + mi - 64x, local_k = 256ko + ki - 256y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -63 + 64mo + mi <= 64x <= 64mo + mi and 0 <= y <= 7 and -255 + 256ko + ki <= 256y <= 256ko + ki }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\"), access_adapt_schedule=None, box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> A[(64mo), (256ko)] }\", size: \"{ A[64, 256] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransA[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 0, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransA[mo, no, ko, mi, ni = 0, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 1, mi' = mi, 0, ni' = 0, 0, ki' = ki] : 0 <= no <= 7 and mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(4,))\n"
     ]
    }
   ],
   "source": [
    "def get_kelly_map(self: Computation, *tps: Tuple[int, int]):\n",
    "  ndim = self.schedule.dim(isl.dim_type.OUT)\n",
    "  sche = self.schedule.range().identity()\n",
    "  d = {p[0] + 1: p[1] for p in tps}\n",
    "  for i in range(ndim):\n",
    "    sche = sche.insert_dims(isl.dim_type.OUT, i * 2,\n",
    "                            1).fix_val(isl.dim_type.OUT, i * 2, d.get(i, 0))\n",
    "  return sche.set_tuple_name(isl.dim_type.OUT, sche.get_tuple_name(isl.dim_type.IN))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class TransferScheduleInfo:\n",
    "  dim: int\n",
    "  access_map: isl.map\n",
    "  access_shard_map: isl.map  # schedule -> buffer\n",
    "  access_schedule: isl.map  # schedule -> new schedule\n",
    "  access_adapt_schedule: isl.map | None\n",
    "  box_hull: isl.fixed_box\n",
    "  alloc_schedule: isl.map\n",
    "  trans_schedule: isl.map\n",
    "  redundancies: Tuple[int, ...]\n",
    "\n",
    "  @property\n",
    "  def alloc_name(self):\n",
    "    return self.alloc_schedule.tuple_name(isl.dim_type.IN)\n",
    "\n",
    "  @property\n",
    "  def trans_name(self):\n",
    "    return self.trans_schedule.tuple_name(isl.dim_type.IN)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class ComputationScheduleInfo:\n",
    "  comp_schedule: isl.map\n",
    "  assign_kind: OpKind\n",
    "  op_kind: OpKind\n",
    "\n",
    "  @property\n",
    "  def comp_name(self):\n",
    "    return self.comp_schedule.tuple_name(isl.dim_type.IN)\n",
    "\n",
    "\n",
    "def get_transfer_schedule_info(self: Computation, transfer: Transfer, dim: int, order: int):\n",
    "  sched_domain = self.schedule.range()\n",
    "  ndim = sched_domain.n_dim()\n",
    "  access_map = self.schedule.apply_domain(transfer.access.relation).reverse()\n",
    "  access_shard_map = access_map.apply_range(transfer.access.buffer.sharding)\n",
    "  box_hull = access_map. \\\n",
    "      eliminate(isl.dim_type.IN, dim + 1, ndim - dim - 1). \\\n",
    "      range_simple_fixed_box_hull()\n",
    "\n",
    "  trans_name = OpKind.Trans.name + transfer.access.buffer.name\n",
    "  alloc_name = OpKind.Alloc.name + trans_name\n",
    "  alloc_schedule = get_kelly_map(self, (dim, order)). \\\n",
    "      intersect_domain(sched_domain). \\\n",
    "      project_out(isl.dim_type.IN, dim + 1, ndim - (dim + 1)). \\\n",
    "      set_domain_tuple(alloc_name)\n",
    "  for drop_dim in range(dim + 1, ndim):\n",
    "    alloc_schedule = alloc_schedule.fix_si(isl.dim_type.OUT, drop_dim * 2 + 1, 0)\n",
    "  order += 1\n",
    "\n",
    "  trans_schedule = get_kelly_map(self, (dim, order)). \\\n",
    "      intersect_domain(sched_domain). \\\n",
    "      set_domain_tuple(trans_name)\n",
    "\n",
    "  # find dropped dimensions\n",
    "  redundancies = []\n",
    "  cons_free_map = access_map.drop_constraints_not_involving_dims(\n",
    "      isl.dim_type.OUT, 0, len(transfer.access.buffer.dims))\n",
    "  for i in range(dim, ndim):\n",
    "    if not cons_free_map.involves_dims(isl.dim_type.IN, i, 1):\n",
    "      trans_schedule = trans_schedule.fix_si(isl.dim_type.IN, i, 0)\n",
    "      redundancies.append(i)\n",
    "\n",
    "  order += 1\n",
    "\n",
    "  return TransferScheduleInfo(dim, access_map, access_shard_map, transfer.schedule, \n",
    "                              None, box_hull, alloc_schedule, trans_schedule,\n",
    "                              tuple(redundancies))\n",
    "\n",
    "\n",
    "s0_trans_info_0 = get_transfer_schedule_info(\n",
    "    s0_communicated, s0_communicated.transfers[ko][0], 2, 0)\n",
    "s0_trans_info_1 = get_transfer_schedule_info(\n",
    "    s0_communicated, s0_communicated.transfers[ko][1], 2, 0)\n",
    "print(s0_trans_info_0)\n",
    "print(s0_trans_info_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757b75c",
   "metadata": {},
   "source": [
    "有了调度信息，其实已经知道了通信的节点/偏移信息，但是由于我这里选择的分布式后端是MPI，没办法直接根据以上信息进行数据读写，只能依赖它提供的通信原语。比如当多个rank需要从同一个rank进行取数时，需要使用broadcast原语才可以正常通信，如果使用sendrecv原语则需要指定rank多次调用。 所以还需要根据通信调度还需要检测其通信模式，我这里的方法是通过改变通信发生的时间维度，获得时间变化下 source rank的变化表达式，如果source rank不变，那么也许是p2p或者broadcast，再通过进一步检查source rank与dest rank是否双射来确定是不是broadcast。当source rank随时间发生变化时，可以对其采用确定他是否为ring以及ring的方向："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5951bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcast(axes=(0,))\n",
      "Shift(axes=(1,), direction=1)\n"
     ]
    }
   ],
   "source": [
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class CommPattern:\n",
    "  def build_call(self, build):\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class SendRecv(CommPattern):\n",
    "  def build_call(self, build):\n",
    "    return call_from(build, OpKind.CommSendrecv)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class Broadcast(CommPattern):\n",
    "  axes: tuple[int, ...]\n",
    "\n",
    "  def build_call(self, build):\n",
    "    return call_from(build, OpKind.CommBroadcast, *self.axes)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class Shift(CommPattern):\n",
    "  axes: tuple[int, ...]\n",
    "  direction: int\n",
    "\n",
    "  def build_call(self, build):\n",
    "    return call_from(build, OpKind.CommShift, *self.axes, self.direction)\n",
    "\n",
    "\n",
    "def drop_dims(sche: isl.map | isl.aff, redundancies: Tuple[int] = ()):\n",
    "  dims = list(redundancies)\n",
    "  dims.sort()\n",
    "  j = 0\n",
    "  for i in range(len(dims)):\n",
    "    if isinstance(sche, isl.map):\n",
    "      sche = sche.project_out(isl.dim_type.IN, dims[i] - j, 1)\n",
    "    elif isinstance(sche, isl.pw_aff):\n",
    "      sche = sche.drop_dims(isl.dim_type.IN, dims[i] - j, 1)\n",
    "    else:\n",
    "      raise NotImplementedError\n",
    "    j += 1\n",
    "  return sche\n",
    "\n",
    "\n",
    "def detect_communication_pattern(self: Computation, info: TransferScheduleInfo):\n",
    "  domain_ndim = info.access_map.dim(isl.dim_type.IN)\n",
    "  shard_ndim = info.access_shard_map.dim(isl.dim_type.OUT)\n",
    "  mesh_ndim = len(self.mesh.dims)\n",
    "  comm_dim = info.dim\n",
    "  access_shard_map = info.access_shard_map.apply_domain(info.access_schedule)\n",
    "  access_src_rank = access_shard_map. \\\n",
    "      project_out(isl.dim_type.OUT, mesh_ndim, shard_ndim - mesh_ndim).\\\n",
    "      project_out(isl.dim_type.IN, info.dim + 1, domain_ndim - info.dim - 1)\n",
    "  # mesh_ndim = len(self.mesh.dims)\n",
    "  # access_shard_map = info.access_shard_map.apply_domain(info.access_schedule)\n",
    "  # cons_free_map = access_shard_map.drop_constraints_not_involving_dims(\n",
    "  #     isl.dim_type.OUT, 0, access_shard_map.dim(isl.dim_type.OUT))\n",
    "  # redundancies = []\n",
    "  # for i in range(comm_dim, cons_free_map.dim(isl.dim_type.IN)):\n",
    "  #   if not cons_free_map.involves_dims(isl.dim_type.IN, i, 1):\n",
    "  #     redundancies.append(i)\n",
    "\n",
    "  # access_src_rank = drop_dims(access_shard_map, redundancies)\n",
    "  access_src_pma = access_src_rank.as_pw_multi_aff()\n",
    "  delta_vals = ','.join(\n",
    "    ['1' if i == comm_dim else '0' for i in range(access_src_pma.dim(isl.dim_type.IN))])\n",
    "  access_next_src_pma = isl.pw_multi_aff.identity_on_domain(\n",
    "      access_src_pma.domain_space()).add_constant(isl.multi_val(f'{{[{delta_vals}]}}'))\n",
    "  src_rank_deltas = access_src_pma.pullback(access_next_src_pma).sub(access_src_pma).coalesce()\n",
    "  comm_patterns = []\n",
    "  for i in range(mesh_ndim):\n",
    "    pa = src_rank_deltas.at(i)\n",
    "    if pa.is_cst():\n",
    "      match pa.max_val().num_si():\n",
    "        case 0:  # not involved\n",
    "          comm_patterns.append(SendRecv())\n",
    "        case 1:  # changed with time.\n",
    "          if not access_src_rank.is_bijective():  # detect broadcast\n",
    "            unbounded = access_src_rank.drop_constraints_not_involving_dims(\n",
    "                isl.dim_type.OUT, 0, mesh_ndim)\n",
    "            if not unbounded.involves_dims(isl.dim_type.IN, i, 1):\n",
    "              comm_patterns.append(Broadcast((i,)))\n",
    "            else:\n",
    "              comm_patterns.append(SendRecv())\n",
    "          else:\n",
    "            comm_patterns.append(SendRecv())\n",
    "    else:\n",
    "      points = []\n",
    "      pa.as_map().range().foreach_point(lambda x: points.append(isl.set(x)))\n",
    "      points = reduce(lambda acc, x: acc.union(x), points, isl.set.empty(\n",
    "          isl.space.unit().add_dims(isl.dim_type.SET, 1)))\n",
    "      extent = self.schedule.range().dim_max_val(info.dim).num_si()\n",
    "      cw_set = isl.set(f'{{[1]; [-{extent}]}}')\n",
    "      ccw_set = isl.set(f'{{[-1]; [{extent}]}}')\n",
    "      if points.is_equal(cw_set):\n",
    "        comm_patterns.append(Shift((i,), 1))\n",
    "      elif points.is_equal(ccw_set):\n",
    "        comm_patterns.append(Shift((i,), -1))\n",
    "\n",
    "  special = sum([isinstance(p, (Broadcast, Shift)) for p in comm_patterns])\n",
    "  assert special <= 1\n",
    "  return SendRecv() if special == 0 else next(filter(lambda p: not isinstance(p, SendRecv), comm_patterns))\n",
    "\n",
    "\n",
    "print(detect_communication_pattern(s0_communicated, s0_trans_info_0))\n",
    "print(detect_communication_pattern(s0_communicated, s0_trans_info_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146c9dc",
   "metadata": {},
   "source": [
    "上一步通过`TransferScheduleInfo`检测到了数据传输的模式，我们还需要获得`ComputationScheduleInfo`, 这一步相对简单，只需要把原始的schedule转化为`2d+1`的表示即可："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a6589f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScheduleInfo(trans_infos=(TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[256ko + ki, 128no + ni] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> B[x, y, 256ko + ki - 256x, local_n = 128no + ni - 128y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -255 + 256ko + ki <= 256x <= 256ko + ki and 0 <= y <= 7 and -127 + 128no + ni <= 128y <= 128no + ni }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_adapt_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\"), box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> B[(256ko), (128no)] }\", size: \"{ B[256, 128] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransB[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 0, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransB[mo, no, ko, mi = 0, ni, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 1, mi' = 0, 0, ni' = ni, 0, ki' = ki] : 0 <= mo <= 7 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(3,)), TransferScheduleInfo(dim=2, access_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[64mo + mi, 256ko + ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), access_shard_map=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> A[x, y, 64mo + mi - 64x, local_k = 256ko + ki - 256y] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 and 0 <= x <= 7 and -63 + 64mo + mi <= 64x <= 64mo + mi and 0 <= y <= 7 and -255 + 256ko + ki <= 256y <= 256ko + ki }\"), access_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\"), access_adapt_schedule=None, box_hull=isl.fixed_box(\"\"\"{ offset: \"{ s0[mo, no, ko, mi, ni, ki] -> A[(64mo), (256ko)] }\", size: \"{ A[64, 256] }\" }\"\"\"), alloc_schedule=isl.map(\"{ AllocTransA[mo, no, ko] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 2, mi = 0, 0, ni = 0, 0, ki = 0] : 0 <= mo <= 7 and 0 <= no <= 7 and 0 <= ko <= 7 }\"), trans_schedule=isl.map(\"{ TransA[mo, no, ko, mi, ni = 0, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 3, mi' = mi, 0, ni' = 0, 0, ki' = ki] : 0 <= no <= 7 and mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), redundancies=(4,))), comp_infos=(ComputationScheduleInfo(comp_schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[0, mo' = mo, 0, no' = no, 0, ko' = ko, 4, mi' = mi, 0, ni' = ni, 0, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\"), assign_kind=<OpKind.AugAssign: 9>, op_kind=<OpKind.Mul: 130>),))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass(frozen=True, unsafe_hash=True)\n",
    "class ScheduleInfo:\n",
    "  trans_infos: Tuple[TransferScheduleInfo]\n",
    "  comp_infos: Tuple[ComputationScheduleInfo]\n",
    "\n",
    "\n",
    "def get_schedule_info(self: Computation):\n",
    "  transfer_sche_infos: List[TransferScheduleInfo] = []\n",
    "  used_orders = []\n",
    "  for (var, accesses) in self.transfers.items():\n",
    "    dim = self.iter_vars.index(var)\n",
    "    order = 0\n",
    "    for access in accesses:\n",
    "      transfer_sche_infos.append(get_transfer_schedule_info(self, access, dim, order))\n",
    "      order += 2\n",
    "      used_orders.append((dim, order))\n",
    "  # check dim bindings\n",
    "  for dim, dim_indices in self.dim_bindings.items():\n",
    "    worklist: List[Tuple[int, TransferScheduleInfo, AccessDimIndex]] = []\n",
    "    for dim_index in dim_indices:\n",
    "      for var, trans_infos in self.transfers.items():\n",
    "        for i, trans in enumerate(trans_infos):\n",
    "          if self.accesses[dim_index.access_idx] == trans.access:\n",
    "            worklist.append((i, transfer_sche_infos[i], dim_index))\n",
    "    # process worklist\n",
    "    if len(worklist) > 1:\n",
    "      access_dim_maps: List[isl.map] = []\n",
    "      for workitem in worklist:\n",
    "        _, trans_info, dim_index = workitem\n",
    "        access_dim_map: isl.map = trans_info.access_map.apply_domain(trans_info.access_schedule)\n",
    "        access_dim_map = access_dim_map.project_out(isl.dim_type.OUT, 0, dim_index.buffer_dim)\n",
    "        access_dim_map = access_dim_map.project_out(\n",
    "            isl.dim_type.OUT, 1, access_dim_map.dim(isl.dim_type.OUT) - 1)\n",
    "        access_dim_maps.append(access_dim_map)\n",
    "      for i in range(len(access_dim_maps) - 1):\n",
    "        # when dim not equal, add index schedule\n",
    "        if not access_dim_maps[i].is_equal(access_dim_maps[i + 1]):\n",
    "          a = worklist[i][1]\n",
    "          b = worklist[i + 1][1]\n",
    "          if a.access_schedule.is_identity():\n",
    "            assert a.access_adapt_schedule is None\n",
    "            transfer_sche_infos[worklist[i][0]] = replace(a, access_adapt_schedule=b.access_schedule)\n",
    "          elif b.access_schedule.is_identity():\n",
    "            assert b.access_adapt_schedule is None\n",
    "            transfer_sche_infos[worklist[i + 1][0]] = replace(b, access_adapt_schedule=a.access_schedule)\n",
    "          else:\n",
    "            raise ValueError(\"Incompatible access schedules\")\n",
    "\n",
    "  in_iters = set(itertools.flatten(\n",
    "      [acc.buffer.dims for acc in self.accesses if acc.buffer.usage is UsageKind.Input]))\n",
    "  out_iters = set(itertools.flatten(\n",
    "      [acc.buffer.dims for acc in self.accesses if acc.buffer.usage is UsageKind.Output]))\n",
    "\n",
    "  op_kind = None\n",
    "  match self.op:\n",
    "    case OpKind():\n",
    "      op_kind = self.op\n",
    "    case 'arith.mulf':\n",
    "      op_kind = OpKind.Mul\n",
    "    case _:\n",
    "      raise NotImplementedError()\n",
    "\n",
    "  comp_schedule = ComputationScheduleInfo(get_kelly_map(\n",
    "      self, *used_orders).intersect_domain(self.schedule.range()),\n",
    "      OpKind.AugAssign if len(in_iters) > len(out_iters) else OpKind.Assign,\n",
    "      op_kind)\n",
    "  return ScheduleInfo(tuple(transfer_sche_infos), (comp_schedule,))\n",
    "\n",
    "\n",
    "s0_schedule_info = get_schedule_info(s0_communicated)\n",
    "s0_schedule_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2705c",
   "metadata": {},
   "source": [
    "基于`ScheduleInfo`进行ast生成，同时使用上述分析在ast中插入所需要的操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea79a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int ko = 0; ko <= 7; ko += 1) {\n",
      "      Alloc(TransB, 256, 128);\n",
      "      for (int ni = 0; ni <= 127; ni += 1)\n",
      "        for (int ki = 0; ki <= 255; ki += 1)\n",
      "          Trans(CommBroadcast(0), Access(B, Slice(ki, ki + 1), Slice(ni, ni + 1)), Rank((y + ko) % 8), Access(TransB, Slice(ki, ki + 1), Slice(ni, ni + 1)), Rank(x));\n",
      "      Alloc(TransA, 64, 256);\n",
      "      for (int mi = 0; mi <= 63; mi += 1)\n",
      "        for (int ki = 0; ki <= 255; ki += 1)\n",
      "          Trans(CommShift(1, 1), Access(A, Slice(mi, mi + 1), Slice(ki, ki + 1)), Rank(x, (y + ko) % 8), Access(TransA, Slice(mi, mi + 1), Slice(ki, ki + 1)), Rank(x, y));\n",
      "      for (int mi = 0; mi <= 63; mi += 1)\n",
      "        for (int ni = 0; ni <= 127; ni += 1)\n",
      "          for (int ki = 0; ki <= 255; ki += 1)\n",
      "            AugAssign(Access(C, Slice(mi, mi + 1), Slice(ni, ni + 1)), Mul(Access(TransA, Slice(mi, mi + 1), Slice(ki, ki + 1)), Access(TransB, Slice(ki, ki + 1), Slice(ni, ni + 1))));\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lower_computation(self: Computation):\n",
    "  schedule_info = get_schedule_info(self)\n",
    "  # process tensorized\n",
    "  sched_domain = self.schedule.range()\n",
    "  sched_domain_min = self.schedule.range()\n",
    "  sched_domain_max = self.schedule.range()\n",
    "  tensorized_dims = []\n",
    "  for i, v in enumerate(self.iter_vars):\n",
    "    if self.iter_kinds.get(v) is IterKind.Tensorize:\n",
    "      sched_domain_min = sched_domain_min.fix_val(isl.dim_type.SET, i, sched_domain.dim_min_val(i))\n",
    "      sched_domain_max = sched_domain_max.fix_val(isl.dim_type.SET, i, sched_domain.dim_max_val(i))\n",
    "      tensorized_dims.append(i)\n",
    "\n",
    "  def fix_dims(sche: isl.map):\n",
    "    for d in tensorized_dims:\n",
    "      sche = sche.fix_si(isl.dim_type.OUT, (2 * d) + 1, 0)\n",
    "    return sche\n",
    "\n",
    "  def drop_dims1(sche: isl.map | isl.aff, redundancies: Tuple[int] = ()):\n",
    "    dims = list(set([*redundancies, *tensorized_dims]))\n",
    "    dims.sort()\n",
    "    j = 0\n",
    "    for i in range(len(dims)):\n",
    "      if isinstance(sche, isl.map):\n",
    "        sche = sche.project_out(isl.dim_type.IN, dims[i] - j, 1)\n",
    "      elif isinstance(sche, isl.pw_aff):\n",
    "        sche = sche.drop_dims(isl.dim_type.IN, dims[i] - j, 1)\n",
    "      else:\n",
    "        raise NotImplementedError\n",
    "      j += 1\n",
    "    return sche\n",
    "\n",
    "  def get_box(map: isl.map) -> isl.multi_val:\n",
    "    min = drop_dims1(map.intersect_domain(sched_domain_min))\n",
    "    max = drop_dims1(map.intersect_domain(sched_domain_max))\n",
    "    diff = max.as_pw_multi_aff().sub(min.as_pw_multi_aff())\n",
    "    assert diff.is_cst()\n",
    "    return diff.max_multi_val()\n",
    "\n",
    "  full_sche_map = isl.union_map.empty()\n",
    "  for info in schedule_info.comp_infos:\n",
    "    full_sche_map = full_sche_map.union(fix_dims(info.comp_schedule))\n",
    "  for info in schedule_info.trans_infos:\n",
    "    full_sche_map = full_sche_map.union(fix_dims(info.alloc_schedule))\n",
    "    full_sche_map = full_sche_map.union(fix_dims(info.trans_schedule))\n",
    "  alloc_info_map = {info.alloc_name: info for info in schedule_info.trans_infos}\n",
    "  trans_info_map = {info.trans_name: info for info in schedule_info.trans_infos}\n",
    "  comp_info_map = {info.comp_name: info for info in schedule_info.comp_infos}\n",
    "\n",
    "  def at_each_domain(node: isl.ast_node_user, build: isl.ast_build) -> isl.ast_node:\n",
    "    origin_expr = node.expr()\n",
    "    if not isinstance(origin_expr, isl.ast_expr_op_call):\n",
    "      return node\n",
    "\n",
    "    call_id: isl.ast_expr_id = origin_expr.op_arg(0)\n",
    "    call_id_name = call_id.id().name()\n",
    "    # alloc\n",
    "    if call_id_name in alloc_info_map:\n",
    "      info = alloc_info_map[call_id_name]\n",
    "      box_shape = info.box_hull.get_size()\n",
    "      rank = box_shape.size()\n",
    "      alloc = call_from(build, OpKind.Alloc, info.trans_name,\n",
    "                        *[box_shape.at(i) for i in range(rank)])\n",
    "      return isl.ast_node_user(alloc)\n",
    "\n",
    "    # trans\n",
    "    if call_id_name in trans_info_map:\n",
    "      info = trans_info_map[call_id_name]\n",
    "      pattern = detect_communication_pattern(self, info)\n",
    "      select_ranks = list(range(len(self.mesh.dims)))\n",
    "      match pattern:\n",
    "        case Broadcast():\n",
    "          select_ranks = list(filter(lambda i: i in pattern.axes, select_ranks))\n",
    "\n",
    "      def drop_dims2(x): return drop_dims1(x, info.redundancies)\n",
    "\n",
    "      src_shard_pma = info.access_shard_map.as_pw_multi_aff()\n",
    "      access_sche_pma = info.access_schedule.as_pw_multi_aff()\n",
    "      src_shard_pma = src_shard_pma.pullback(access_sche_pma)\n",
    "      if info.access_adapt_schedule:\n",
    "        src_shard_pma = src_shard_pma.pullback(info.access_adapt_schedule.as_pw_multi_aff())\n",
    "      src_rank = call_from(build, OpKind.Rank, *[drop_dims2(src_shard_pma.at(i))\n",
    "                           for i in select_ranks])\n",
    "\n",
    "      dest_rank_pma = info.access_map.domain().identity().as_pw_multi_aff()\n",
    "      dest_rank_pma = dest_rank_pma.pullback(access_sche_pma)\n",
    "      dest_rank = call_from(build, OpKind.Rank, *\n",
    "                            [drop_dims2(dest_rank_pma.at(i)) for i in select_ranks])\n",
    "\n",
    "      src_tensor_box = get_box(info.access_shard_map)\n",
    "      src_slice = call_from(build, OpKind.Access, info.access_shard_map.tuple_name(isl.dim_type.OUT),\n",
    "                            *[call_from(build, OpKind.Slice, drop_dims2(src_shard_pma.at(i)),\n",
    "                                        drop_dims2(src_shard_pma.at(i)).add_constant(src_tensor_box.at(i)).add_constant(1))\n",
    "                              for i in range(len(self.mesh.dims), src_shard_pma.dim(isl.dim_type.OUT))])\n",
    "\n",
    "      dest_start_pma = info.box_hull.get_offset().as_pw_multi_aff()\n",
    "      dest_origin_pma = info.access_map.as_pw_multi_aff()\n",
    "      dest_tensor_box = get_box(info.access_map)\n",
    "      dest_pma = dest_origin_pma.sub(dest_start_pma)\n",
    "      dest_pma = dest_pma.pullback(access_sche_pma)\n",
    "      dest_slice = call_from(build, OpKind.Access, info.trans_name,\n",
    "                             *[call_from(build, OpKind.Slice, drop_dims2(dest_pma.at(i)),\n",
    "                                         drop_dims2(dest_pma.at(i)).add_constant(dest_tensor_box.at(i)).add_constant(1))\n",
    "                               for i in range(dest_pma.size())])\n",
    "\n",
    "      trans = call_from(build, OpKind.Trans, pattern.build_call(build),\n",
    "                        src_slice, src_rank, dest_slice, dest_rank)\n",
    "      return isl.ast_node_user(trans)\n",
    "    if call_id_name in comp_info_map:\n",
    "      info = comp_info_map[call_id_name]\n",
    "      access_exprs = []\n",
    "      for access in self.accesses:\n",
    "        trans_name = OpKind.Trans.name + access.buffer.name\n",
    "        if trans_name in trans_info_map:\n",
    "          trans_info = trans_info_map[trans_name]\n",
    "          access_sche_pma = trans_info.access_schedule.as_pw_multi_aff()\n",
    "          dest_start_pma = trans_info.box_hull.get_offset().as_pw_multi_aff()\n",
    "          dest_origin_pma = trans_info.access_map.as_pw_multi_aff()\n",
    "          dest_tensor_box = get_box(trans_info.access_map)\n",
    "          dest_pma = dest_origin_pma.sub(dest_start_pma)\n",
    "          dest_pma = dest_pma.pullback(access_sche_pma)\n",
    "          access_exprs.append(call_from(build, OpKind.Access, trans_name, *\n",
    "                              [call_from(build, OpKind.Slice, drop_dims1(dest_pma.at(i)), drop_dims1(dest_pma.at(i)).add_constant(dest_tensor_box.at(i)).add_constant(1))\n",
    "                               for i in range(dest_pma.size())]))\n",
    "        else:\n",
    "          access_shard_map = self.schedule.reverse().apply_range(\n",
    "              access.relation).apply_range(access.buffer.sharding)\n",
    "          dest_shard_pma = access_shard_map.as_pw_multi_aff()\n",
    "          dest_tensor_box = get_box(access_shard_map)\n",
    "          dest_slice = call_from(build, OpKind.Access, access.buffer.name, *[\n",
    "              call_from(build, OpKind.Slice, drop_dims1(dest_shard_pma.at(i)),\n",
    "                        drop_dims1(dest_shard_pma.at(i)).add_constant(dest_tensor_box.at(i)).add_constant(1))\n",
    "              for i in range(len(self.mesh.dims), dest_shard_pma.dim(isl.dim_type.OUT))])\n",
    "          access_exprs.append(dest_slice)\n",
    "      call_expr = call_from(build, info.assign_kind,\n",
    "                            access_exprs[0],\n",
    "                            call_from(build, info.op_kind, access_exprs[1], access_exprs[2]))\n",
    "      return isl.ast_node_user(call_expr)\n",
    "    return node\n",
    "\n",
    "  builtin_iters = list(map(str, self.mesh.dims))\n",
    "\n",
    "  def at_each_for(node: isl.ast_node_for, build: isl.ast_build) -> isl.ast_node:\n",
    "    it = node.get_iterator()\n",
    "    if isinstance(it, isl.ast_expr_id) and it.id().name() in builtin_iters:\n",
    "      node = node.set_annotation(IterKind.Distributed.name)\n",
    "    return node\n",
    "\n",
    "  ast_build = isl.ast_build()\n",
    "  ast_build = ast_build.set_at_each_domain(at_each_domain)\n",
    "  ast_build = ast_build.set_after_each_for(at_each_for)\n",
    "  iter_ids = []\n",
    "  ndim = len(self.iter_vars)\n",
    "  comp_schedule = schedule_info.comp_infos[0].comp_schedule\n",
    "  iter_kinds = {k.name: v for (k, v) in self.iter_kinds.items()}\n",
    "  for i in range(ndim):\n",
    "    iter_ids.append(f'c{i}')\n",
    "    name = comp_schedule.dim_name(isl.dim_type.OUT, 2 * i + 1)\n",
    "    if iter_kinds.get(name) is IterKind.Distributed:\n",
    "      name = str(self.mesh.dims[i])\n",
    "    iter_ids.append(name)\n",
    "  ast_build = ast_build.set_iterators('(' + ','.join(iter_ids) + ')')\n",
    "  ast_node = ast_build.node_from_schedule_map(full_sche_map)\n",
    "  return ast_node\n",
    "\n",
    "\n",
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_computation = lower_computation(s0_communicated)\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.flush()\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f850cfc",
   "metadata": {},
   "source": [
    "到这里一步，我们已经得到了相对完善的伪代码，不过可以发现都是完全循环的，相对性能较低。这里再添加一个`tensorize`的调度，把维度进行折叠："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9793ba96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computation(op=<OpKind.MatMul: 131>, domain=isl.set(\"{ s0[k, m, n] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 }\"), schedule=isl.map(\"{ s0[k, m, n] -> s0[mo, no, ko, mi = m - 64mo, ni = n - 128no, ki = k - 256ko] : 0 <= k <= 2047 and 0 <= m <= 511 and 0 <= n <= 1023 and -63 + m <= 64mo <= m and -127 + n <= 128no <= n and -255 + k <= 256ko <= k }\"), accesses=(Access(buffer=Buffer(name='C', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ C[m, n] -> C[x, y, m - 64x, local_n = n - 128y] : 0 <= m <= 511 and 0 <= n <= 1023 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Output: 1>), relation=isl.map(\"{ s0[k, m, n] -> C[m, n] }\")), Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\"))), iter_vars=(IterVar(name='mo', lower_bound=None, upper_bound=None, step=1), IterVar(name='no', lower_bound=None, upper_bound=None, step=1), IterVar(name='ko', lower_bound=None, upper_bound=None, step=1), IterVar(name='mi', lower_bound=None, upper_bound=None, step=1), IterVar(name='ni', lower_bound=None, upper_bound=None, step=1), IterVar(name='ki', lower_bound=None, upper_bound=None, step=1)), mesh=Mesh(dims=(IterVar(name='x', lower_bound=0, upper_bound=8, step=1), IterVar(name='y', lower_bound=0, upper_bound=8, step=1))), iter_kinds={IterVar(name='mo', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='no', lower_bound=None, upper_bound=None, step=1): <IterKind.Distributed: 1>, IterVar(name='mi', lower_bound=None, upper_bound=None, step=1): <IterKind.Tensorize: 2>, IterVar(name='ni', lower_bound=None, upper_bound=None, step=1): <IterKind.Tensorize: 2>, IterVar(name='ki', lower_bound=None, upper_bound=None, step=1): <IterKind.Tensorize: 2>}, dim_bindings={1: [AccessDimIndex(access_idx=0, buffer_dim=0), AccessDimIndex(access_idx=1, buffer_dim=0)], 2: [AccessDimIndex(access_idx=0, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=1)], 0: [AccessDimIndex(access_idx=1, buffer_dim=1), AccessDimIndex(access_idx=2, buffer_dim=0)]}, transfers={IterVar(name='ko', lower_bound=None, upper_bound=None, step=1): (Transfer(access=Access(buffer=Buffer(name='B', dims=(IterVar(name='k', lower_bound=0, upper_bound=2048, step=1), IterVar(name='n', lower_bound=0, upper_bound=1024, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ B[k, n] -> B[x, y, k - 256x, local_n = n - 128y] : 0 <= k <= 2047 and 0 <= n <= 1023 and 0 <= x <= 7 and -255 + k <= 256x <= k and 0 <= y <= 7 and -127 + n <= 128y <= n }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> B[k, n] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo' = mo, no' = no, ko' = ko, mi' = mi, ni' = ni, ki' = ki] : mi >= 0 and -64mo <= mi <= 511 - 64mo and mi <= 63 and ni >= 0 and -128no <= ni <= 1023 - 128no and ni <= 127 and ki >= 0 and -256ko <= ki <= 2047 - 256ko and ki <= 255 }\")), Transfer(access=Access(buffer=Buffer(name='A', dims=(IterVar(name='m', lower_bound=0, upper_bound=512, step=1), IterVar(name='k', lower_bound=0, upper_bound=2048, step=1)), dtype=Float32Type(), sharding=isl.map(\"{ A[m, k] -> A[x, y, m - 64x, local_k = k - 256y] : 0 <= m <= 511 and 0 <= k <= 2047 and 0 <= x <= 7 and -63 + m <= 64x <= m and 0 <= y <= 7 and -255 + k <= 256y <= k }\"), usage=<UsageKind.Input: 0>), relation=isl.map(\"{ s0[k, m, n] -> A[m, k] }\")), schedule=isl.map(\"{ s0[mo, no, ko, mi, ni, ki] -> s0[mo, no, ko_r, mi, ni, ki] : (-no - ko + ko_r) mod 8 = 0 and 0 <= no <= 7 and 0 <= ko <= 7 and 0 <= ko_r <= 7 }\")))})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tensorize(self: Computation, vars: List[IterVar], new_op: OpKind = None):\n",
    "  new_kinds = self.iter_kinds.copy()\n",
    "  for var in vars:\n",
    "    assert new_kinds.get(var, None) in (None, IterKind.Serial)\n",
    "    new_kinds[var] = IterKind.Tensorize\n",
    "  if new_op:\n",
    "    self = replace(self, op=new_op)\n",
    "  return replace(self, iter_kinds=new_kinds)\n",
    "\n",
    "\n",
    "Computation.tensorize = tensorize\n",
    "\n",
    "s0_tensorized = s0_communicated.tensorize([mi, ni, ki], OpKind.MatMul)\n",
    "s0_tensorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e622a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int ko = 0; ko <= 7; ko += 1) {\n",
      "      Alloc(TransB, 256, 128);\n",
      "      Trans(CommBroadcast(0), Access(B, Slice(0, 256), Slice(0, 128)), Rank((y + ko) % 8), Access(TransB, Slice(0, 256), Slice(0, 128)), Rank(x));\n",
      "      Alloc(TransA, 64, 256);\n",
      "      Trans(CommShift(1, 1), Access(A, Slice(0, 64), Slice(0, 256)), Rank(x, (y + ko) % 8), Access(TransA, Slice(0, 64), Slice(0, 256)), Rank(x, y));\n",
      "      AugAssign(Access(C, Slice(0, 64), Slice(0, 128)), MatMul(Access(TransA, Slice(0, 64), Slice(0, 256)), Access(TransB, Slice(0, 256), Slice(0, 128))));\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_computation = lower_computation(s0_tensorized)\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.flush()\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaaa38c",
   "metadata": {},
   "source": [
    "现在我们获得了计算部分的ast，为了让他可以正常执行，还需要准备输入输出。 这里我直接对`Access`进行代码生成："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a31144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alloc(C, 64, 128);\n",
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int m = 0; m <= 63; m += 1)\n",
      "      for (int n = 0; n <= 127; n += 1)\n",
      "        AssertEqual(Access(C, m, n), Access(GlobalC, 64 * x + m, 128 * y + n));\n",
      "Alloc(A, 64, 256);\n",
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int m = 0; m <= 63; m += 1)\n",
      "      for (int k = 0; k <= 255; k += 1)\n",
      "        Assign(Access(A, m, k), Access(GlobalA, 64 * x + m, 256 * y + k));\n",
      "Alloc(B, 256, 128);\n",
      "for (int x = 0; x <= 7; x += 1)\n",
      "  for (int y = 0; y <= 7; y += 1)\n",
      "    for (int k = 0; k <= 255; k += 1)\n",
      "      for (int n = 0; n <= 127; n += 1)\n",
      "        Assign(Access(B, k, n), Access(GlobalB, 256 * x + k, 128 * y + n));\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lower_shard(self: Computation, access: Access) -> Tuple[isl.ast_build, isl.ast_build]:\n",
    "  sharding = access.buffer.sharding\n",
    "  assert sharding\n",
    "  builtin_iters = list(map(str, self.mesh.dims))\n",
    "\n",
    "  access_global_map = sharding.reverse().set_tuple_id(\n",
    "      isl.dim_type.OUT, 'Global' + access.buffer.name)\n",
    "\n",
    "  redundancies = []\n",
    "  cons_free_map = access_global_map.drop_constraints_not_involving_dims(\n",
    "      isl.dim_type.OUT, 0, access_global_map.dim(isl.dim_type.OUT))\n",
    "  for i in range(0, access_global_map.dim(isl.dim_type.IN)):\n",
    "    if not cons_free_map.involves_dims(isl.dim_type.IN, i, 1):\n",
    "      redundancies.append(i)\n",
    "\n",
    "  access_global_pma = access_global_map.as_pw_multi_aff()\n",
    "  access_global_domain = sharding.reverse().domain()\n",
    "  buffer_local_shape = access_global_domain.project_out(\n",
    "      isl.dim_type.SET, 0, len(self.mesh.dims)).simple_fixed_box_hull().size()\n",
    "  access_local_map = sharding.reverse().domain().identity().project_out(\n",
    "      isl.dim_type.OUT, 0, len(self.mesh.dims)).set_range_tuple(access.buffer.name)\n",
    "  access_local_pma = access_local_map.as_pw_multi_aff()\n",
    "\n",
    "  ast_build = isl.ast_build()\n",
    "\n",
    "  def at_each_domain(node: isl.ast_node_user, build: isl.ast_build) -> isl.ast_node:\n",
    "    \n",
    "    access_global = call_from(build, OpKind.Access, access_global_pma.tuple_name(\n",
    "        isl.dim_type.OUT), *[drop_dims(access_global_pma.at(i), redundancies) for i in range(access_global_pma.size())])\n",
    "    access_local = call_from(build, OpKind.Access, access_local_pma.tuple_name(\n",
    "        isl.dim_type.OUT), *[drop_dims(access_local_pma.at(i), redundancies) for i in range(access_local_pma.size())])\n",
    "\n",
    "    call = call_from(build, OpKind.Assign if access.buffer.usage ==\n",
    "                     UsageKind.Input else OpKind.AssertEqual, access_local, access_global)\n",
    "    return isl.ast_node_user(call)\n",
    "\n",
    "  def at_each_for(node: isl.ast_node_for, build: isl.ast_build) -> isl.ast_node:\n",
    "    it = node.get_iterator()\n",
    "    if isinstance(it, isl.ast_expr_id) and it.id().name() in builtin_iters:\n",
    "      node = node.set_annotation(IterKind.Distributed.name)\n",
    "    return node\n",
    "\n",
    "  ast_build = ast_build.set_at_each_domain(at_each_domain)\n",
    "  ast_build = ast_build.set_after_each_for(at_each_for)\n",
    "  ast_build = ast_build.set_iterators(\n",
    "      '(' + ', '.join(map(str, chain(self.mesh.dims, access.buffer.dims))) + ')')\n",
    "  ast_node = ast_build.node_from_schedule_map(sharding.range().identity())\n",
    "  alloc = isl.ast_node_user(call_from(ast_build, OpKind.Alloc, access.buffer.name, *\n",
    "                                      [buffer_local_shape.at(i) for i in range(buffer_local_shape.size())]))\n",
    "  return (alloc, ast_node)\n",
    "\n",
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_shard_buffer_0 = lower_shard(s0_communicated, s0_communicated.accesses[0])\n",
    "  ast_shard_buffer_1 = lower_shard(s0_communicated, s0_communicated.accesses[1])\n",
    "  ast_shard_buffer_2 = lower_shard(s0_communicated, s0_communicated.accesses[2])\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_shard_buffer_0[0].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_0[1].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_1[0].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_1[1].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_2[0].print(printer, print_options)\n",
    "  printer = ast_shard_buffer_2[1].print(printer, print_options)\n",
    "  printer.flush()\n",
    "  \n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c0727",
   "metadata": {},
   "source": [
    "具备了全部的ast之后，要生成对应的后端代码。isl提供了printer给用户，我则添加了一个python style的printer实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d25adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_python_style_item(printer: isl.printer, item: isl.ast_expr | str):\n",
    "  match item:\n",
    "    case str():\n",
    "      printer.print_str(item)\n",
    "    case isl.ast_expr():\n",
    "      expr = item\n",
    "      match expr:\n",
    "        case isl.ast_expr_op_call():\n",
    "          op_name = expr.get_op_arg(0).id().name()\n",
    "          match op_name:\n",
    "            case OpKind.Access.name:\n",
    "              print_python_style_item(printer, expr.get_op_arg(1))  # buffer name\n",
    "              printer.print_str(\"[\")\n",
    "              for i in range(2, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(\"]\")\n",
    "            case OpKind.Rank.name:\n",
    "              printer.print_str(\"[\")\n",
    "              for i in range(1, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(\"]\")\n",
    "            case OpKind.Assign.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" = \", expr.get_op_arg(2))\n",
    "            case OpKind.AugAssign.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" += \", expr.get_op_arg(2))\n",
    "            case OpKind.Slice.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \":\", expr.get_op_arg(2))\n",
    "              if expr.op_n_arg() > 3:\n",
    "                printer.print_str(\":\")\n",
    "                print_python_style_item(printer, expr.get_op_arg(3))\n",
    "            case OpKind.Alloc.name:\n",
    "              print_python_style_item(printer, expr.get_op_arg(1))\n",
    "              printer.print_str(\" = np.zeros([\")\n",
    "              for i in range(2, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(\"])\")\n",
    "            case OpKind.AssertEqual.name:\n",
    "              print_python_style_items(printer, \"assert np.allclose(\", expr.get_op_arg(1), \", \", expr.get_op_arg(2), \")\")\n",
    "            case OpKind.Trans.name:\n",
    "              printer.print_str(op_name)\n",
    "              printer.print_str('(')\n",
    "              for i in range(1, expr.op_n_arg()):\n",
    "                print_python_style_item(printer, expr.get_op_arg(i))\n",
    "                printer.print_str(\", \"[i - expr.op_n_arg():-1])\n",
    "              printer.print_str(')')\n",
    "            case OpKind.Mul.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" * \", expr.get_op_arg(2))\n",
    "            case OpKind.MatMul.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \" @ \", expr.get_op_arg(2))\n",
    "            case OpKind.MatMulTransA.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(1), \".T\", \" @ \", expr.get_op_arg(2))\n",
    "            case OpKind.CommShift.name:\n",
    "              print_python_style_items(printer, expr.get_op_arg(0), \"(\")\n",
    "              print_python_style_item(printer, '(')\n",
    "              for i in range(1, expr.op_n_arg() - 1):\n",
    "                print_python_style_items(printer, expr.get_op_arg(i), ',')\n",
    "              print_python_style_item(printer, '),')\n",
    "              print_python_style_item(printer, expr.get_op_arg(expr.op_n_arg() - 1))\n",
    "              print_python_style_item(printer, ')')\n",
    "            case _:\n",
    "              printer.print_ast_expr(expr)\n",
    "        case _:\n",
    "          printer.print_ast_expr(expr)\n",
    "    case _:\n",
    "      raise NotImplementedError()\n",
    "\n",
    "\n",
    "def print_python_style_items(printer: isl.printer, *items: List[isl.ast_expr | str]):\n",
    "  for item in items:\n",
    "    print_python_style_item(printer, item)\n",
    "\n",
    "\n",
    "def print_python_style_user(printer: isl.printer, options: isl.ast_print_options, node: isl.ast_node):\n",
    "  expr: isl.ast_expr = node.get_expr()\n",
    "  printer.start_line()\n",
    "  print_python_style_item(printer, expr)\n",
    "  printer.end_line()\n",
    "  return printer\n",
    "\n",
    "\n",
    "def print_python_style_for(printer: isl.printer, options: isl.ast_print_options, node: isl.ast_node_for):\n",
    "  (it, init, cond, inc) = node.get_iterator(), node.get_init(), node.get_cond(), node.get_inc()\n",
    "  omit = False\n",
    "  try:\n",
    "    anno = node.annotation()\n",
    "    if anno.name() == IterKind.Distributed.name:\n",
    "      omit = True\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  if not omit:\n",
    "    printer.start_line()\n",
    "    print_python_style_items(printer, \"for \", it, \" in range(\", init,\n",
    "                             \", \", cond.get_arg(1), \" + 1\", \", \", inc, \"):\\n\")\n",
    "    printer = printer.indent(4)\n",
    "  printer = node.get_body().print(printer, options)\n",
    "  if not omit:\n",
    "    printer = printer.indent(-4)\n",
    "  return printer\n",
    "\n",
    "\n",
    "def print_python_style_block(printer: isl.printer, options: isl.ast_print_options, node: isl.ast_node_block):\n",
    "  children = node.get_children()\n",
    "  for i in range(children.size()):\n",
    "    printer = children.get_at(i).print(printer, options)\n",
    "  return printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4325608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ko in range(0, 7 + 1, 1):\n",
      "    TransB = np.zeros([256,128])\n",
      "    Trans(CommBroadcast(0),B[0:256,0:128],[(y + ko) % 8],TransB[0:256,0:128],[x])\n",
      "    TransA = np.zeros([64,256])\n",
      "    Trans(CommShift((1,),1),A[0:64,0:256],[x,(y + ko) % 8],TransA[0:64,0:256],[x,y])\n",
      "    C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('tmp/pumma.py', 'w') as f:\n",
    "  ast_computation = lower_computation(s0_tensorized)\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  print_options = print_options.set_print_for(print_python_style_for)\n",
    "  print_options = print_options.set_print_user(print_python_style_user)\n",
    "  print_options = print_options.set_print_block(print_python_style_block)\n",
    "  printer.set_output_format(isl.format.C)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.flush()\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679c62d",
   "metadata": {},
   "source": [
    "在生成ast的过程中，我使用了统一的通信操作api，包括这些api以及一些setup的代码，需要放到runtime中实现。不过它们并不包含在compile的过程中，为了简单起见，采用直接构造字符串写入文件的方式来处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52544aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codegen_setup(self: Computation, printer: isl.printer) -> isl.printer:\n",
    "  printer.print_str('import numpy as np\\n')\n",
    "  printer.print_str('from mpi4py import MPI\\n')\n",
    "  printer.print_str('from enum import IntEnum\\n')\n",
    "  printer.print_str('import sys\\n')\n",
    "  printer.print_str('RANK = MPI.COMM_WORLD.Get_rank()\\n')\n",
    "  printer.print_str(f'MESH = [{\",\".join(map(str, self.mesh.shape))}]\\n')\n",
    "  printer.print_str(f'COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\\n')\n",
    "  printer.print_str(f\"({','.join(map(str, self.mesh.dims))},) = PIDS = COMM_ALL.Get_coords(RANK)\\n\")\n",
    "\n",
    "  printer.print_str(f\"\"\"\n",
    "\n",
    "class CommBroadcast:\n",
    "  def __init__(self, *axes: int):\n",
    "    self.axes: tuple[int] = axes\n",
    "\n",
    "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
    "    src_rank = comm.Get_cart_rank(source)\n",
    "    if comm.Get_rank() == src_rank:\n",
    "      np.copyto(recvbuf, srcbuf)\n",
    "    comm.Bcast(recvbuf, root=src_rank)\n",
    "\n",
    "class CommShift:\n",
    "  def __init__(self, axes: tuple[int], delta: int):\n",
    "    self.axes: tuple[int] = axes\n",
    "    self.delta: int = delta\n",
    "\n",
    "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
    "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
    "      src_rank = COMM_ALL.Get_cart_rank(\n",
    "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
    "      dest_rank = COMM_ALL.Get_cart_rank(\n",
    "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
    "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
    "    np.copyto(recvbuf, srcbuf)\n",
    "\n",
    "\n",
    "class CommSendrecv:\n",
    "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
    "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
    "\n",
    "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
    "  comm(srcbuf, source, recvbuf, dest)\n",
    "\n",
    "\"\"\")\n",
    "  return printer\n",
    "\n",
    "\n",
    "def codegen_computation(self: Computation, printer: isl.printer, ast_computation: isl.ast_node):\n",
    "  printer.print_str(f\"def computation({', '.join([a.buffer.name for a in self.accesses])}):\\n\")\n",
    "  printer.set_indent(4)\n",
    "  printer = ast_computation.print(printer, print_options)\n",
    "  printer.set_indent(-4)\n",
    "  printer.end_line()\n",
    "  return printer\n",
    "\n",
    "\n",
    "def codegen_main(self: Computation, printer: isl.printer, ast_inputs: List[isl.ast_node], ast_outputs: List[isl.ast_node]):\n",
    "  printer.print_str('if __name__ == \"__main__\":\\n')\n",
    "  for i, access in enumerate(self.accesses):\n",
    "    printer.print_str(\n",
    "        f'    Global{access.buffer.name} = np.load(sys.argv[{i + 1}], mmap_mode=\"r\")\\n')\n",
    "\n",
    "  printer.set_indent(4)\n",
    "  for in_ast in ast_inputs:\n",
    "    printer = in_ast[0].print(printer, print_options)\n",
    "    printer = in_ast[1].print(printer, print_options)\n",
    "  for out_ast in ast_outputs:\n",
    "    printer = out_ast[0].print(printer, print_options)\n",
    "  printer.print_str(f\"    computation({', '.join([a.buffer.name for a in self.accesses])})\\n\")\n",
    "  for out_ast in ast_outputs:\n",
    "    printer = out_ast[1].print(printer, print_options)\n",
    "  printer.print_str(\"    print(f\\\"rank [{','.join(map(str,PIDS))}] passed!\\\")\")\n",
    "  printer.set_indent(-4)\n",
    "  printer.end_line()\n",
    "  return printer\n",
    "\n",
    "\n",
    "def codegen_full(self: Computation, f: FileIO, ast_inputs: List[isl.ast_node], ast_outputs: List[Tuple[isl.ast_node, isl.ast_node]], ast_computation: isl.ast_node):\n",
    "  printer = isl.printer.to_file(f)\n",
    "  print_options = isl.ast_print_options.alloc()\n",
    "  print_options = print_options.set_print_for(print_python_style_for)\n",
    "  print_options = print_options.set_print_user(print_python_style_user)\n",
    "  print_options = print_options.set_print_block(print_python_style_block)\n",
    "  printer.set_output_format(isl.format.C)\n",
    "\n",
    "  printer = codegen_setup(self, printer)\n",
    "  printer = codegen_computation(self, printer, ast_computation)\n",
    "  printer = codegen_main(self, printer, ast_inputs, ast_outputs)\n",
    "\n",
    "  printer.flush()\n",
    "\n",
    "\n",
    "def lower_and_codegen(self: Computation, f: FileIO):\n",
    "  ast_shard_inputs = [lower_shard(self, access)\n",
    "                      for access in self.accesses if access.buffer.usage == UsageKind.Input]\n",
    "  ast_shard_outputs = [lower_shard(self, access)\n",
    "                       for access in self.accesses if access.buffer.usage == UsageKind.Output]\n",
    "  ast_computation = lower_computation(self)\n",
    "  codegen_full(self, f, ast_shard_inputs, ast_shard_outputs, ast_computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd7e25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [8,8]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,y,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for ko in range(0, 7 + 1, 1):\n",
      "        TransB = np.zeros([256,128])\n",
      "        Trans(CommBroadcast(0),B[0:256,0:128],[(y + ko) % 8],TransB[0:256,0:128],[x])\n",
      "        TransA = np.zeros([64,256])\n",
      "        Trans(CommShift((1,),1),A[0:64,0:256],[x,(y + ko) % 8],TransA[0:64,0:256],[x,y])\n",
      "        C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([64,256])\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for k in range(0, 255 + 1, 1):\n",
      "            A[m,k] = GlobalA[64 * x + m,256 * y + k]\n",
      "    B = np.zeros([256,128])\n",
      "    for k in range(0, 255 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            B[k,n] = GlobalB[256 * x + k,128 * y + n]\n",
      "    C = np.zeros([64,128])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[64 * x + m,128 * y + n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"tmp/pumma.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/pumma.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f636fa1",
   "metadata": {},
   "source": [
    "开始创建输入并执行程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8101555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arrA = np.random.rand(512, 2048).astype(np.float32)\n",
    "arrB = np.random.rand(2048, 1024).astype(np.float32)\n",
    "np.save(\"tmp/arrA.npy\", arrA)\n",
    "np.save(\"tmp/arrB.npy\", arrB)\n",
    "np.save(\"tmp/arrC.npy\", arrA @ arrB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27053ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 64 python tmp/pumma.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f95a20",
   "metadata": {},
   "source": [
    "# 总结\n",
    "\n",
    "在实现上述功能的时候有一些想法和大家分享一下：\n",
    "1. 计算调度和分布式存储调度是相互影响的，比如cannon算法，正确的分布数据与ring的通信方式是相互依赖的，缺少任何一个都将导致结果错误。这一点其实极大的限制了schedule language的，因为许多特殊的分布式计算方法很难从原始的index notation一步步调度过去。\n",
    "2. 目前基本上都是tile-based的硬件，从index notation到多面体表示再raise到tensor级别会引入非常复杂的index处理过程，未来应该直接在tile的基础上配合多面体进行调度优化。\n",
    "3. 虽然引入支持任意通信的后端会扩大调度搜索域，但其实高性能的通信模式还是常用的几种，最终应该还是会类似coalesced memory access一样offload过去。\n",
    "4. AI编译器可以考虑就基于ring/broadcast/p2p的通信方式构建搜索域，其中的主要难点应该是如何调整time dimension和distributed dimension的映射。\n",
    "5. distal的作者的新论文[Task-Based Tensor Computations on Modern GPUs](https://rohany.github.io/publications/pldi2025-cypress.pdf)也是一种很好的解决方案，值得学习。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708732b9",
   "metadata": {},
   "source": [
    "# Examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94340e31",
   "metadata": {},
   "source": [
    "## AllGather + Gemm\n",
    "\n",
    "参考nvida的[cublasmp文档](https://docs.nvidia.com/cuda/cublasmp/usage/tp.html), 用index notation的方式表示其计算流程为`C[m @ x,n] = A[k,m @ x].T @ B[k,n @ x]`. 也就是`A/B`矩阵的`m/n`被分布在一维拓扑上，但输出`c`只有`m`被分布，因此计算时数据依赖所有的`n`. 朴素的计算方式是通过在每个进程上通过`AllGather`收集完整的`B`矩阵，然后执行`C[m @ x, n] = A[k, m @ x].T @ B[k, n]`运算得到结果。 \n",
    "\n",
    "但是在本文中，通过多面体分析，只需要用户指定在`n`维度迭代时进行通信，就可以自动在计算中加载正确的`B`矩阵进行运算，实现了通算融合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd2e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ctx.parse_program\n",
    "def ag_matmul(A: Buffer[float, [1024, 2048]], B: Buffer[float, [1024, 4096]], C: Buffer[float, [2048, 4096]], m: IterVar, n: IterVar, k: IterVar) -> Buffer[float, [2048, 4096]]:\n",
    "  C[m, n] = A[k, m] * B[k, n]\n",
    "  return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97f2f228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [4]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for no in range(0, 3 + 1, 1):\n",
      "        TransB = np.zeros([1024,1024])\n",
      "        Trans(CommBroadcast(0),B[0:1024,0:1024],[no],TransB[0:1024,0:1024],[x])\n",
      "        C[0:512,1024 * no:1024 * no + 1024] += A[0:1024,0:512].T @ TransB[0:1024,0:1024]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([1024,512])\n",
      "    for k in range(0, 1023 + 1, 1):\n",
      "        for m in range(0, 511 + 1, 1):\n",
      "            A[k,m] = GlobalA[k,512 * x + m]\n",
      "    B = np.zeros([1024,1024])\n",
      "    for k in range(0, 1023 + 1, 1):\n",
      "        for n in range(0, 1023 + 1, 1):\n",
      "            B[k,n] = GlobalB[k,1024 * x + n]\n",
      "    C = np.zeros([512,4096])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 511 + 1, 1):\n",
      "        for n in range(0, 4095 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[512 * x + m,n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s0 = polyhedron_extract(ag_matmul) # extract to polyhedron.\n",
    "\n",
    "k, m, n = s0.iter_vars\n",
    "x = IterVar.range('x', 4) # mesh axis\n",
    "\n",
    "no, ni, mo, mi = IterVar.symbol('no ni mo mi')\n",
    "s0_tensorized = s0.distribute([m], [mo], [mi], Mesh((x,))). \\\n",
    "    divide(n, no, ni, x.extent). \\\n",
    "    reorder(mo, no, mi, ni, k). \\\n",
    "    shard('A', m @ x).shard('B', n @ x).shard('C', m @ x). \\\n",
    "    communicate('B', no). \\\n",
    "    tensorize([mi, ni, k], OpKind.MatMulTransA)\n",
    "\n",
    "with open(\"tmp/ag_matmul.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/ag_matmul.py', 'r') as f:\n",
    "  print(f.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93a0b9",
   "metadata": {},
   "source": [
    "使用numpy构造输入输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec080f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m, k, n = 2048, 1024, 4096\n",
    "arrA = np.random.randn(k, m)\n",
    "arrB = np.random.randn(k, n)\n",
    "np.save(\"tmp/arrA.npy\", arrA)\n",
    "np.save(\"tmp/arrB.npy\", arrB)\n",
    "np.save(\"tmp/arrC.npy\", arrA.T @ arrB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de1c8a",
   "metadata": {},
   "source": [
    "并通过mpi4py进行验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae37b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 4 python tmp/ag_matmul.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641466b9",
   "metadata": {},
   "source": [
    "## SUMMA\n",
    "\n",
    "关于SUMMA的细节介绍可以参考我之前文章：[分布式存储架构下的矩阵乘与编译器](https://zhuanlan.zhihu.com/p/6906641426) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3025f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [8,8]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,y,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for ko in range(0, 7 + 1, 1):\n",
      "        TransB = np.zeros([256,128])\n",
      "        Trans(CommBroadcast(0),B[0:256,0:128],[ko],TransB[0:256,0:128],[x])\n",
      "        TransA = np.zeros([64,256])\n",
      "        Trans(CommBroadcast(1),A[0:64,0:256],[ko],TransA[0:64,0:256],[y])\n",
      "        C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([64,256])\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for k in range(0, 255 + 1, 1):\n",
      "            A[m,k] = GlobalA[64 * x + m,256 * y + k]\n",
      "    B = np.zeros([256,128])\n",
      "    for k in range(0, 255 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            B[k,n] = GlobalB[256 * x + k,128 * y + n]\n",
      "    C = np.zeros([64,128])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[64 * x + m,128 * y + n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@ctx.parse_program\n",
    "def matmul(A: Buffer[float, [512, 2048]], B: Buffer[float, [2048, 1024]], C: Buffer[float, [512, 1024]], m: IterVar, n: IterVar, k: IterVar) -> Buffer[float, [512, 1024]]:\n",
    "  C[m, n] = A[m, k] * B[k, n]\n",
    "  return C\n",
    "  \n",
    "s0 = polyhedron_extract(matmul)\n",
    "\n",
    "k, m, n = s0.iter_vars\n",
    "x, y = IterVar.range('x', 8), IterVar.range('y', 8)\n",
    "mo, no, mi, ni = IterVar.symbol('mo no mi ni')\n",
    "ko, ki = IterVar.symbol('ko ki')\n",
    "s0_tensorized = s0.distribute([m, n], [mo, no], [mi, ni], Mesh((x, y))). \\\n",
    "    divide(k, ko, ki, x.extent). \\\n",
    "    reorder(mo, no, ko, mi, ni, ki). \\\n",
    "    shard('A', m @ x, k @ y). \\\n",
    "    shard('B', k @ x, n @ y). \\\n",
    "    shard('C', m @ x, n @ y). \\\n",
    "    communicate('A', ko). \\\n",
    "    communicate('B', ko). \\\n",
    "    tensorize([mi, ni, ki], OpKind.MatMul)\n",
    "\n",
    "with open(\"tmp/summa.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/summa.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820be2c",
   "metadata": {},
   "source": [
    "使用numpy构造输入输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36bdabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "m, k, n = 512, 2048, 1024\n",
    "arrA = np.random.randn(m, k)\n",
    "arrB = np.random.randn(k, n)\n",
    "np.save(\"tmp/arrA.npy\", arrA)\n",
    "np.save(\"tmp/arrB.npy\", arrB)\n",
    "np.save(\"tmp/arrC.npy\", arrA @ arrB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4e9efa",
   "metadata": {},
   "source": [
    "并通过mpi4py进行验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12281d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 64 python tmp/summa.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ab9cf",
   "metadata": {},
   "source": [
    "## Cannon\n",
    "\n",
    "细节可以参考我之前文章：[分布式存储架构下的矩阵乘与编译器](https://zhuanlan.zhihu.com/p/6906641426) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "121e53d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "from mpi4py import MPI\n",
      "from enum import IntEnum\n",
      "import sys\n",
      "RANK = MPI.COMM_WORLD.Get_rank()\n",
      "MESH = [8,8]\n",
      "COMM_ALL = MPI.COMM_WORLD.Create_cart(MESH)\n",
      "(x,y,) = PIDS = COMM_ALL.Get_coords(RANK)\n",
      "\n",
      "\n",
      "class CommBroadcast:\n",
      "  def __init__(self, *axes: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    comm = COMM_ALL.Sub([True if i in self.axes else False for i in range(len(PIDS))])\n",
      "    src_rank = comm.Get_cart_rank(source)\n",
      "    if comm.Get_rank() == src_rank:\n",
      "      np.copyto(recvbuf, srcbuf)\n",
      "    comm.Bcast(recvbuf, root=src_rank)\n",
      "\n",
      "class CommShift:\n",
      "  def __init__(self, axes: tuple[int], delta: int):\n",
      "    self.axes: tuple[int] = axes\n",
      "    self.delta: int = delta\n",
      "\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    diffs = [p[0] - p[1] for p in zip(source, dest)]\n",
      "    if not all([diffs[axis] == 0 for axis in self.axes]):\n",
      "      src_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord + self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      dest_rank = COMM_ALL.Get_cart_rank(\n",
      "          [(cord - self.delta) % MESH[i] if i in self.axes else cord for i, cord in enumerate(dest)])\n",
      "      COMM_ALL.Sendrecv_replace(srcbuf, dest=dest_rank, source=src_rank)\n",
      "    np.copyto(recvbuf, srcbuf)\n",
      "\n",
      "\n",
      "class CommSendrecv:\n",
      "  def __call__(self, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "    COMM_ALL.Sendrecv(srcbuf, COMM_ALL.Get_cart_rank(dest), 0,\n",
      "                      recvbuf, COMM_ALL.Get_cart_rank(source))\n",
      "\n",
      "def Trans(comm, srcbuf: np.ndarray, source: list[int], recvbuf: np.ndarray, dest: list[int]):\n",
      "  comm(srcbuf, source, recvbuf, dest)\n",
      "\n",
      "def computation(C, A, B):\n",
      "    for ko in range(0, 7 + 1, 1):\n",
      "        TransB = np.zeros([256,128])\n",
      "        Trans(CommShift((0,),1),B[0:256,0:128],[(x + ko) % 8,y],TransB[0:256,0:128],[x,y])\n",
      "        TransA = np.zeros([64,256])\n",
      "        Trans(CommShift((1,),1),A[0:64,0:256],[x,(y + ko) % 8],TransA[0:64,0:256],[x,y])\n",
      "        C[0:64,0:128] += TransA[0:64,0:256] @ TransB[0:256,0:128]\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    GlobalC = np.load(sys.argv[1], mmap_mode=\"r\")\n",
      "    GlobalA = np.load(sys.argv[2], mmap_mode=\"r\")\n",
      "    GlobalB = np.load(sys.argv[3], mmap_mode=\"r\")\n",
      "    A = np.zeros([64,256])\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for k in range(0, 255 + 1, 1):\n",
      "            A[m,k] = GlobalA[64 * x + m,(256 * x + 256 * y + k) % 2048]\n",
      "    B = np.zeros([256,128])\n",
      "    for k in range(0, 255 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            B[k,n] = GlobalB[(256 * x + 256 * y + k) % 2048,128 * y + n]\n",
      "    C = np.zeros([64,128])\n",
      "    computation(C, A, B)\n",
      "    for m in range(0, 63 + 1, 1):\n",
      "        for n in range(0, 127 + 1, 1):\n",
      "            assert np.allclose(C[m,n], GlobalC[64 * x + m,128 * y + n])\n",
      "    print(f\"rank [{','.join(map(str,PIDS))}] passed!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k, m, n = s0.iter_vars\n",
    "x, y = IterVar.range('x', 8), IterVar.range('y', 8)\n",
    "mo, no, mi, ni = IterVar.symbol('mo no mi ni')\n",
    "ko, ki = IterVar.symbol('ko ki')\n",
    "s0_tensorized = s0.distribute([m, n], [mo, no], [mi, ni], Mesh((x, y))). \\\n",
    "    divide(k, ko, ki, x.extent). \\\n",
    "    reorder(mo, no, ko, mi, ni, ki). \\\n",
    "    shard('A', m @ x, k @ ((x + y) % 8)). \\\n",
    "    shard('B', k @ ((x + y) % 8), n @ y). \\\n",
    "    shard('C', m @ x, n @ y). \\\n",
    "    communicate('A', ko, [mo, no]). \\\n",
    "    communicate('B', ko, [mo, no]). \\\n",
    "    tensorize([mi, ni, ki], OpKind.MatMul)\n",
    "\n",
    "with open(\"tmp/cannon.py\", \"w\") as f:\n",
    "  lower_and_codegen(s0_tensorized, f)\n",
    "\n",
    "with open('tmp/cannon.py', 'r') as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26981d50",
   "metadata": {},
   "source": [
    "复用summa的数据，并通过mpi4py进行验证："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun --map-by :OVERSUBSCRIBE -n 64 python tmp/cannon.py tmp/arrC.npy tmp/arrA.npy tmp/arrB.npy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
